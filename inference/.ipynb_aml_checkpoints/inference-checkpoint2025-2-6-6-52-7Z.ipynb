{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.pipeline import EntityRecognizer\n",
        "from spacy.tokens import Doc, Span\n",
        "from transformers import AutoModelForTokenClassification, AutoTokenizer, pipeline\n",
        "\n",
        "# Load your saved model\n",
        "model_name = \"bert-large-mp-local\"  # Directory where your model is saved\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# Create an NER pipeline\n",
        "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Define a function to process text with the Hugging Face model\n",
        "def hf_ner_pipe(doc):\n",
        "    text = doc.text\n",
        "    entities = ner_pipeline(text)\n",
        "\n",
        "    ents = []\n",
        "    for ent in entities:\n",
        "        start_char, end_char, label = ent[\"start\"], ent[\"end\"], ent[\"entity_group\"]\n",
        "\n",
        "        # Convert character-based indices to token indices\n",
        "        start_token = len(tokenizer.encode(text[:start_char])) - 1\n",
        "        end_token = len(tokenizer.encode(text[:end_char])) - 1\n",
        "\n",
        "        span = Span(doc, start_token, end_token + 1, label=label)\n",
        "        ents.append(span)\n",
        "\n",
        "    doc.ents = ents  # Assign extracted entities to the doc\n",
        "    return doc\n",
        "\n",
        "# Create a blank spaCy pipeline\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "# Add custom NER component\n",
        "nlp.add_pipe(hf_ner_pipe, name=\"hf_ner\", first=True)\n",
        "\n",
        "# Test it\n",
        "text = \"Elon Musk is the CEO of SpaceX.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Print extracted entities\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1741243840218
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}