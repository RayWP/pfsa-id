{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90390258-19fd-4e26-931a-5d82ea4015eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m data[LABEL_COLUMNS] \u001b[38;5;241m=\u001b[39m mlb\u001b[38;5;241m.\u001b[39mfit_transform(data[LABEL_COLUMNS]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mtuple\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Split data into training and validation sets\u001b[39;00m\n\u001b[1;32m     28\u001b[0m train_texts, val_texts, train_labels, val_labels \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m---> 29\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLABEL_COLUMNS\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m(), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Load tokenizer\u001b[39;00m\n\u001b[1;32m     33\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_NAME)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6297\u001b[0m ):\n\u001b[1;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torchcrf import CRF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device to CUDA if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define model parameters\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 8\n",
    "LABEL_COLUMNS = [\"structure_focus\", \"usecase_focus\"]\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('type_classification-validation.csv')\n",
    "\n",
    "# Encode labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "data[LABEL_COLUMNS] = mlb.fit_transform(data[LABEL_COLUMNS].apply(tuple, axis=1)).tolist()\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data['sentence'].tolist(), data[LABEL_COLUMNS].tolist(), test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Tokenize the data\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Load pre-trained model\n",
    "num_labels = len(LABEL_COLUMNS)\n",
    "class BertMultiLabelCRFModel(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super(BertMultiLabelCRFModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        self.fc = torch.nn.Linear(self.hidden_size, num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.fc(outputs.last_hidden_state[:, 0, :])  # Take [CLS] token representation\n",
    "        return logits\n",
    "\n",
    "model = BertMultiLabelCRFModel(MODEL_NAME, num_labels)\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=EPOCHS):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "            logits = model(**inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=total_loss / (progress_bar.n + 1))\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Train model\n",
    "train_model(model, train_loader, optimizer, criterion, epochs=EPOCHS)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"./fine_tuned_bert_multilabel.pth\")\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "            logits = model(**inputs)\n",
    "            preds = torch.sigmoid(logits).cpu().numpy() > 0.5\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Get predictions\n",
    "y_true, y_pred = evaluate_model(model, val_loader)\n",
    "\n",
    "# Generate evaluation metrics\n",
    "class_names = LABEL_COLUMNS\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(report)\n",
    "\n",
    "# Compute overall precision, recall, f1-score, and accuracy\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Overall Precision: {precision:.4f}\")\n",
    "print(f\"Overall Recall: {recall:.4f}\")\n",
    "print(f\"Overall F1-score: {f1:.4f}\")\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save results to file\n",
    "results_filename = f\"results_{MODEL_NAME}_epochs{EPOCHS}_batch{BATCH_SIZE}_multilabel.txt\"\n",
    "with open(results_filename, \"w\") as f:\n",
    "    f.write(report)\n",
    "    f.write(f\"\\nOverall Precision: {precision:.4f}\\n\")\n",
    "    f.write(f\"Overall Recall: {recall:.4f}\\n\")\n",
    "    f.write(f\"Overall F1-score: {f1:.4f}\\n\")\n",
    "    f.write(f\"Overall Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "print(f\"Results saved to {results_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ece9de2-9b01-4358-89fe-af320552c26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b57d9cafe474e32ad97ef92874aebec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769a3891e0144e2f925e2676d62a347f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6021df693764232bd7f124b61d1f357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fbf52c856c4383bafa584debbcc7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d53a6d5d0642d095085d442cc86941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabe4a99711d497e9d1d2e57499525fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " The automatic generation of UML diagrams from requirements can significantly speed up software design. This paper presents a pipeline that uses sentence classification to identify useful requirements and transform them into class and use case diagrams.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BART model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Input long text to summarize\n",
    "text = \"\"\"\n",
    "The automatic generation of UML diagrams from requirements can significantly speed up software design. \n",
    "Traditionally, this involves manual review of textual requirements to determine relevant entities and behaviors. \n",
    "Recent advances in natural language processing, particularly in fine-tuning pre-trained transformer models, \n",
    "have made it possible to automate this process with greater accuracy. \n",
    "This paper presents a pipeline that uses sentence classification to identify useful requirements \n",
    "and transform them into class and use case diagrams.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize and encode the text\n",
    "inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "# Generate summary (you can control length via min_length, max_length)\n",
    "summary_ids = model.generate(inputs, max_length=100, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode the summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f760632-5e74-40c0-9105-96d3770d56ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
