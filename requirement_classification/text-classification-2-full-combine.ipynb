{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926ee245-18e1-47ce-ba1f-320a271aebb4",
   "metadata": {},
   "source": [
    "## Use Case Focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a7ac7e-575a-4068-8531-d3472e68c3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:02<00:00,  7.45it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=1.25]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.03it/s, loss=1.12]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.03it/s, loss=1.12]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 10.13it/s, loss=1.26]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.92it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.07it/s, loss=0.965]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.03it/s, loss=0.817]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.95it/s, loss=1.07]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=1.08]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.05it/s, loss=1.04]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=1.16]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=1.3] \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=1.24]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=1.12]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.05it/s, loss=0.977]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.94it/s, loss=0.86] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 10.23it/s, loss=1.07]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00, 10.08it/s, loss=0.974]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00, 10.14it/s, loss=0.916]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.02it/s, loss=1.07]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.03it/s, loss=0.931]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.03it/s, loss=0.798]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=0.649]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.05it/s, loss=1.11]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.966]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.02it/s, loss=0.811]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=1.01] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.93it/s, loss=1.1] \n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.05it/s, loss=1.01]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.06it/s, loss=1.08] \n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=0.839]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.03it/s, loss=1.06]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.949]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.02it/s, loss=0.763]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.03it/s, loss=0.598]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 10.10it/s, loss=1.18]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00, 10.23it/s, loss=1.04] \n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00, 10.20it/s, loss=0.936]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00, 10.12it/s, loss=0.805]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.07it/s, loss=1.15]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.01it/s, loss=0.955]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=0.726]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.10it/s, loss=0.555]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.44] \n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.01it/s, loss=0.326]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.275]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=0.179]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.143]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=1.18]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=1.05]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.992]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.95it/s, loss=0.891]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.698]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.02it/s, loss=0.55] \n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.441]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.10it/s, loss=0.353]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.248]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.06it/s, loss=1.04]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.08it/s, loss=0.865]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.02it/s, loss=0.933]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.01it/s, loss=0.873]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.98it/s, loss=0.667]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.545]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.424]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.337]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.95it/s, loss=0.235]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.02it/s, loss=1.15]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.94it/s, loss=1.02]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.921]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.86] \n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.687]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.98it/s, loss=0.584]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.95it/s, loss=0.421]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=0.292]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.94it/s, loss=0.188]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 10.04it/s, loss=1.19]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00, 10.14it/s, loss=0.872]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00, 10.07it/s, loss=0.726]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00, 10.12it/s, loss=0.608]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:01<00:00, 10.63it/s, loss=0.624]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:01<00:00, 10.50it/s, loss=0.487]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:01<00:00, 10.62it/s, loss=0.441]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:01<00:00, 10.57it/s, loss=0.345]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.57it/s, loss=0.347]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.94it/s, loss=1.16]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.02it/s, loss=1.03] \n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.98it/s, loss=1.32]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=1.14]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=1.03] \n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.985]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.98it/s, loss=0.928]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.722]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.594]\n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.555]\n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.98it/s, loss=0.387]\n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.268]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.98it/s, loss=1.08]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.01it/s, loss=0.9]  \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.98it/s, loss=0.789]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.02it/s, loss=0.636]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=0.627]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.441]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.329]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.98it/s, loss=0.215]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=0.168]\n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.147]\n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.147]\n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.122]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.05it/s, loss=1.11]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.866]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.769]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.03it/s, loss=0.7]  \n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.534]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.452]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.37] \n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.95it/s, loss=0.38] \n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.28] \n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=0.277]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.97it/s, loss=0.198]\n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.179]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.01it/s, loss=1.13]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.944]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.00it/s, loss=0.795]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.657]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=0.56] \n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.95it/s, loss=0.454]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.378]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.98it/s, loss=0.313]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=0.262]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=0.206]\n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=0.152]\n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.95it/s, loss=0.115]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 10.26it/s, loss=1.1] \n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00, 10.09it/s, loss=0.964]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00, 10.10it/s, loss=0.864]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00, 10.19it/s, loss=0.726]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:01<00:00, 10.15it/s, loss=0.538]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:01<00:00, 10.06it/s, loss=0.363]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:01<00:00, 10.21it/s, loss=0.359]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:01<00:00, 10.14it/s, loss=0.254]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:01<00:00, 10.10it/s, loss=0.231]\n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:01<00:00, 10.22it/s, loss=0.204]\n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:01<00:00, 10.20it/s, loss=0.15] \n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:01<00:00, 10.03it/s, loss=0.0982]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to albert-albert-base-v2_label.txt\n",
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.11]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.14]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.46it/s, loss=1.32]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.27it/s, loss=1.13]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.943]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.954]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.22]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.94] \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.851]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=1.16]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.03]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.962]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=1.27]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.06]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=1.01]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.45it/s, loss=1.22]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.45it/s, loss=1.06]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.46it/s, loss=0.976]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.1] \n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.991]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.894]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.732]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=1.16]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.992]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.807]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.666]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.19]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.05]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.952]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.842]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.19]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.05]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.03]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.984]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.44it/s, loss=1.12]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.45it/s, loss=1.05] \n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.47it/s, loss=0.978]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.45it/s, loss=0.848]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=1.15]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.27it/s, loss=0.979]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.83] \n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.645]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.497]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.17it/s, loss=0.409]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.76it/s, loss=0.355]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.65it/s, loss=0.402]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.302]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=1.18]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.27it/s, loss=0.968]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.9]  \n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.864]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.775]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.606]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.664]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.517]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.432]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.17]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.08]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.939]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.753]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.61] \n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.551]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.506]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.418]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.273]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.23it/s, loss=1.1] \n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.984]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.897]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.747]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.601]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.445]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.374]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.244]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.255]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.43it/s, loss=1.2] \n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.44it/s, loss=0.988]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.43it/s, loss=0.904]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.44it/s, loss=0.791]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.42it/s, loss=0.651]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.42it/s, loss=0.522]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.43it/s, loss=0.494]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.42it/s, loss=0.488]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.42it/s, loss=0.304]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.99] \n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.997]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.92] \n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.82] \n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.23it/s, loss=0.681]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.575]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.463]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.447]\n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.402]\n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.318]\n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.209]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=1.17]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.01] \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.968]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.858]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.771]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.689]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.624]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.477]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.444]\n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.365]\n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:04<00:00,  3.23it/s, loss=0.308]\n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.303]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.18]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=1.07]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.01]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.927]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.82] \n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.828]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.714]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.27it/s, loss=0.565]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.438]\n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.376]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=0.383]\n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.267]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.11]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.25it/s, loss=0.956]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=0.968]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.06] \n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.07]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.08]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.11]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.04]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.26it/s, loss=1.04]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:04<00:00,  3.24it/s, loss=1.05] \n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:04<00:00,  3.27it/s, loss=1.02] \n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:04<00:00,  3.27it/s, loss=1.03] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.45it/s, loss=1.1] \n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.44it/s, loss=0.947]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.43it/s, loss=0.95] \n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.42it/s, loss=1.1] \n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.43it/s, loss=1.03]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.45it/s, loss=1.07]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.45it/s, loss=1.03]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.44it/s, loss=1.04]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.43it/s, loss=1]   \n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:04<00:00,  3.46it/s, loss=1.02]\n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:04<00:00,  3.45it/s, loss=1.05] \n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:04<00:00,  3.45it/s, loss=1.03]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to albert-albert-large-v2_label.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.10it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.20it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.20it/s, loss=1.23]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.10it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.23it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.11it/s, loss=1.16]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.19it/s, loss=1.03]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.21it/s, loss=0.928]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=1.16]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s, loss=1.02]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.822]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=1.18]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=1.06]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.857]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=1.13]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s, loss=1.01] \n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s, loss=0.825]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s, loss=1.17]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.19it/s, loss=1.03]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s, loss=0.86] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=1.4] \n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=1.06]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.956]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.643]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=1.19]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s, loss=1.02]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.839]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:06<00:00,  2.18it/s, loss=0.529]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.11it/s, loss=1.1] \n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.991]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  1.98it/s, loss=0.887]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:07<00:00,  1.98it/s, loss=0.664]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  1.98it/s, loss=1.24]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:07<00:00,  2.00it/s, loss=1.02]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.941]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:07<00:00,  1.98it/s, loss=0.718]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=1.18]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:07<00:00,  2.03it/s, loss=0.992]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  2.09it/s, loss=0.924]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.746]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.05it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=1.01] \n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  2.03it/s, loss=0.936]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.673]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:07<00:00,  2.03it/s, loss=0.516]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.301]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:07<00:00,  2.03it/s, loss=0.178]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:07<00:00,  2.01it/s, loss=0.137]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:07<00:00,  2.01it/s, loss=0.123] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.01it/s, loss=1.18]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:07<00:00,  1.98it/s, loss=1.05]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  2.01it/s, loss=0.926]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:07<00:00,  1.94it/s, loss=0.73] \n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:07<00:00,  1.98it/s, loss=0.563]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.465]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.428]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.228]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.205]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.01it/s, loss=1.27]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:07<00:00,  1.98it/s, loss=1]   \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  1.97it/s, loss=0.913]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:07<00:00,  1.97it/s, loss=0.771]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:07<00:00,  1.97it/s, loss=0.637]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:07<00:00,  1.97it/s, loss=0.443]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:07<00:00,  1.97it/s, loss=0.372]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:07<00:00,  2.13it/s, loss=0.226]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=0.138]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=1.08]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.868]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.949]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.82] \n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:06<00:00,  2.14it/s, loss=0.599]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:06<00:00,  2.14it/s, loss=0.413]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:06<00:00,  2.14it/s, loss=0.3]  \n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s, loss=0.295]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=1.16]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=1.04] \n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=0.913]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.853]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.683]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.453]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=0.346]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.229]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=0.166]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s, loss=1.26]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.14it/s, loss=1.06] \n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s, loss=0.954]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s, loss=0.634]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:07<00:00,  2.13it/s, loss=0.462]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s, loss=0.287]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.196]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s, loss=0.171]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.124]\n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.095] \n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.0588]\n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.0451]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=1.13]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.94] \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=0.757]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.542]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:06<00:00,  2.17it/s, loss=0.373]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=0.234]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=0.18] \n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.103] \n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.0687]\n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.0566]\n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=0.0426]\n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=0.0417]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s, loss=1.16]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:06<00:00,  2.16it/s, loss=1]    \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s, loss=0.783]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:06<00:00,  2.14it/s, loss=0.845]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s, loss=0.972]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:07<00:00,  2.14it/s, loss=1.05]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:07<00:00,  2.04it/s, loss=0.969]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:07<00:00,  1.97it/s, loss=1.01] \n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:07<00:00,  2.04it/s, loss=0.87] \n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:07<00:00,  1.96it/s, loss=0.753]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:07<00:00,  1.97it/s, loss=0.617]\n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:07<00:00,  2.05it/s, loss=0.552]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  1.97it/s, loss=1.27]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:07<00:00,  2.03it/s, loss=1.1] \n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  1.98it/s, loss=0.949]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.839]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.798]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.589]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:07<00:00,  1.96it/s, loss=0.454]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:07<00:00,  2.03it/s, loss=0.5]  \n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:07<00:00,  2.02it/s, loss=0.356]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:07<00:00,  2.03it/s, loss=0.234]\n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.293]\n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:07<00:00,  1.95it/s, loss=0.24] \n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:07<00:00,  2.03it/s, loss=1.19]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:07<00:00,  1.98it/s, loss=1.03] \n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.939]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.729]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.429]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.288]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.217]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.154]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.159]\n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:07<00:00,  2.00it/s, loss=0.121]\n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:07<00:00,  2.00it/s, loss=0.108]\n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:07<00:00,  1.99it/s, loss=0.114] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to microsoft-deberta-v3-large_label.txt\n",
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s, loss=1.28]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=1.35]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s, loss=1.22]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.88it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.96it/s, loss=1.12]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=1.16]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=1.08] \n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.96it/s, loss=1.06]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.07it/s, loss=1.14]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.07it/s, loss=1.11]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.06it/s, loss=0.996]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.07it/s, loss=1.22]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.08it/s, loss=1.08]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.13]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.07it/s, loss=1.23]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.08it/s, loss=1.14]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.08]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.32]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.13it/s, loss=1.01]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.12it/s, loss=1.01]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.16]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.08it/s, loss=1.13]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.04]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.07it/s, loss=0.962]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.26]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.1] \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.11it/s, loss=1.05] \n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=0.883]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.24]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.1] \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.1] \n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.25]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.13]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.07]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.08it/s, loss=1.07]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.11it/s, loss=1.2] \n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.12it/s, loss=1.06]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.14it/s, loss=1.04] \n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.13it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.22]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.08]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.04]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.1] \n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.08]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.15]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.05]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.04]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.11it/s, loss=1.05] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.08it/s, loss=1.17]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=1.05]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=0.971]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=0.921]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=0.776]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.10it/s, loss=0.681]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.08it/s, loss=0.51] \n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.08it/s, loss=0.311]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=0.258]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.3] \n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.08]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.04] \n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.92it/s, loss=1.01]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.93it/s, loss=0.891]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.80it/s, loss=0.796]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.96it/s, loss=0.715]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.79it/s, loss=0.812]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s, loss=0.644]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.96it/s, loss=1.21]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=1.05]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=1.05]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=1.01] \n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.986]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.82it/s, loss=0.951]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s, loss=0.631]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s, loss=0.641]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s, loss=0.342]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=1.26]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s, loss=1.15]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=1.1] \n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.88it/s, loss=0.998]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=1]    \n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=1.09]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=1.07]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=1.2] \n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=1.05] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.87it/s, loss=1.19]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=1.07]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.986]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.951]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.798]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.84it/s, loss=0.699]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=0.483]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.58] \n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.84it/s, loss=0.552]\n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:05<00:00,  2.87it/s, loss=0.239]\n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.0972]\n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.0629]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=1.17]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=1.01] \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=1.04]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.921]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.87it/s, loss=0.777]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=0.66] \n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.538]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.88it/s, loss=0.421]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.87it/s, loss=0.389]\n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:05<00:00,  2.87it/s, loss=0.192]\n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:05<00:00,  2.87it/s, loss=0.159]\n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.127]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.88it/s, loss=1.29]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.87it/s, loss=1.08]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=1.07] \n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=1.06]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=0.988]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.88it/s, loss=0.885]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.03it/s, loss=0.9]  \n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:04<00:00,  3.11it/s, loss=1.13]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:04<00:00,  3.11it/s, loss=1.19]\n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:04<00:00,  3.12it/s, loss=1.15]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:04<00:00,  3.12it/s, loss=1.08]\n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:04<00:00,  3.12it/s, loss=1.08]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.12it/s, loss=1.2] \n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:04<00:00,  3.12it/s, loss=1.05]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:04<00:00,  3.12it/s, loss=1.08]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:04<00:00,  3.11it/s, loss=1.08]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:04<00:00,  3.06it/s, loss=0.931]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:04<00:00,  3.13it/s, loss=0.711]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:04<00:00,  3.04it/s, loss=0.568]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.81it/s, loss=0.497]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.84it/s, loss=0.394]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s, loss=0.249]\n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:05<00:00,  2.84it/s, loss=0.169]\n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s, loss=0.133]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.84it/s, loss=1.14]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=1.07]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.927]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.84it/s, loss=0.865]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=0.626]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.87it/s, loss=0.502]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.85it/s, loss=0.315]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.98it/s, loss=0.184]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.81it/s, loss=0.289]\n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.152]\n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.102]\n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.072] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to FacebookAI-roberta-large_label.txt\n",
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.37it/s, loss=1.23]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.39it/s, loss=1.22]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.31it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.39it/s, loss=1.29]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=1.25]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.42it/s, loss=1.25]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.36it/s, loss=1.02] \n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.42it/s, loss=0.84] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.41it/s, loss=1.18]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.40it/s, loss=0.988]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=0.779]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.36it/s, loss=1.39]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.39it/s, loss=1.05]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.77it/s, loss=0.803]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.66it/s, loss=1.26]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.83it/s, loss=1.04]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.54it/s, loss=0.92] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.81it/s, loss=1.28]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.86it/s, loss=0.954]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.80it/s, loss=0.828]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=1.27]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.66it/s, loss=1.1] \n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.963]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.15it/s, loss=0.887]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=1.12]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.994]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.884]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.67it/s, loss=0.688]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.62it/s, loss=1.14]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.61it/s, loss=1.01] \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=0.914]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.63it/s, loss=0.798]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.58it/s, loss=1.07]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.48it/s, loss=0.959]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.61it/s, loss=0.824]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=0.662]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.73it/s, loss=1.09]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.84it/s, loss=0.941]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.65it/s, loss=0.821]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.76it/s, loss=0.671]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=1.2] \n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=1.07]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.941]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=0.796]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.61] \n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=0.489]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.62it/s, loss=0.374]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.61it/s, loss=0.285]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.202]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.41it/s, loss=1.21]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.967]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.58it/s, loss=0.832]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=0.675]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.513]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=0.377]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=0.315]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=0.225]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.63it/s, loss=0.185]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=1.22]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.948]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.878]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=0.778]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.609]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=0.488]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.50it/s, loss=0.394]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.337]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=0.307]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.62it/s, loss=1.01]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=0.874]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=0.762]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=0.607]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.61it/s, loss=0.53] \n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.432]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=0.375]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.357]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.66it/s, loss=1.18]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.64it/s, loss=0.984]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.76it/s, loss=0.839]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.76it/s, loss=0.689]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.78it/s, loss=0.584]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=0.464]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s, loss=0.416]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.66it/s, loss=0.291]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.70it/s, loss=0.238]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=1.01]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=0.898]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.73] \n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.572]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=0.418]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.285]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.63it/s, loss=0.194]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=0.151]\n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=0.119] \n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  9.38it/s, loss=0.127]\n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.94it/s, loss=0.0785]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.23it/s, loss=1.17]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.19it/s, loss=1.12] \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.14it/s, loss=0.895]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.20it/s, loss=0.727]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.95it/s, loss=0.539]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.04it/s, loss=0.381]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.15it/s, loss=0.275]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.18it/s, loss=0.193]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.15it/s, loss=0.149]\n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  9.39it/s, loss=0.116]\n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  9.28it/s, loss=0.0943]\n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  9.07it/s, loss=0.0957]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.24it/s, loss=1.38]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.13it/s, loss=1.11]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.11it/s, loss=0.893]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.25it/s, loss=0.84] \n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  9.07it/s, loss=0.684]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.99it/s, loss=0.573]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=0.394]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.14it/s, loss=0.345]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.12it/s, loss=0.264]\n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  9.16it/s, loss=0.212]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  9.13it/s, loss=0.189]\n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  9.34it/s, loss=0.154]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.13it/s, loss=1.3] \n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.19it/s, loss=1.04] \n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.24it/s, loss=0.806]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.24it/s, loss=0.662]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  9.11it/s, loss=0.613]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.23it/s, loss=0.468]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.13it/s, loss=0.366]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.21it/s, loss=0.308]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.09it/s, loss=0.238]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  9.32it/s, loss=0.218]\n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  9.23it/s, loss=0.181]\n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.62it/s, loss=0.163]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.71it/s, loss=1.28]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.82it/s, loss=1.01]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.68it/s, loss=0.906]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s, loss=0.766]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.77it/s, loss=0.606]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.90it/s, loss=0.485]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.69it/s, loss=0.302]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.81it/s, loss=0.23] \n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.83it/s, loss=0.206]\n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.80it/s, loss=0.16] \n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.66it/s, loss=0.119] \n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s, loss=0.1]   \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to google-bert-bert-base-uncased_label.txt\n",
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.64it/s, loss=1.22]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=1.13]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=1.26]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.05it/s, loss=1.25]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=1.2] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=1.26]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.966]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.64it/s, loss=0.798]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.70it/s, loss=1.21]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.65it/s, loss=1]    \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=0.829]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.64it/s, loss=1.17]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.70it/s, loss=0.877]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:02<00:00,  7.34it/s, loss=0.733]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.83it/s, loss=1.27]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=0.933]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.01it/s, loss=0.797]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.68it/s, loss=1.29]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=0.972]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.70it/s, loss=0.832]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.43it/s, loss=1.12]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.43it/s, loss=0.987]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.775]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.56] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.40it/s, loss=1.16]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=0.943]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.41it/s, loss=0.775]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.41it/s, loss=0.59] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.39it/s, loss=1.14]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=0.899]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.43it/s, loss=0.702]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=0.531]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=1.15]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.32it/s, loss=0.893]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.675]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.471]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.58it/s, loss=1.23]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.955]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.67it/s, loss=0.838]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.607]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.33it/s, loss=1.26]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=0.946]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=0.759]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.566]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.411]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=0.343]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.267]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=0.198]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=0.17] \n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=1.17]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.999]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=0.875]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.54it/s, loss=0.735]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.605]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.36it/s, loss=0.461]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.382]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.324]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.221]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=1.12]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=0.989]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.36it/s, loss=0.785]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.65] \n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.37it/s, loss=0.532]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.425]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.33] \n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=0.274]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.43it/s, loss=0.193]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.43it/s, loss=1.33]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.42it/s, loss=1.02]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.43it/s, loss=0.902]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=0.815]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.655]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.487]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=0.355]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=0.268]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.43it/s, loss=0.211]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=1.17]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.69it/s, loss=0.902]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.747]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=0.605]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.484]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.69it/s, loss=0.374]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.63it/s, loss=0.257]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.58it/s, loss=0.205]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.174]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=1.08]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.956]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.46it/s, loss=0.828]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.58it/s, loss=0.632]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=0.431]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.50it/s, loss=0.31] \n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.43it/s, loss=0.189]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=0.142]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=0.113] \n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=0.0978]\n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=0.0727]\n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.40it/s, loss=0.0593]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=1.18]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.914]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.62it/s, loss=0.731]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.558]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=0.448]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.316]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.40it/s, loss=0.283]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.234]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.48it/s, loss=0.194]\n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.166]\n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.148]\n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.43it/s, loss=0.139]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=1.25]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.65it/s, loss=0.963]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.75it/s, loss=0.818]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.90it/s, loss=0.694]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.50it/s, loss=0.575]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.40it/s, loss=0.439]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.31it/s, loss=0.306]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=0.236]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s, loss=0.198]\n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.69it/s, loss=0.172]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.72it/s, loss=0.145]\n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=0.139]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.07it/s, loss=1.26]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.83it/s, loss=0.998]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.87it/s, loss=0.864]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.67it/s, loss=0.725]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.94it/s, loss=0.584]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.71it/s, loss=0.418]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.27it/s, loss=0.3]  \n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.41it/s, loss=0.241]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.28it/s, loss=0.184]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  9.25it/s, loss=0.141]\n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  9.34it/s, loss=0.0944]\n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  9.20it/s, loss=0.103] \n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.49it/s, loss=1.16]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.31it/s, loss=0.969]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.50it/s, loss=0.793]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.58it/s, loss=0.622]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  9.50it/s, loss=0.449]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.48it/s, loss=0.312]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.44it/s, loss=0.22] \n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.53it/s, loss=0.158]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.48it/s, loss=0.129]\n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  9.54it/s, loss=0.102] \n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  9.54it/s, loss=0.0811]\n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  9.49it/s, loss=0.0877]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to ProsusAI-finbert_label.txt\n",
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.51it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.75it/s, loss=1.2] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.66it/s, loss=1.14]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.58it/s, loss=1.27]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 17.18it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.80it/s, loss=1.15]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.92it/s, loss=0.953]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.72it/s, loss=0.801]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.59it/s, loss=1.27]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.83it/s, loss=0.978]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.88it/s, loss=0.845]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.71it/s, loss=1.27]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.85it/s, loss=1]    \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.83it/s, loss=0.873]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.80it/s, loss=1.25]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.63it/s, loss=0.977]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.95it/s, loss=0.829]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.88it/s, loss=1.27]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.08it/s, loss=1.03] \n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.16it/s, loss=0.828]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.93it/s, loss=1.3] \n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.63it/s, loss=1]    \n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.91it/s, loss=0.855]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 16.89it/s, loss=0.729]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 14.98it/s, loss=1.19]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.08it/s, loss=0.95] \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.12it/s, loss=0.802]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.08it/s, loss=0.677]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 15.04it/s, loss=1.27]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.22it/s, loss=0.978]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.03it/s, loss=0.876]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00, 14.90it/s, loss=0.704]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 14.94it/s, loss=1.17]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.08it/s, loss=0.954]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00, 14.89it/s, loss=0.823]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00, 14.90it/s, loss=0.674]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 15.49it/s, loss=1.16]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.76it/s, loss=0.941]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.73it/s, loss=0.803]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.67it/s, loss=0.671]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 15.44it/s, loss=1.16]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.23it/s, loss=0.935]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.38it/s, loss=0.838]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.38it/s, loss=0.644]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.50it/s, loss=0.552]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.38it/s, loss=0.436]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 15.22it/s, loss=0.333]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 15.40it/s, loss=0.27] \n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.39it/s, loss=0.212]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 15.25it/s, loss=1.17]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.41it/s, loss=0.985]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.34it/s, loss=0.838]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.31it/s, loss=0.727]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.40it/s, loss=0.548]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.25it/s, loss=0.401]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 15.36it/s, loss=0.308]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 15.33it/s, loss=0.244]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.33it/s, loss=0.17] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 15.11it/s, loss=1.31]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.40it/s, loss=0.977]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.27it/s, loss=0.836]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.37it/s, loss=0.777]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.24it/s, loss=0.605]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.41it/s, loss=0.511]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 15.47it/s, loss=0.394]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 15.04it/s, loss=0.305]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.40it/s, loss=0.248]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 15.21it/s, loss=1.18]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.33it/s, loss=0.954]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.37it/s, loss=0.783]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.25it/s, loss=0.626]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.32it/s, loss=0.49] \n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.31it/s, loss=0.368]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 15.30it/s, loss=0.283]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 15.51it/s, loss=0.23] \n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.36it/s, loss=0.17] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 14.91it/s, loss=1.19]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.24it/s, loss=0.996]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.29it/s, loss=0.84] \n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.30it/s, loss=0.759]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.04it/s, loss=0.602]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.29it/s, loss=0.486]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 15.38it/s, loss=0.352]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 15.04it/s, loss=0.253]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.26it/s, loss=0.187]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 14.89it/s, loss=1.27]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.15it/s, loss=0.97]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00, 14.95it/s, loss=0.802]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00, 14.92it/s, loss=0.68] \n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.24it/s, loss=0.548]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.02it/s, loss=0.41] \n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:01<00:00, 15.00it/s, loss=0.328]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 15.17it/s, loss=0.245]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.11it/s, loss=0.173]\n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 15.14it/s, loss=0.129]\n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 15.14it/s, loss=0.0947]\n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 15.07it/s, loss=0.0857]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 15.15it/s, loss=1.24]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.11it/s, loss=0.979]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.07it/s, loss=0.8]  \n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00, 14.86it/s, loss=0.653]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.36it/s, loss=0.486]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.14it/s, loss=0.408]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 15.09it/s, loss=0.3]  \n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 15.06it/s, loss=0.213]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.20it/s, loss=0.17] \n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 15.02it/s, loss=0.147]\n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 15.20it/s, loss=0.112]\n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 15.14it/s, loss=0.0966]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 15.05it/s, loss=1.13]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.19it/s, loss=0.96] \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.37it/s, loss=0.818]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.25it/s, loss=0.681]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.12it/s, loss=0.562]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.04it/s, loss=0.433]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 15.08it/s, loss=0.364]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 15.06it/s, loss=0.238]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.44it/s, loss=0.183]\n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 15.11it/s, loss=0.143]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 15.33it/s, loss=0.102] \n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 15.12it/s, loss=0.0925]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00, 14.98it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.16it/s, loss=0.961]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.07it/s, loss=0.803]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.11it/s, loss=0.654]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.07it/s, loss=0.482]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.12it/s, loss=0.389]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 15.10it/s, loss=0.273]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:01<00:00, 14.91it/s, loss=0.218]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.15it/s, loss=0.154]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 15.15it/s, loss=0.127]\n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 15.19it/s, loss=0.0994]\n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:01<00:00, 14.93it/s, loss=0.0926]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 15.25it/s, loss=1.17]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 15.17it/s, loss=0.967]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 15.27it/s, loss=0.85] \n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 15.36it/s, loss=0.745]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 15.38it/s, loss=0.629]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.54it/s, loss=0.477]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 15.90it/s, loss=0.369]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 15.86it/s, loss=0.248]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 15.63it/s, loss=0.169]\n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 15.67it/s, loss=0.149]\n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 15.75it/s, loss=0.12]  \n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 15.84it/s, loss=0.114] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to PHILIPPUNI-distilbert-amazon-software-reviews-finetuned_label.txt\n",
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.22it/s, loss=1.3] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=1.12]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=1.27]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.72it/s, loss=1.22]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.65it/s, loss=1.22]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.65it/s, loss=1.26]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.68it/s, loss=0.995]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=0.928]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.34it/s, loss=1.35]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.07it/s, loss=1.06]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.30it/s, loss=0.887]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=1.13]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=1.02] \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.50it/s, loss=0.911]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=1.2] \n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=1]    \n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.48it/s, loss=0.834]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.72it/s, loss=1.33]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.74it/s, loss=1.08]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.70it/s, loss=0.881]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=1.33]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=1.02]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.61it/s, loss=0.888]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.7]  \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.61it/s, loss=1.33]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.54it/s, loss=1.04]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.65it/s, loss=0.867]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.54it/s, loss=0.704]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=1.11]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.57it/s, loss=0.988]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=0.838]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=0.694]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=1.18]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.48it/s, loss=0.958]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.777]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=0.572]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.75it/s, loss=1.33]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.67it/s, loss=0.99] \n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.83it/s, loss=0.849]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.69it/s, loss=0.719]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=1.36]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=1.06]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.53it/s, loss=0.969]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=0.867]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.702]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.522]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.64it/s, loss=0.369]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.63it/s, loss=0.225]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.159]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.54it/s, loss=1.24]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.60it/s, loss=1.02]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.971]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.839]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=0.662]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.478]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.335]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=0.218]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.151]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  7.99it/s, loss=1.33]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=1]   \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.50it/s, loss=0.876]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.692]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.52it/s, loss=0.54] \n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.61it/s, loss=0.418]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.308]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=0.265]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.54it/s, loss=0.226]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.55it/s, loss=1.16]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.999]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.59it/s, loss=0.916]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.56it/s, loss=0.726]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.90it/s, loss=0.509]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.18it/s, loss=0.35] \n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.96it/s, loss=0.227]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.70it/s, loss=0.172]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.07it/s, loss=0.12] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.47it/s, loss=1.14]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.63it/s, loss=1.01] \n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.61it/s, loss=0.807]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.63it/s, loss=0.72] \n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  9.58it/s, loss=0.49] \n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.41it/s, loss=0.318]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.55it/s, loss=0.227]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.54it/s, loss=0.195]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.61it/s, loss=0.156]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.40it/s, loss=1.28]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.28it/s, loss=1.04] \n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.44it/s, loss=0.985]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.32it/s, loss=0.727]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  9.30it/s, loss=0.525]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.43it/s, loss=0.405]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.22it/s, loss=0.253]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.35it/s, loss=0.202]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.26it/s, loss=0.162]\n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  9.40it/s, loss=0.126]\n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  9.43it/s, loss=0.109]\n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  9.25it/s, loss=0.0799]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.31it/s, loss=1.34]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  9.47it/s, loss=1.02] \n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  9.31it/s, loss=0.945]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  9.29it/s, loss=0.719]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  9.48it/s, loss=0.541]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  9.21it/s, loss=0.379]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  9.27it/s, loss=0.271]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  9.34it/s, loss=0.183]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  9.37it/s, loss=0.114]\n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  9.39it/s, loss=0.106] \n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  9.29it/s, loss=0.082] \n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  9.40it/s, loss=0.0655]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  9.09it/s, loss=1.28]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=1.02]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.39it/s, loss=0.906]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=0.789]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.38it/s, loss=0.66] \n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.36it/s, loss=0.543]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.49it/s, loss=0.427]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.42it/s, loss=0.322]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.283]\n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.44it/s, loss=0.191]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.61it/s, loss=0.14] \n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.38it/s, loss=0.127]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.47it/s, loss=1.41]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.42it/s, loss=1.02]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.37it/s, loss=0.88] \n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.37it/s, loss=0.782]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.41it/s, loss=0.656]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.525]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.69it/s, loss=0.36] \n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.83it/s, loss=0.264]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.76it/s, loss=0.208]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.65it/s, loss=0.177]\n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.79it/s, loss=0.136]\n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.84it/s, loss=0.12] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:01<00:00,  8.38it/s, loss=1.23]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:01<00:00,  8.88it/s, loss=0.982]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:01<00:00,  8.89it/s, loss=0.794]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:01<00:00,  8.84it/s, loss=0.575]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:01<00:00,  8.45it/s, loss=0.417]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:01<00:00,  8.63it/s, loss=0.321]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:01<00:00,  8.63it/s, loss=0.242]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:01<00:00,  8.50it/s, loss=0.17] \n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:01<00:00,  8.51it/s, loss=0.113]\n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:01<00:00,  8.88it/s, loss=0.0845]\n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:01<00:00,  8.83it/s, loss=0.0621]\n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:01<00:00,  8.90it/s, loss=0.0733]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to justinlamlamlam-softwareengineering_label.txt\n",
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s, loss=1.06]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.72it/s, loss=1.21]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.73it/s, loss=1.12]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.72it/s, loss=1.01]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.75it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.73it/s, loss=1.2] \n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.62it/s, loss=0.621]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.65it/s, loss=0.269]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.70it/s, loss=1.13]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.71it/s, loss=0.583]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.71it/s, loss=0.228]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.64it/s, loss=1.28]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.73it/s, loss=0.74] \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.72it/s, loss=0.569]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.70it/s, loss=1.15]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.71it/s, loss=0.65] \n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.59it/s, loss=0.314]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.78it/s, loss=1.02]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.75it/s, loss=0.472]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.72it/s, loss=0.187]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.71it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.72it/s, loss=0.715]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.72it/s, loss=0.353]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.71it/s, loss=0.108]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.70it/s, loss=1.14]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.71it/s, loss=0.662]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.72it/s, loss=0.373]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.72it/s, loss=0.112]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.63it/s, loss=1.18]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.71it/s, loss=0.939]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.71it/s, loss=0.687]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.78it/s, loss=0.324]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s, loss=0.995]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.84it/s, loss=0.596]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.341]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.137]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=1.17] \n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.868]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.93it/s, loss=0.48] \n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.92it/s, loss=0.289]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.88it/s, loss=1.08]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.569]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.213]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.88it/s, loss=0.172]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.0554]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.0285]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0249] \n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.0274] \n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.0175] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=1.07]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.609]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.27] \n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0752]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0365]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0415]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0312] \n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0352]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0305]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=1.14]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.596]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.225]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0747]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0859]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0353]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0338] \n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0388] \n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.0397] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=1.14]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.531]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.197]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0498]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0525]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.0499]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.0704]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0435]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.239]  \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.92it/s, loss=1]   \n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.92it/s, loss=0.399]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.232]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.0827]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.039] \n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.0318]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.0413] \n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.92it/s, loss=0.0285] \n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.92it/s, loss=0.0284] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=1.15]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.521]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.171]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0653]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.92it/s, loss=0.0243]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.0375] \n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.0303] \n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0199]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.02]   \n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0196] \n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0204] \n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0188]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=1.03]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.518]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.235]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.124]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.101] \n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.0571]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.89it/s, loss=0.0695]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.91it/s, loss=0.137]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.196]\n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:04<00:00,  3.11it/s, loss=0.0468]\n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:04<00:00,  3.14it/s, loss=0.0319]\n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:04<00:00,  3.16it/s, loss=0.03]   \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s, loss=1.22]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.87it/s, loss=0.694]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.96it/s, loss=0.366]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.131]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.0634]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.93it/s, loss=0.076] \n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.0431]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.0355]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.96it/s, loss=0.041] \n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.0373]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.034]  \n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.0359]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.93it/s, loss=1.11]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.554]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.21] \n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.0848]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.109] \n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.0695]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.0702] \n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.0366]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.0344]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:05<00:00,  2.93it/s, loss=0.0318]\n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.0313] \n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.0239]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.94it/s, loss=0.998]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.97it/s, loss=0.433]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.98it/s, loss=0.142]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.97it/s, loss=0.14] \n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.95it/s, loss=0.0665]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:05<00:00,  2.96it/s, loss=0.0449]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:05<00:00,  2.98it/s, loss=0.0224] \n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:05<00:00,  2.90it/s, loss=0.0263] \n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:05<00:00,  2.96it/s, loss=0.0234]\n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:05<00:00,  2.96it/s, loss=0.0268] \n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:05<00:00,  2.98it/s, loss=0.0209] \n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:05<00:00,  2.97it/s, loss=0.0232] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to answerdotai-ModernBERT-large_label.txt\n",
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=1, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.52it/s, loss=1.3] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.67it/s, loss=1.31]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.69it/s, loss=1.24]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.63it/s, loss=1.26]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.87it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=3, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.69it/s, loss=1.25]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.79it/s, loss=0.975]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.10it/s, loss=0.787]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.76it/s, loss=1.23]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.79it/s, loss=0.988]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.84it/s, loss=0.824]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.74it/s, loss=1.25]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.94it/s, loss=1.02]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.08it/s, loss=0.875]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.78it/s, loss=1.19]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.93it/s, loss=0.916]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.84it/s, loss=0.79] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.83it/s, loss=1.25]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.23it/s, loss=0.963]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.31it/s, loss=0.792]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=4, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.75it/s, loss=1.23]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.93it/s, loss=1.01]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.93it/s, loss=0.842]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.10it/s, loss=0.74] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.68it/s, loss=1.1] \n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.89it/s, loss=0.945]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.92it/s, loss=0.759]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 16.86it/s, loss=0.625]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.73it/s, loss=1.23]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.04it/s, loss=0.976]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.13it/s, loss=0.875]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 16.97it/s, loss=0.736]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.66it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.88it/s, loss=0.928]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.06it/s, loss=0.776]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.05it/s, loss=0.586]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 17.05it/s, loss=1.17]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.07it/s, loss=0.945]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.02it/s, loss=0.817]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.33it/s, loss=0.617]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=9, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.92it/s, loss=1.23]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.97it/s, loss=0.976]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.82it/s, loss=0.845]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.01it/s, loss=0.648]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 17.00it/s, loss=0.474]\n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 17.06it/s, loss=0.355]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 17.54it/s, loss=0.302]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 17.60it/s, loss=0.23] \n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 17.37it/s, loss=0.206]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 17.23it/s, loss=1.18]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.61it/s, loss=0.936]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.52it/s, loss=0.772]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.53it/s, loss=0.611]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 17.50it/s, loss=0.526]\n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 17.53it/s, loss=0.417]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 17.19it/s, loss=0.363]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:01<00:00, 14.60it/s, loss=0.284]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 16.38it/s, loss=0.236]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 17.46it/s, loss=1.19]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.43it/s, loss=0.97] \n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.30it/s, loss=0.846]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.44it/s, loss=0.669]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 17.16it/s, loss=0.511]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 15.84it/s, loss=0.401]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 16.17it/s, loss=0.346]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 16.74it/s, loss=0.262]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 17.56it/s, loss=0.201]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 17.50it/s, loss=1.21]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.34it/s, loss=0.992]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.11it/s, loss=0.836]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.11it/s, loss=0.667]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 16.90it/s, loss=0.523]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 17.36it/s, loss=0.405]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 17.15it/s, loss=0.313]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 16.93it/s, loss=0.258]\n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 17.04it/s, loss=0.21] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 17.24it/s, loss=1.3] \n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.32it/s, loss=1]   \n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.15it/s, loss=0.853]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.50it/s, loss=0.684]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 17.45it/s, loss=0.5]  \n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 17.24it/s, loss=0.378]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 17.04it/s, loss=0.283]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 17.08it/s, loss=0.206]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 17.26it/s, loss=0.16] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=12, BATCH_SIZE=8, K-FOLD=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.88it/s, loss=1.21]\n",
      "Fold 1 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.23it/s, loss=0.952]\n",
      "Fold 1 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.95it/s, loss=0.821]\n",
      "Fold 1 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.08it/s, loss=0.671]\n",
      "Fold 1 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 16.87it/s, loss=0.53] \n",
      "Fold 1 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 17.35it/s, loss=0.434]\n",
      "Fold 1 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 17.23it/s, loss=0.324]\n",
      "Fold 1 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 16.88it/s, loss=0.226]\n",
      "Fold 1 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 16.98it/s, loss=0.188]\n",
      "Fold 1 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 16.97it/s, loss=0.144]\n",
      "Fold 1 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 17.34it/s, loss=0.109]\n",
      "Fold 1 Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 17.28it/s, loss=0.109] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 17.01it/s, loss=1.28]\n",
      "Fold 2 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.21it/s, loss=0.965]\n",
      "Fold 2 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 16.99it/s, loss=0.754]\n",
      "Fold 2 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.22it/s, loss=0.595]\n",
      "Fold 2 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 17.22it/s, loss=0.44] \n",
      "Fold 2 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 16.99it/s, loss=0.342]\n",
      "Fold 2 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 17.05it/s, loss=0.273]\n",
      "Fold 2 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 17.04it/s, loss=0.225]\n",
      "Fold 2 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 17.09it/s, loss=0.161]\n",
      "Fold 2 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 16.96it/s, loss=0.158]\n",
      "Fold 2 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 16.99it/s, loss=0.0951]\n",
      "Fold 2 Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 16.96it/s, loss=0.0939]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 16.92it/s, loss=1.25]\n",
      "Fold 3 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 16.99it/s, loss=0.948]\n",
      "Fold 3 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.02it/s, loss=0.779]\n",
      "Fold 3 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 16.89it/s, loss=0.624]\n",
      "Fold 3 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 16.85it/s, loss=0.503]\n",
      "Fold 3 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 17.28it/s, loss=0.369]\n",
      "Fold 3 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 17.11it/s, loss=0.293]\n",
      "Fold 3 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 16.96it/s, loss=0.243]\n",
      "Fold 3 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 17.05it/s, loss=0.179]\n",
      "Fold 3 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 16.99it/s, loss=0.134]\n",
      "Fold 3 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 17.27it/s, loss=0.105]\n",
      "Fold 3 Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 17.29it/s, loss=0.0955]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 17.19it/s, loss=1.19]\n",
      "Fold 4 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.32it/s, loss=0.985]\n",
      "Fold 4 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.25it/s, loss=0.783]\n",
      "Fold 4 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.08it/s, loss=0.622]\n",
      "Fold 4 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 17.26it/s, loss=0.465]\n",
      "Fold 4 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 17.23it/s, loss=0.391]\n",
      "Fold 4 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 17.22it/s, loss=0.334]\n",
      "Fold 4 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 17.02it/s, loss=0.29] \n",
      "Fold 4 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 17.38it/s, loss=0.248]\n",
      "Fold 4 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 17.32it/s, loss=0.192]\n",
      "Fold 4 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 17.30it/s, loss=0.137]\n",
      "Fold 4 Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 17.12it/s, loss=0.117]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 17.06it/s, loss=1.12]\n",
      "Fold 5 Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 17.52it/s, loss=0.925]\n",
      "Fold 5 Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 17.44it/s, loss=0.779]\n",
      "Fold 5 Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 17.30it/s, loss=0.577]\n",
      "Fold 5 Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 17.18it/s, loss=0.451]\n",
      "Fold 5 Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 17.51it/s, loss=0.308]\n",
      "Fold 5 Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 17.39it/s, loss=0.228]\n",
      "Fold 5 Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 17.31it/s, loss=0.184]\n",
      "Fold 5 Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 17.11it/s, loss=0.16]  \n",
      "Fold 5 Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 17.51it/s, loss=0.111]\n",
      "Fold 5 Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 17.48it/s, loss=0.105]\n",
      "Fold 5 Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 17.33it/s, loss=0.0925]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 6 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to milyiyo-distilbert-base-uncased-finetuned-amazon-review_label.txt\n",
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.88it/s, loss=1.08]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.95it/s, loss=1.11]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.96it/s, loss=1.23]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.91it/s, loss=1.07]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.92it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.96it/s, loss=1.12]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.92it/s, loss=1.17]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.93it/s, loss=1.09]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 10.05it/s, loss=1.22]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.90it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.98it/s, loss=1.15]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.92it/s, loss=1.09]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.03it/s, loss=1.03]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.95it/s, loss=1.1] \n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.01it/s, loss=1]   \n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.99it/s, loss=0.951]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.03it/s, loss=1.19]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.02it/s, loss=1.03]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.96it/s, loss=0.869]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.99it/s, loss=1.14]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.01it/s, loss=0.975]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.97it/s, loss=0.853]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.01it/s, loss=1.08]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.97it/s, loss=0.908]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.94it/s, loss=0.684]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.98it/s, loss=1.13]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.96it/s, loss=0.978]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.94it/s, loss=0.845]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.00it/s, loss=1.09]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.92it/s, loss=0.963]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.00it/s, loss=0.911]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.90it/s, loss=1.22]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.02it/s, loss=1.21]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.96it/s, loss=1.1] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.80it/s, loss=1.15]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.96it/s, loss=0.988]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.19it/s, loss=0.796]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  6.36it/s, loss=1.16]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  6.21it/s, loss=0.952]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  6.88it/s, loss=0.85] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.90it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.95it/s, loss=0.926]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.98it/s, loss=0.807]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.01it/s, loss=0.61] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.95it/s, loss=1.08]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.99it/s, loss=0.999]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.98it/s, loss=0.876]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  8.95it/s, loss=0.704]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.01it/s, loss=1.11]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.96it/s, loss=0.998]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.95it/s, loss=0.93] \n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  8.93it/s, loss=0.788]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.94it/s, loss=1.12]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.99it/s, loss=1.2] \n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.03it/s, loss=1.22]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  8.95it/s, loss=1.06]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.01it/s, loss=1.1] \n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.92it/s, loss=1.03] \n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.04it/s, loss=0.896]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  8.99it/s, loss=0.828]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.97it/s, loss=1.17]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.96it/s, loss=0.966]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.93it/s, loss=0.724]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  8.92it/s, loss=0.711]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.94it/s, loss=1.07]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.94it/s, loss=0.856]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.93it/s, loss=0.784]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  8.98it/s, loss=0.566]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.92it/s, loss=1.18]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.97it/s, loss=1.02]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.95it/s, loss=0.915]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  8.96it/s, loss=0.814]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.99it/s, loss=1.11]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.99it/s, loss=0.946]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 10.00it/s, loss=0.732]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 10.14it/s, loss=0.575]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.89it/s, loss=1.08]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.98it/s, loss=0.974]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.93it/s, loss=0.867]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  8.91it/s, loss=0.868]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.97it/s, loss=1.2] \n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.00it/s, loss=1.09]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.93it/s, loss=1.03]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.02it/s, loss=1.08]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  8.92it/s, loss=0.975]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  8.91it/s, loss=1.06] \n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  8.94it/s, loss=0.981]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.02it/s, loss=1]    \n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  8.89it/s, loss=0.991]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  6.45it/s, loss=1.17]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  6.26it/s, loss=1.04]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  6.27it/s, loss=0.931]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  6.15it/s, loss=0.833]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  6.14it/s, loss=0.754]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  6.18it/s, loss=0.623]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  6.18it/s, loss=0.463]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.99it/s, loss=0.352]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  5.90it/s, loss=0.256]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  6.20it/s, loss=1.21]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  6.13it/s, loss=1.06]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  6.14it/s, loss=0.992]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  6.18it/s, loss=0.773]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  6.09it/s, loss=0.649]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  6.14it/s, loss=0.526]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  6.19it/s, loss=0.49] \n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  6.26it/s, loss=0.531]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  6.12it/s, loss=0.617]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  6.21it/s, loss=1.12]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  6.17it/s, loss=0.942]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  6.14it/s, loss=0.836]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  6.13it/s, loss=0.607]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  6.12it/s, loss=0.43] \n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  6.11it/s, loss=0.327]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  6.07it/s, loss=0.236]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  6.16it/s, loss=0.17] \n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  6.13it/s, loss=0.116]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.96it/s, loss=1.07]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  6.22it/s, loss=1.04] \n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  5.88it/s, loss=1.1] \n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  5.86it/s, loss=1.08]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  5.90it/s, loss=1.02] \n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  5.98it/s, loss=0.977]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  6.01it/s, loss=1.07]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.88it/s, loss=0.818]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  5.90it/s, loss=0.754]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.91it/s, loss=1.18]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  6.04it/s, loss=0.985]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  6.06it/s, loss=0.865]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  6.26it/s, loss=0.704]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  6.19it/s, loss=0.522]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  6.23it/s, loss=0.357]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  5.75it/s, loss=0.263]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.99it/s, loss=0.183]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  6.14it/s, loss=0.13] \n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=1.14]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=0.976]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  5.70it/s, loss=0.87] \n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  5.73it/s, loss=0.653]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=0.507]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=0.374]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  5.82it/s, loss=0.344]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.79it/s, loss=0.211]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.183]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=1.19]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  5.74it/s, loss=1.19]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  5.73it/s, loss=1.08]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  5.75it/s, loss=1.05]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=1.02] \n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=1.01]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=0.841]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=0.627]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=0.499]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  6.32it/s, loss=1.24]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  6.28it/s, loss=1.17]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  6.29it/s, loss=1.06] \n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  6.32it/s, loss=1.03]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  6.37it/s, loss=0.909]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  6.43it/s, loss=0.723]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  6.34it/s, loss=0.596]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  6.42it/s, loss=0.532]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  6.40it/s, loss=0.429]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.74it/s, loss=1.17]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  5.78it/s, loss=0.96] \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  5.74it/s, loss=0.787]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  5.73it/s, loss=0.601]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:03<00:00,  5.64it/s, loss=0.548]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  5.73it/s, loss=0.441]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=0.35] \n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=0.214]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:03<00:00,  5.65it/s, loss=0.188]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-base-v2 | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=1.12]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=0.899]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=0.812]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  5.70it/s, loss=0.722]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  5.70it/s, loss=0.608]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  5.73it/s, loss=0.513]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  5.81it/s, loss=0.378]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.75it/s, loss=0.3]  \n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=0.23] \n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:02<00:00,  5.70it/s, loss=0.212]\n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=0.198]\n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:02<00:00,  5.72it/s, loss=0.279]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.80it/s, loss=1.14]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=1.04]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.995]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.935]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  5.71it/s, loss=0.901]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=0.828]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:03<00:00,  5.65it/s, loss=0.629]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.77it/s, loss=0.478]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  5.74it/s, loss=0.669]\n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.395]\n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:03<00:00,  5.65it/s, loss=0.271]\n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:03<00:00,  5.65it/s, loss=0.253]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.82it/s, loss=1.12]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  5.73it/s, loss=0.979]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=0.85] \n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=0.758]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.607]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:03<00:00,  5.62it/s, loss=0.55] \n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:03<00:00,  5.64it/s, loss=0.371]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=0.29] \n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  5.71it/s, loss=0.284]\n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:02<00:00,  5.78it/s, loss=0.211]\n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:02<00:00,  5.70it/s, loss=0.144]\n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:03<00:00,  5.63it/s, loss=0.132]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=1.1] \n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  5.88it/s, loss=0.933]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  6.29it/s, loss=0.718]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  6.27it/s, loss=0.502]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=0.489]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.369]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.427]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.328]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  5.78it/s, loss=0.275]\n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:02<00:00,  5.75it/s, loss=0.251]\n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=0.329]\n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=0.295]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=1.13]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  5.77it/s, loss=0.997]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  5.78it/s, loss=0.886]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:03<00:00,  5.64it/s, loss=0.792]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.736]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=0.647]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:03<00:00,  5.65it/s, loss=0.534]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:03<00:00,  5.65it/s, loss=0.423]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:03<00:00,  5.65it/s, loss=0.363]\n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:02<00:00,  5.75it/s, loss=0.319]\n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:02<00:00,  5.78it/s, loss=0.318]\n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.391]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=1.13]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  5.70it/s, loss=0.894]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  5.78it/s, loss=0.701]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  5.71it/s, loss=0.53] \n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  5.67it/s, loss=0.496]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:03<00:00,  5.62it/s, loss=0.377]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  5.68it/s, loss=0.302]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=0.284]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.197]\n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:03<00:00,  5.65it/s, loss=0.155]\n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:02<00:00,  5.81it/s, loss=0.106]\n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:02<00:00,  5.76it/s, loss=0.0845]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=1.12]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.938]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.798]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  5.73it/s, loss=0.639]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  5.81it/s, loss=0.47] \n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  5.69it/s, loss=0.343]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:03<00:00,  5.65it/s, loss=0.305]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:03<00:00,  5.62it/s, loss=0.243]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:03<00:00,  5.56it/s, loss=0.166]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:03<00:00,  5.27it/s, loss=0.117] \n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:03<00:00,  5.66it/s, loss=0.104] \n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:02<00:00,  5.78it/s, loss=0.11]  \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:02<00:00,  6.61it/s, loss=1.13]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:02<00:00,  7.95it/s, loss=0.884]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:02<00:00,  8.00it/s, loss=0.768]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:02<00:00,  7.97it/s, loss=0.617]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:02<00:00,  8.02it/s, loss=0.474]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:02<00:00,  8.00it/s, loss=0.322]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:02<00:00,  8.04it/s, loss=0.306]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:02<00:00,  8.08it/s, loss=0.263]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:02<00:00,  8.00it/s, loss=0.188]\n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:02<00:00,  8.46it/s, loss=0.144]\n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:02<00:00,  8.41it/s, loss=0.14] \n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  8.81it/s, loss=0.161]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.80it/s, loss=1.16]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.84it/s, loss=1.17]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.88it/s, loss=1.03] \n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.79it/s, loss=1.01]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.83it/s, loss=0.912]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.90it/s, loss=0.858]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.92it/s, loss=0.773]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.83it/s, loss=0.653]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.84it/s, loss=0.526]\n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.87it/s, loss=0.425]\n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.80it/s, loss=0.3]  \n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.85it/s, loss=0.211]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.85it/s, loss=1.24]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  8.80it/s, loss=0.909]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  8.93it/s, loss=0.709]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  8.82it/s, loss=0.577]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  8.84it/s, loss=0.436]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  8.77it/s, loss=0.387]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  8.81it/s, loss=0.296]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  8.82it/s, loss=0.241]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  8.87it/s, loss=0.227]\n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  8.83it/s, loss=0.216]\n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  8.87it/s, loss=0.154]\n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  8.83it/s, loss=0.12] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to albert-albert-base-v2_label.txt\n",
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=1.21]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=1.09]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=1.27]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=1.1] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=1.14]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.16it/s, loss=1.2] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.16it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.16it/s, loss=1.14]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.36it/s, loss=1.13]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.16it/s, loss=1.11]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=1.19]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.19it/s, loss=1.01] \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=0.956]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=1.15]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=1.14]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=1.12]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=1.27]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=0.977]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=0.929]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=1.15]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=0.946]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=0.74] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=1.1] \n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=0.996]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=0.837]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.15it/s, loss=1.09]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.17it/s, loss=0.975]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.16it/s, loss=0.797]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.31it/s, loss=1.15]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.27it/s, loss=1.08]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.24it/s, loss=1.1] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.1] \n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.23it/s, loss=0.959]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.25it/s, loss=0.966]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.37it/s, loss=1.22]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.38it/s, loss=1.01] \n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.36it/s, loss=0.875]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.24it/s, loss=1.18]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.21]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.25it/s, loss=1.09]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.25it/s, loss=1.21]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=0.94] \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.21]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.26it/s, loss=1.12]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.02]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.956]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.25it/s, loss=0.863]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.08]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.23it/s, loss=1.01]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.25it/s, loss=0.971]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=0.981]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.15]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.13it/s, loss=0.972]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.843]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.875]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.05]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=1.06]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.969]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=0.823]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=1.15]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=1]   \n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=0.886]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=0.71] \n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.14]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.06]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=0.98] \n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.894]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=1.19]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.23]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=1.12]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.09] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.24it/s, loss=1.13]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.25it/s, loss=1.04]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.39it/s, loss=1.09]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.23it/s, loss=1.23]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.12]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.13]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.06] \n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.03] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.12]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.01]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.13it/s, loss=1.06]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=0.999]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.977]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.901]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.88] \n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=0.799]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.1] \n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.956]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=0.985]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=0.887]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.763]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.653]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.461]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.13it/s, loss=0.563]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.443]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.2] \n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.19]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.13it/s, loss=1.07] \n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.06]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.24it/s, loss=1.02]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.26it/s, loss=1.03]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=0.997]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.04]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.02]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.15]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.03]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.991]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.901]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=0.732]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.607]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.492]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.344]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.347]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.12]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.957]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.767]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.663]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.499]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.32it/s, loss=0.371]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.358]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.275]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.268]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.18]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=0.972]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.9]  \n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.83] \n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.722]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.57] \n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.443]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.423]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.342]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.2] \n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.05]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.953]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.874]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.789]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.59] \n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.492]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.412]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.403]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.15]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.993]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.02] \n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.84] \n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:08<00:00,  2.03it/s, loss=0.643]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.506]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.05it/s, loss=1.21]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:08<00:00,  2.05it/s, loss=1.03] \n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:08<00:00,  2.05it/s, loss=1.05]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.14]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.31it/s, loss=0.993]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.892]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.26it/s, loss=0.76] \n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.25it/s, loss=0.621]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.26it/s, loss=0.539]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.24it/s, loss=0.35] \n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.23it/s, loss=0.293]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.23it/s, loss=0.218]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=1.09]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=1.1] \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=1.07]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.08] \n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=1.01]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=1.06]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.02] \n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.03]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.01]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: albert/albert-large-v2 | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.18]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=0.992]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=0.788]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=0.713]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.13it/s, loss=0.674]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=0.554]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.44] \n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:08<00:00,  2.07it/s, loss=0.352]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.33] \n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=0.351]\n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:08<00:00,  2.05it/s, loss=0.254]\n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.223]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.07it/s, loss=1.17]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.956]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.07it/s, loss=0.994]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.902]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:08<00:00,  2.07it/s, loss=0.873]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=0.813]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.721]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=0.632]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.559]\n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:08<00:00,  2.07it/s, loss=0.571]\n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:08<00:00,  2.07it/s, loss=0.362]\n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=0.255]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.13]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.979]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=0.872]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.23it/s, loss=1.34]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.1]  \n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.08]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.23it/s, loss=0.995]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.02]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.02] \n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.03]\n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.04] \n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.07]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.15]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.04] \n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.16]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.05]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.07]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.08]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.09]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.08]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.23it/s, loss=1.03]\n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.25it/s, loss=1.03]\n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.33it/s, loss=1.01]\n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.1] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.2] \n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.43]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.15]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.09]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.14]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.24it/s, loss=1.03]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.08]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.08]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.06] \n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.04]\n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.02]\n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.01] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.15]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.01] \n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.861]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.672]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.541]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.371]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.383]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.429]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.398]\n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.46] \n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.312]\n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.257]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.07it/s, loss=1.14]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=1.04]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.941]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.04it/s, loss=0.851]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:08<00:00,  2.05it/s, loss=0.815]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.631]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.07it/s, loss=0.583]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.46] \n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.336]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.239]\n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.283]\n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:08<00:00,  2.05it/s, loss=0.197]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=1.14]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.986]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.04it/s, loss=0.903]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.718]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:08<00:00,  2.05it/s, loss=0.518]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=0.482]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=0.353]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=0.529]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.3] \n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.13]\n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.13it/s, loss=1.08]\n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.08]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.09]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.1] \n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=0.976]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.942]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.7]  \n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=0.54] \n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=0.428]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.353]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=0.391]\n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=0.341]\n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=0.314]\n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=0.227]\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.06it/s, loss=1.07]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=1]    \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.05it/s, loss=0.985]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.05]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.04]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:08<00:00,  2.09it/s, loss=1.06] \n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.08] \n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.01] \n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.05]\n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s, loss=1.04] \n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=1.04]\n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.06]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to albert-albert-large-v2_label.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=1.1] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.25]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.21]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.2] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.17]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:10<00:00,  1.61it/s, loss=1.14]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.18]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.25]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:09<00:00,  1.76it/s, loss=1]    \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=0.984]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.16]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=1.02] \n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=0.937]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=1.23]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:08<00:00,  2.03it/s, loss=0.97] \n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.796]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.13]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.941]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.774]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.17]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=1.04]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.877]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.21]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.05] \n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.863]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=1.14]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=1.01] \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.94] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.1] \n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.03]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.46it/s, loss=0.812]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.2] \n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.08]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=0.916]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=1.28]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.46it/s, loss=1.04]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.52it/s, loss=0.921]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=1.14]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.944]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.77] \n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.46it/s, loss=0.648]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:10<00:00,  1.55it/s, loss=1.18]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=1]   \n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.946]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.782]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.2] \n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.968]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.961]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.42it/s, loss=0.855]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=1.18]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.04] \n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.87] \n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.674]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.17]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=1.03]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.03]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.42it/s, loss=1.03] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.24]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.06]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.04] \n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.808]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.11]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.04]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.894]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.804]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=1.19]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.02] \n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.813]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.624]\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.54it/s, loss=1.24]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=1.03] \n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.935]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.745]\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.11]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.05] \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1]    \n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.934]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.996]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.814]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.613]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.454]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.29] \n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.177]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.137]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.0779]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.46it/s, loss=1.12]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=1.04] \n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.958]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.657]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.436]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.31] \n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.189]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.129]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.115]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=1.16]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.942]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.799]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=0.678]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.536]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=0.442]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.314]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.299]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=0.244]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=1.13]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=0.981]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.887]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=0.7]  \n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.457]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.305]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.218]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.45it/s, loss=0.157]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.45it/s, loss=0.135]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.25]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.973]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.889]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.682]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.408]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.246]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.18] \n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:12<00:00,  1.42it/s, loss=0.136]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.118]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.18]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.03] \n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.848]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=0.625]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.392]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=0.259]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.46it/s, loss=0.283]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:10<00:00,  1.56it/s, loss=0.283]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.53it/s, loss=0.13] \n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=1.23]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.52it/s, loss=1.05] \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.46it/s, loss=0.997]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=0.846]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=0.504]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.325]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.18] \n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=0.166]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.112]\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=1.27]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=1.06] \n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.937]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.789]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.511]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.346]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.239]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.143]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.0939]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=1.16]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=0.978]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.847]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.939]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=1.1] \n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=1.09]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=1.06]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.05]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=1.03]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=1.2] \n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.983]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=0.81] \n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.56] \n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.311]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.292]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.247]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=0.146]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.0855]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: microsoft/deberta-v3-large | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=1.05] \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.946]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=0.736]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.56] \n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.28] \n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.252]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=0.116]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.0896]\n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.0731]\n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.063] \n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.0445]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=1.24]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.42it/s, loss=1.01] \n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.833]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.745]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.7]  \n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=0.589]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.53it/s, loss=0.502]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.52it/s, loss=0.351]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.328]\n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:11<00:00,  1.52it/s, loss=0.418]\n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:11<00:00,  1.52it/s, loss=0.217]\n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:11<00:00,  1.52it/s, loss=0.178]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=1.28]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.98] \n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.827]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.691]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.462]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.302]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.183]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.0975]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.0702]\n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.0617]\n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=0.0494]\n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.0421]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.06] \n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.952]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=1.06]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.45it/s, loss=1.04]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.05]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.01]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.03]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.04] \n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.05] \n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.03]\n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.01]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=1.14]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=1.03]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.89] \n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.95] \n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.05] \n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.05]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=1.03]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=1.08]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.01]\n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1]   \n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.01]\n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1]   \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.24]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=1.05]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.965]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.752]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=0.647]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=0.466]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.562]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.35] \n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.27] \n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.191]\n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.126]\n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:11<00:00,  1.43it/s, loss=0.11]  \n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=1.18]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=1.08]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=1.03] \n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.833]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.549]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.478]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.301]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.216]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.238]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.224]\n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.159]\n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.116] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:10<00:00,  1.57it/s, loss=1.16]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.958]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.673]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:11<00:00,  1.48it/s, loss=0.444]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.238]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.27] \n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.205]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.134]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:11<00:00,  1.50it/s, loss=0.104]\n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.0796]\n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.0569]\n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:11<00:00,  1.49it/s, loss=0.0408]\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:11<00:00,  1.51it/s, loss=1.15]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:11<00:00,  1.44it/s, loss=1.01]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.42it/s, loss=0.808]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.42it/s, loss=0.565]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.387]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.189]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.122] \n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.119]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.0807]\n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.0595]\n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.0497]\n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:12<00:00,  1.41it/s, loss=0.0486]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:12<00:00,  1.38it/s, loss=1.17]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=1.03] \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=0.921]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.697]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.486]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.369]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:12<00:00,  1.39it/s, loss=0.261]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:11<00:00,  1.47it/s, loss=0.251]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.181]\n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.153]\n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.131]\n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:12<00:00,  1.40it/s, loss=0.0916]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to microsoft-deberta-v3-large_label.txt\n",
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.02it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.01it/s, loss=1.16]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.02it/s, loss=1.2] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.02it/s, loss=1.27]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.02it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.02it/s, loss=1.21]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.01it/s, loss=1.38]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.05it/s, loss=1.13]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.39]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.31]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.13]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.09]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.19]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.1] \n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.02] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.2] \n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.1] \n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.04]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.18]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.12]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.01]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.15]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.04]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.1] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.23]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.13]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.1]  \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.14]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.25it/s, loss=1.09]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=0.988]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.13]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.06]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.951]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.14]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.01] \n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.962]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.12]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.974]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=0.961]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.16]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.12]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.936]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.861]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.2] \n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.15]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.03]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.04]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.28]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.05]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.993]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.927]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.08]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.996]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.953]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.24]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.08]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.08]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.06]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.13it/s, loss=1.24]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.12]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.11]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.06]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.27]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.21]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.11]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.901]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.15]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.32it/s, loss=1.07]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.04]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.94] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.24]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.08]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.03]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.892]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=1.2] \n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.18]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.06]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.08]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.32]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.12]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.06]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.03] \n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.879]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.818]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.619]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.546]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.452]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.12]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.08]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.03]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.03] \n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1]    \n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.922]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.832]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.667]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.01] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.09]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.05]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.97] \n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.942]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.686]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.458]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.367]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.29] \n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.328]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.02]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.07]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.865]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.865]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.33it/s, loss=0.535]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.312]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.164]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.167]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.21]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.07]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.13]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.04]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.08]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.11] \n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.05]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.06] \n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.01]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.24]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.08]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.03]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.08]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.09]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.17]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.05]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.05]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.05]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.33]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.08]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.08]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.13]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.03]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.893]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.89] \n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=0.745]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.523]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.25]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.19]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.12]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.01] \n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.05]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.01] \n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.919]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.811]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.653]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.16]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.07]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.08] \n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.30it/s, loss=0.942]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=0.755]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.698]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.498]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.497]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.264]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.28]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.12]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.13it/s, loss=1.07]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.981]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.02] \n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.02]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.949]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.13it/s, loss=0.885]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.71] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: FacebookAI/roberta-large | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.22]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.2] \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.19]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.06]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.11] \n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.975]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.898]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.853]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.819]\n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.733]\n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.664]\n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.513]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=1.22]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.09]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=1.04]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.02] \n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.945]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.808]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.656]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.553]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.421]\n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.344]\n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=0.196]\n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.141]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.2] \n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.14]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.07] \n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.03]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.946]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.29it/s, loss=0.976]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.23it/s, loss=0.75] \n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.542]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.339]\n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=0.203]\n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.12] \n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.0865]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.21]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.04]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.06]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=0.996]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.12]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.04] \n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.887]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.806]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.704]\n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.504]\n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=0.423]\n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=0.222]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.2] \n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.13]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.14]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.27]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s, loss=1.07] \n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.11]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s, loss=1.03]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.12]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.07]\n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.08] \n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.03]\n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.21it/s, loss=1.05]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.2] \n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.16it/s, loss=1.17]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s, loss=1.11]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s, loss=1.03] \n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.17it/s, loss=1.08]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=0.989]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=0.929]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=0.776]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.15it/s, loss=0.545]\n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=0.554]\n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.14it/s, loss=0.426]\n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:08<00:00,  2.12it/s, loss=0.232]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:08<00:00,  2.11it/s, loss=1.14]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.34it/s, loss=1.17]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:06<00:00,  2.48it/s, loss=1.01] \n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.37it/s, loss=0.917]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.39it/s, loss=0.722]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.37it/s, loss=0.548]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.41it/s, loss=0.37] \n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.41it/s, loss=0.338]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.39it/s, loss=0.223]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:07<00:00,  2.41it/s, loss=0.196]\n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:07<00:00,  2.38it/s, loss=0.169] \n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:07<00:00,  2.41it/s, loss=0.209]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:07<00:00,  2.37it/s, loss=1.15]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:07<00:00,  2.41it/s, loss=1.12]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:07<00:00,  2.40it/s, loss=1.05]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:07<00:00,  2.39it/s, loss=0.965]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:07<00:00,  2.40it/s, loss=0.819]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:07<00:00,  2.39it/s, loss=0.858]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:07<00:00,  2.41it/s, loss=0.749]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:07<00:00,  2.38it/s, loss=0.5]  \n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:07<00:00,  2.40it/s, loss=0.285]\n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:06<00:00,  2.76it/s, loss=0.195]\n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  3.09it/s, loss=0.152]\n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  3.08it/s, loss=0.107]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.13it/s, loss=1.13]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.12it/s, loss=1.08] \n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.14it/s, loss=1.08] \n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  3.12it/s, loss=0.995]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  3.13it/s, loss=0.846]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  3.13it/s, loss=0.681]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  3.13it/s, loss=0.526]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  3.13it/s, loss=0.285]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  3.11it/s, loss=0.228]\n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  3.12it/s, loss=0.134]\n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  3.13it/s, loss=0.155] \n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  3.23it/s, loss=0.114] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.15it/s, loss=1.24]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=1.13]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.18it/s, loss=1.08]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  3.08it/s, loss=1.01]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  3.15it/s, loss=0.872]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  3.15it/s, loss=0.906]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  3.15it/s, loss=0.808]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  3.15it/s, loss=0.553]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  3.14it/s, loss=0.441]\n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  3.14it/s, loss=0.298]\n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  3.14it/s, loss=0.183]\n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  3.15it/s, loss=0.137] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to FacebookAI-roberta-large_label.txt\n",
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.43it/s, loss=1.29]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.46it/s, loss=1.13]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.42it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.39it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.30it/s, loss=1.28]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.31it/s, loss=1.23]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.38it/s, loss=1.27]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.42it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.37it/s, loss=1.22]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.35it/s, loss=1.24]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=0.961]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=0.779]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.42it/s, loss=1.25]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=0.916]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=0.818]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.35it/s, loss=1.17]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=1.09]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.43it/s, loss=0.905]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.36it/s, loss=1.17]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.39it/s, loss=0.934]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.32it/s, loss=0.739]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.43it/s, loss=1.16]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.994]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=0.882]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.40it/s, loss=1.26]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=1.03] \n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=0.846]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.41it/s, loss=1.22]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.44it/s, loss=1]    \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.44it/s, loss=0.907]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.38it/s, loss=1.31]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=0.973]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.37it/s, loss=0.886]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=1.25]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.05] \n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.933]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.29it/s, loss=1.25]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.43it/s, loss=0.978]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.36it/s, loss=0.786]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.43it/s, loss=1.16]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.934]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.40it/s, loss=0.822]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=0.643]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.31it/s, loss=1.16]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.942]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=0.805]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=0.687]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=1.38]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=1.03]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.965]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.771]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=1.08]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=0.937]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.829]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.50it/s, loss=0.605]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.50it/s, loss=1.32]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.996]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=0.902]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=0.782]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.41it/s, loss=1.2] \n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=1.01]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.44it/s, loss=0.95] \n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=0.875]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=1.28]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=1.02] \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.865]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.48it/s, loss=0.669]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.31it/s, loss=1.12]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.33it/s, loss=0.927]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=0.814]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=0.707]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=1.31]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=1.02]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.979]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.732]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.44it/s, loss=1.22]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.37it/s, loss=1]    \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.44it/s, loss=0.804]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.37it/s, loss=0.616]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.46it/s, loss=1.18]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.967]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=0.806]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.631]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.48it/s, loss=0.523]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.418]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.43it/s, loss=0.334]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.263]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.48it/s, loss=0.224]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.43it/s, loss=1.16]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.37it/s, loss=0.939]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=0.802]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=0.576]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=0.464]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=0.366]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.46it/s, loss=0.284]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=0.216]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.165]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=1.33]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.931]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=0.757]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=0.581]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=0.48] \n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.48it/s, loss=0.328]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.258]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.44it/s, loss=0.221]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.198]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.42it/s, loss=1.33]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=1.07]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.50it/s, loss=0.935]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=0.802]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.686]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=0.504]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=0.421]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.40it/s, loss=0.315]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.279]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.34it/s, loss=1.19]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.43it/s, loss=0.988]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.79it/s, loss=0.869]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.91it/s, loss=0.697]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.76it/s, loss=0.549]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.462]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.92it/s, loss=0.328]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.86it/s, loss=0.253]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.88it/s, loss=0.186]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.13it/s, loss=1.12]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1]   \n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.857]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.726]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.54] \n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.42] \n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.288]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.214]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.177]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=1.37]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.98] \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=0.847]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.786]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.655]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.523]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.453]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.336]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.282]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=1.19]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.998]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.874]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.687]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.516]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.41] \n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.269]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.199]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.161]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=1.36]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.78it/s, loss=1.02]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.864]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.725]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.531]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.464]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.79it/s, loss=0.355]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.309]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.76it/s, loss=0.248]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=1.15]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=1]    \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.926]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.767]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.658]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.549]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.463]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.379]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.335]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: google-bert/bert-base-uncased | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=1.23]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=1.04]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.903]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.778]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.68] \n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.575]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.475]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.419]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.4]  \n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.28] \n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.22] \n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.173]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=1.03]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.938]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.784]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.626]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.453]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.35] \n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.276]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.241]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.223]\n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.166]\n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.127]\n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.112] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.11]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=1.03] \n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.9]  \n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.796]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.50it/s, loss=0.592]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.455]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.351]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.301]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.242]\n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.192]\n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.163]\n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.146]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.34]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.02]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.823]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.683]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.626]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.492]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.4]  \n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.305]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.253]\n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.217]\n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.178]\n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.173]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=1.3] \n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=1.01]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.935]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.738]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.648]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.501]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.481]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.352]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.339]\n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.288]\n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.252]\n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.225]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.38it/s, loss=1.22]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=1.03]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.935]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.744]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.554]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.4]  \n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.279]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.239]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.199]\n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.2]  \n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.162]\n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.138]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=1.28]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=1.03] \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.876]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.675]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.523]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.355]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.243]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.172]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.145]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.108]\n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.0832]\n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.0726]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=1.18]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=0.97] \n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.74] \n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=0.552]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.471]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.371]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.346]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.25] \n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.193]\n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.174]\n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.138]\n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.14] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=1.14]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.77it/s, loss=0.972]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.856]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.78it/s, loss=0.73] \n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.525]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.79it/s, loss=0.456]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.373]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.74it/s, loss=0.3]  \n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.245]\n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.74it/s, loss=0.21] \n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.154]\n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.114]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.40it/s, loss=1.27]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.988]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.46it/s, loss=0.825]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.706]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.534]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.4]  \n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.321]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.231]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.196]\n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.188]\n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.139]\n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.122]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to google-bert-bert-base-uncased_label.txt\n",
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=1.25]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=1.23]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.25]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.23]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.32]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.48it/s, loss=1.14]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.08]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=1.27]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=1.31]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.48it/s, loss=1.21]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=1.15]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.9]  \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.728]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=1.17]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.991]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.904]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=1.1] \n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.01]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.917]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.23]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.904]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.718]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=1.26]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.971]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.952]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=1.11]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=0.896]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.685]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.44it/s, loss=1.13]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.899]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.704]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=1.21]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.97] \n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.825]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.2] \n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.963]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.81it/s, loss=0.851]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.41it/s, loss=1.12]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.921]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.743]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.02]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.928]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.76] \n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.637]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=1.11]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.913]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.805]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.552]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=1.18]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.965]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.878]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.68] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=1.19]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.9]  \n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.749]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.564]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.18]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.979]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.816]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.649]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.14]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.885]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.657]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.452]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.16]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.894]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.703]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.528]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.50it/s, loss=1.42]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.981]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.48it/s, loss=0.84] \n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.718]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.74it/s, loss=1.16]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.923]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.77it/s, loss=0.722]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.512]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=1.19]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.978]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.825]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.645]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.48it/s, loss=1.3] \n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.974]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.783]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.655]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.492]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.411]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.315]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.239]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.186]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.19]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=1.07]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.74it/s, loss=0.91] \n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.759]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.534]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.379]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.248]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.189]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.127]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.44it/s, loss=1.29]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.991]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.809]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.664]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.562]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.426]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.302]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.293]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.192]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=1.19]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.88] \n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.64] \n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.457]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.394]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.309]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.248]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.199]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.175]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=1.37]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=0.934]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.50it/s, loss=0.849]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.701]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.582]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.445]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.337]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.263]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.259]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.2] \n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=1.04] \n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.829]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.715]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.577]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.421]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.50it/s, loss=0.297]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.229]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.169]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.13]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.943]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.756]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.559]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.431]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.326]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.257]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.182]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.128] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=1.2] \n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.985]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.883]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.74] \n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.61] \n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.487]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.371]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.308]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.23] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=1.14]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.77it/s, loss=0.972]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.80it/s, loss=0.703]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.76it/s, loss=0.568]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.74it/s, loss=0.435]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.79it/s, loss=0.337]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.74it/s, loss=0.27] \n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.81it/s, loss=0.207]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.15] \n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=1.19]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.01] \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.757]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.615]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.468]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.363]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.267]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.211]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.18] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ProsusAI/finbert | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=1.09]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.897]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.717]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.576]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.452]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.445]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.249]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.195]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=0.147]\n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.125]\n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.11] \n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.0889]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=1.3] \n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=1.01] \n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.85] \n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.629]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.423]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.308]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.22] \n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.199]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.131]\n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.092] \n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.0743]\n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.0634]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=1.31]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.926]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.741]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.609]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.46] \n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.309]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.229]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.189]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.134]\n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.121]\n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.121] \n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.0857]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=1.28]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.929]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.775]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.597]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.432]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.329]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.259]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.168]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.153]\n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.117]\n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.0942]\n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.079] \n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.24]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.911]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.757]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.556]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.396]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.292]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.209]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.194]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.154]\n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.77it/s, loss=0.118]\n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.113] \n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.0875]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.16]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.992]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.911]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.691]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.52] \n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.401]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.334]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.239]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.176]\n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.143]\n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.116]\n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.123] \n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.50it/s, loss=1.15]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=1]    \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.878]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.669]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.502]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.349]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.246]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.215]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.166]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.139] \n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.117] \n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.0895]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.22]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.979]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.742]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.519]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.403]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.283]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.221]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.176]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.142]\n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.0979]\n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.0836]\n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.0681]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.24]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.76it/s, loss=1.01] \n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.816]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.68] \n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.55] \n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.416]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.313]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.235]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.79it/s, loss=0.186]\n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.149]\n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.81it/s, loss=0.137]\n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.101] \n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=1.42]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.939]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.828]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.719]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.551]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.46] \n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.306]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.208]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.135]\n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.11] \n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.093] \n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.109] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to ProsusAI-finbert_label.txt\n",
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.05it/s, loss=1.13]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.27it/s, loss=1.18]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.19it/s, loss=1.26]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=1.25]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=1.15]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.92it/s, loss=1.18]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.26it/s, loss=1.17]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.17it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.75it/s, loss=1.22]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=1.2] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=1.2] \n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=0.951]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.54it/s, loss=0.798]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.32it/s, loss=1.14]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.35it/s, loss=0.903]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.754]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=1.21]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.36it/s, loss=0.941]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.23it/s, loss=0.842]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.03it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.60it/s, loss=0.939]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.20it/s, loss=0.82] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=1.23]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.93] \n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.24it/s, loss=0.778]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.82it/s, loss=1.15]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.47it/s, loss=0.987]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.849]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=1.17]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.43it/s, loss=0.945]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.19it/s, loss=0.799]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=1.13]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.40it/s, loss=0.953]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.63it/s, loss=0.767]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.56it/s, loss=1.18]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.74it/s, loss=0.944]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.72it/s, loss=0.836]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.07it/s, loss=1.28]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.14it/s, loss=0.947]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.766]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.19it/s, loss=1.14]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.65it/s, loss=0.964]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.55it/s, loss=0.795]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.22it/s, loss=0.631]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=1.16]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.40it/s, loss=0.943]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.37it/s, loss=0.832]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.43it/s, loss=0.713]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=1.14]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.28it/s, loss=0.94] \n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.22it/s, loss=0.804]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.41it/s, loss=0.686]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.25it/s, loss=1.2] \n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.06it/s, loss=0.977]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.50it/s, loss=0.801]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.629]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.00it/s, loss=1.2] \n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.43it/s, loss=0.936]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.805]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.48it/s, loss=0.683]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=1.17]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=0.968]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.26it/s, loss=0.834]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.17it/s, loss=0.642]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=1.19]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.05it/s, loss=0.95] \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.41it/s, loss=0.78] \n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.70it/s, loss=0.622]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=1.12]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.12it/s, loss=0.983]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.06it/s, loss=0.819]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.27it/s, loss=0.692]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.49it/s, loss=1.21]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.65it/s, loss=0.938]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.62it/s, loss=0.799]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.90it/s, loss=0.663]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.12it/s, loss=1.16]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.901]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.34it/s, loss=0.755]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.30it/s, loss=0.657]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=1.11]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.88it/s, loss=0.92] \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.32it/s, loss=0.788]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.41it/s, loss=0.615]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.24it/s, loss=0.512]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.30it/s, loss=0.406]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.40it/s, loss=0.304]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.32it/s, loss=0.262]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.35it/s, loss=0.199]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=1.12]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.927]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.854]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.697]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.569]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.31it/s, loss=0.413]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.22it/s, loss=0.302]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.35it/s, loss=0.214]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.35it/s, loss=0.167]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.19it/s, loss=1.2] \n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=1.02] \n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.61it/s, loss=0.846]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.53it/s, loss=0.7]  \n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.30it/s, loss=0.556]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.16it/s, loss=0.415]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.15it/s, loss=0.31] \n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.25it/s, loss=0.251]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.39it/s, loss=0.206]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.27it/s, loss=1.15]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.30it/s, loss=0.924]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.36it/s, loss=0.767]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.45it/s, loss=0.628]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:01<00:00, 16.95it/s, loss=0.555]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.24it/s, loss=0.409]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.24it/s, loss=0.272]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.23it/s, loss=0.218]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.31it/s, loss=0.162]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.39it/s, loss=1.13]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.23it/s, loss=0.902]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.19it/s, loss=0.779]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.37it/s, loss=0.597]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.458]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.70it/s, loss=0.348]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.49it/s, loss=0.279]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.17it/s, loss=0.237]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.37it/s, loss=0.194]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=1.2] \n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.976]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.28it/s, loss=0.878]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.761]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.46it/s, loss=0.66] \n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.30it/s, loss=0.491]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.07it/s, loss=0.377]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.20it/s, loss=0.272]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:01<00:00, 16.86it/s, loss=0.21] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.20it/s, loss=1.17]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.911]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.35it/s, loss=0.799]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.36it/s, loss=0.644]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=0.51] \n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.15it/s, loss=0.438]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.42it/s, loss=0.316]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:01<00:00, 16.99it/s, loss=0.265]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.204]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=1.18]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.22it/s, loss=0.921]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.20it/s, loss=0.79] \n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.26it/s, loss=0.626]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.07it/s, loss=0.488]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.31it/s, loss=0.348]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.07it/s, loss=0.273]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.193]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.28it/s, loss=0.135]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.59it/s, loss=1.26]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.65it/s, loss=0.969]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.73it/s, loss=0.835]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.89it/s, loss=0.669]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.63it/s, loss=0.517]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.65it/s, loss=0.408]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.48it/s, loss=0.304]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.81it/s, loss=0.251]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.67it/s, loss=0.212]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.94it/s, loss=1.22]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.30it/s, loss=0.982]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.794]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.13it/s, loss=0.631]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.39it/s, loss=0.455]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.24it/s, loss=0.349]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.23it/s, loss=0.257]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.189]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.147]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: PHILIPPUNI/distilbert-amazon-software-reviews-finetuned | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.14it/s, loss=1.22]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.37it/s, loss=0.912]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.30it/s, loss=0.776]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.34it/s, loss=0.62] \n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.37it/s, loss=0.487]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.15it/s, loss=0.377]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.52it/s, loss=0.303]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.56it/s, loss=0.238]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=0.189]\n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.36it/s, loss=0.154]\n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.56it/s, loss=0.134]\n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.119]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=1.2] \n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.43it/s, loss=0.94] \n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.20it/s, loss=0.825]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.28it/s, loss=0.706]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.38it/s, loss=0.551]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.393]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.46it/s, loss=0.279]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.47it/s, loss=0.21] \n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.20it/s, loss=0.161]\n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.39it/s, loss=0.133]\n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.36it/s, loss=0.108] \n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.31it/s, loss=0.0995]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.04it/s, loss=1.14]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.22it/s, loss=0.907]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.19it/s, loss=0.795]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.44it/s, loss=0.725]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.73it/s, loss=0.579]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=0.481]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.342]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.43it/s, loss=0.258]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.26it/s, loss=0.194]\n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.51it/s, loss=0.17] \n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.40it/s, loss=0.157]\n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.122] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.16it/s, loss=1.15]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.44it/s, loss=0.934]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.57it/s, loss=0.792]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.699]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.36it/s, loss=0.508]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.427]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.20it/s, loss=0.255]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.186]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.32it/s, loss=0.147]\n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.22it/s, loss=0.11] \n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.55it/s, loss=0.115] \n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.0745]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.42it/s, loss=1.2] \n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.35it/s, loss=0.942]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.23it/s, loss=0.783]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.30it/s, loss=0.606]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.31it/s, loss=0.545]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.50it/s, loss=0.37] \n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.41it/s, loss=0.311]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.257]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.25it/s, loss=0.247]\n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.16it/s, loss=0.211]\n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.43it/s, loss=0.15] \n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.15it/s, loss=0.131]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.16it/s, loss=1.18]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.942]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.56it/s, loss=0.821]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.43it/s, loss=0.613]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.38it/s, loss=0.505]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.63it/s, loss=0.337]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=0.248]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.175]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.26it/s, loss=0.154]\n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.02it/s, loss=0.128]\n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.40it/s, loss=0.0966]\n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:01<00:00, 16.92it/s, loss=0.0837]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.88it/s, loss=1.21]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.14it/s, loss=0.937]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.15it/s, loss=0.768]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.616]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.501]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.03it/s, loss=0.393]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.48it/s, loss=0.334]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.25it/s, loss=0.256]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.12it/s, loss=0.215]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.158]\n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:01<00:00, 16.98it/s, loss=0.126]\n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.35it/s, loss=0.109]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.15it/s, loss=1.22]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.92it/s, loss=0.987]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.35it/s, loss=0.85] \n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.27it/s, loss=0.656]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.02it/s, loss=0.502]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.31it/s, loss=0.392]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.03it/s, loss=0.333]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.41it/s, loss=0.249]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.46it/s, loss=0.196]\n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=0.169]\n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.47it/s, loss=0.136]\n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.38it/s, loss=0.109]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.78it/s, loss=1.18]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.81it/s, loss=0.913]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.66it/s, loss=0.777]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.64it/s, loss=0.625]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.91it/s, loss=0.498]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.68it/s, loss=0.376]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.71it/s, loss=0.314]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.65it/s, loss=0.222]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.70it/s, loss=0.16] \n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.80it/s, loss=0.161]\n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.39it/s, loss=0.117]\n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.55it/s, loss=0.129]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at PHILIPPUNI/distilbert-amazon-software-reviews-finetuned and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.06it/s, loss=1.17]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.945]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.24it/s, loss=0.819]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.652]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.38it/s, loss=0.532]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.47it/s, loss=0.409]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.39it/s, loss=0.277]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.204]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.35it/s, loss=0.156]\n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.20it/s, loss=0.121]\n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=0.0921]\n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.50it/s, loss=0.0743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to PHILIPPUNI-distilbert-amazon-software-reviews-finetuned_label.txt\n",
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=1.19]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=1.21]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=1.14]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=1.39]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=1.11]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=1.39]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.48it/s, loss=1.27]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=1.23]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=1.2] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=1.2] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.25]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.936]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.771]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=1.25]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.948]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.796]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.22]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.974]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.862]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=1.32]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=0.998]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.831]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=1.16]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.984]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.817]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.16]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.979]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.684]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=1.37]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=1.07]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.856]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=1.3] \n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.999]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.861]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=1.32]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.76it/s, loss=1.03]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.80it/s, loss=0.932]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=1.11]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.949]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.883]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=1.33]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.01]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.869]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.628]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=1.27]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.971]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.815]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.629]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.46it/s, loss=1.11]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.936]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.749]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.546]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.46it/s, loss=1.17]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.928]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.55it/s, loss=0.737]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.516]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=1.2] \n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=1]   \n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.89] \n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.666]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.50it/s, loss=1.21]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.953]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.847]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.628]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.46it/s, loss=1.13]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.938]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.808]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.62] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.46it/s, loss=1.35]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=1.06]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.879]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.754]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=1.22]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.954]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.837]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.80it/s, loss=0.611]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  8.80it/s, loss=1.34]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.995]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.781]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.608]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=1.31]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.994]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.855]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.633]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.452]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.301]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.241]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.173]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.138]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=1.32]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=1.05]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.946]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=0.792]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.537]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.404]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.262]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.188]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.137]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=1.38]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=1.03] \n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.884]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.694]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.543]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.395]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.3]  \n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.236]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.189]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=1.16]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.968]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.735]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.579]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.487]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.322]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.253]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.194]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.133]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=1.27]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.972]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.768]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.586]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.443]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.373]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.278]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.206]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.165]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=1.17]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.988]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.79] \n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.57] \n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.405]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.286]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.225]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.158]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.129]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=1.22]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=1.07]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.916]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.679]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.447]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.312]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.218]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.131]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.108] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=1.27]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=1.1] \n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.948]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=0.757]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.566]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.443]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.288]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.206]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.157]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=1.28]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.78it/s, loss=0.943]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.779]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.82it/s, loss=0.511]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.78it/s, loss=0.385]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.74it/s, loss=0.265]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.84it/s, loss=0.176]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.124]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.81it/s, loss=0.108]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=1.36]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.976]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.737]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.53] \n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.386]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.276]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.2]  \n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.164]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.125]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: justinlamlamlam/softwareengineering | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.52it/s, loss=1.41]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.56it/s, loss=1.01]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.911]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.676]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.472]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.318]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.249]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.167]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.127]\n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.0941]\n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.077] \n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.0834]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=1.12]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.972]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.73] \n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.487]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.322]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.241]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.165]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.117]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.0944]\n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.0765]\n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.0579]\n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.0475]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=1.1] \n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.956]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.822]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.634]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.435]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.306]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.201]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.176]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.129]\n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.092] \n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.0765]\n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.0685]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.54it/s, loss=1.22]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.987]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.785]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.514]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.351]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.256]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.197]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.145]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.119] \n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.0963]\n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.101] \n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.0742]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=1.21]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.96] \n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.897]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.75] \n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.597]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.424]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.315]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.235]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.165]\n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.69it/s, loss=0.0945]\n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.65it/s, loss=0.0979]\n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.0711]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.53it/s, loss=1.41]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=1.01]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.47it/s, loss=0.837]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.644]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.57it/s, loss=0.501]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.64it/s, loss=0.346]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.59it/s, loss=0.238]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.175]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.164]\n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.148]\n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.115]\n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.086] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.45it/s, loss=1.24]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=1]    \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=0.816]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.597]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.51it/s, loss=0.443]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.324]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.261]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.211]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=0.189]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.139]\n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.126]\n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.108]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.49it/s, loss=1.16]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.62it/s, loss=1.01]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.966]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.76] \n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.518]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.68it/s, loss=0.323]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.60it/s, loss=0.243]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.178]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=0.111]\n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.87it/s, loss=0.0924]\n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:01<00:00, 10.05it/s, loss=0.072] \n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:01<00:00, 10.02it/s, loss=0.0707]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=1.27]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00,  9.67it/s, loss=1.06] \n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.70it/s, loss=0.818]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.66] \n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.73it/s, loss=0.484]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.71it/s, loss=0.383]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.61it/s, loss=0.33] \n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.237]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.66it/s, loss=0.178]\n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.143]\n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.58it/s, loss=0.107]\n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.75it/s, loss=0.0963]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at justinlamlamlam/softwareengineering and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00,  9.89it/s, loss=1.19]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 10.02it/s, loss=0.95] \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00,  9.92it/s, loss=0.834]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:01<00:00,  9.93it/s, loss=0.672]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:01<00:00,  9.89it/s, loss=0.484]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:01<00:00,  9.76it/s, loss=0.333]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:01<00:00,  9.63it/s, loss=0.235]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:01<00:00,  9.29it/s, loss=0.194]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:01<00:00,  9.42it/s, loss=0.124]\n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:01<00:00,  9.37it/s, loss=0.103] \n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:01<00:00,  9.43it/s, loss=0.0812]\n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:01<00:00,  9.72it/s, loss=0.0809]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to justinlamlamlam-softwareengineering_label.txt\n",
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=1.02]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=1.14]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=1.06]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=1.09]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=1.14]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=1.07]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=1.14]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.972]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=1.04]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.02it/s, loss=1.08]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.06it/s, loss=1.04]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.07it/s, loss=0.438]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.05it/s, loss=0.203]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.03it/s, loss=1.04]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.05it/s, loss=0.485]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.06it/s, loss=0.167]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.05it/s, loss=1.02]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.687]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.619]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=1.09]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.594]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.246]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=1.05]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.01it/s, loss=0.631]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.258]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=1.17]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.69] \n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.381]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=1.04]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.515]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.183]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=1.04]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.567]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.269]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=1.08]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.00it/s, loss=0.574]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.246]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  3.04it/s, loss=1.15]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.00it/s, loss=0.502]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=0.17] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=1.14]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.12it/s, loss=0.594]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.371]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.135]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=1.04] \n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.678]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.381]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  3.00it/s, loss=0.11]  \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=1.22]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.829]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.573]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  3.00it/s, loss=0.215]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=1.17]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.692]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.441]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.192]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=1.17]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.00it/s, loss=0.554]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.229]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  3.00it/s, loss=0.0776]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=1.2] \n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.716]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.513]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.258]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=1.08]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.57] \n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.318]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0978]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=1.11]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.517]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.212]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0922]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=1.19]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.01it/s, loss=0.592]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  3.00it/s, loss=0.309]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.146] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=1.01]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.518]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.368]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.167] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=1.12]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.603]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.282]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0663]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0334]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.029]  \n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0254] \n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.0293] \n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0794]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=1.04]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.666]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.345]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.149]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0571]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0243]\n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0247] \n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0282]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0254] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=1.09]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.55] \n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.268]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.155]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0797]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0845]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0436]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.0343]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0291]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=1.16]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.664]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.364]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.135]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.0732]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0361]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0738]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.163] \n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0355] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=1.15]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.667]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.347]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.108] \n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0386]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0325] \n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0381]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.0367] \n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.0297] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=1.18]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.596]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.277]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0899]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.0644]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.179]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.066] \n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=0.0465]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.0336] \n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=1.04]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.528]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.204]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=0.0956]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=0.0721]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.069] \n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.0333]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.0837] \n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=0.0321]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.94it/s, loss=1.2] \n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.783]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.423]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=0.131]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=0.0336]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=0.0227]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=0.033]  \n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=0.0319] \n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0262]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.96it/s, loss=1.1] \n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.655]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.396]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.114]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0422]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  3.00it/s, loss=0.0515]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.99it/s, loss=0.0391]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.032]  \n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0376]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.95it/s, loss=1.1] \n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.94it/s, loss=0.504]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.159]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s, loss=0.0541]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=0.0757]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.98it/s, loss=0.0505]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.94it/s, loss=0.0309]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.84it/s, loss=0.035] \n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.87it/s, loss=0.0334]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: answerdotai/ModernBERT-large | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.94it/s, loss=1.02] \n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  3.04it/s, loss=0.52] \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.87it/s, loss=0.289]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.119]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.172]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0594]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0387]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0327] \n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0308]\n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0266] \n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0523] \n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0211]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=1.04]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.591]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.233]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.241]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0554]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0327] \n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0235]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0228] \n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0189] \n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0205] \n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0194] \n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0241] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=1.07]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.567]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.307]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0915]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0561]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.046] \n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0495]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0661] \n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.103] \n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0592]\n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0343] \n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0305] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=1.07]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.677]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.426]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.205]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0541]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0733]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.064] \n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0315]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0256] \n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0243]\n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0244] \n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0221] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=1.12]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.667]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.327]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.131] \n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.132]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0767]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0572] \n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0332]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.032]   \n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.031]  \n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.029]  \n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0277]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=1.04] \n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.617]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.217]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0508]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0433]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0401] \n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0412]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.039] \n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0341]\n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.029]  \n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0371] \n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0277] \n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=1.12]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.607]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.283]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.138]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=0.06]  \n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0324] \n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0394] \n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0293]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0331]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0277]\n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.033] \n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=0.0326]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=1.09]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.677]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.538]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=0.326]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=0.108]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0784]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.0524] \n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.069]  \n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0399] \n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=0.028] \n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.023]  \n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0191]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=1.14] \n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.92it/s, loss=0.662]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.286]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0939]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0405]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0314]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0428] \n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.94it/s, loss=0.0419]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.94it/s, loss=0.0451] \n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.94it/s, loss=0.0348] \n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.93it/s, loss=0.0402] \n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.94it/s, loss=0.0303] \n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=1.04]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=0.575]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.268]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0925]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0492]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0342]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0288]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:05<00:00,  2.89it/s, loss=0.0321] \n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0383] \n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0364] \n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:05<00:00,  2.91it/s, loss=0.0308] \n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:05<00:00,  2.90it/s, loss=0.0317]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to answerdotai-ModernBERT-large_label.txt\n",
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=1, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.70it/s, loss=1.12]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.72it/s, loss=1.22]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.81it/s, loss=1.24]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.61it/s, loss=1.26]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.63it/s, loss=1.32]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.63it/s, loss=1.23]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.60it/s, loss=1.21]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.42it/s, loss=1.18]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=1.26]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.47it/s, loss=1.24]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=3, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.53it/s, loss=1.17]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.81it/s, loss=0.965]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.73it/s, loss=0.822]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.65it/s, loss=1.23]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.65it/s, loss=0.997]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.66it/s, loss=0.795]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.52it/s, loss=1.08]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.72it/s, loss=0.865]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.76it/s, loss=0.734]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.39it/s, loss=1.19]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.65it/s, loss=0.932]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.71it/s, loss=0.814]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.67it/s, loss=1.21]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.85it/s, loss=0.926]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.50it/s, loss=0.829]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.39it/s, loss=1.2] \n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.99it/s, loss=0.978]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.848]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.21it/s, loss=1.32]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.63it/s, loss=1.02]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.70it/s, loss=0.838]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.62it/s, loss=1.26]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.54it/s, loss=0.966]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.60it/s, loss=0.813]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.63it/s, loss=1.17]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.90it/s, loss=0.972]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.88it/s, loss=0.814]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.36it/s, loss=1.15]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.57it/s, loss=0.88] \n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.83it/s, loss=0.725]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=4, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.66it/s, loss=1.29]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.75it/s, loss=1.01] \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.65it/s, loss=0.746]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.70it/s, loss=0.609]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.63it/s, loss=1.23]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.80it/s, loss=0.923]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.59it/s, loss=0.775]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.66it/s, loss=0.618]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.53it/s, loss=1.25]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.92] \n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.32it/s, loss=0.742]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.52it/s, loss=0.657]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.54it/s, loss=1.21]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.62it/s, loss=0.967]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.66it/s, loss=0.762]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.64it/s, loss=0.616]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.68it/s, loss=1.13]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.54it/s, loss=0.915]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.65it/s, loss=0.774]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.73it/s, loss=0.631]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.56it/s, loss=1.11]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.46it/s, loss=0.909]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.62it/s, loss=0.723]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.69it/s, loss=0.539]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.53it/s, loss=1.29]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.63it/s, loss=1.04]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.56it/s, loss=0.851]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.66] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.15it/s, loss=1.17]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.921]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.32it/s, loss=0.729]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.07it/s, loss=0.589]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.39it/s, loss=1.2] \n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.41it/s, loss=0.904]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.31it/s, loss=0.771]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.44it/s, loss=0.579]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.81it/s, loss=1.19]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=0.968]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.24it/s, loss=0.839]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.23it/s, loss=0.702]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=9, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=1.14]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=0.88] \n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.80it/s, loss=0.752]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.16it/s, loss=0.59] \n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.20it/s, loss=0.454]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.19it/s, loss=0.323]\n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.06it/s, loss=0.22] \n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.182]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.166]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.86it/s, loss=1.24]\n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=0.98] \n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.27it/s, loss=0.866]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=0.681]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.21it/s, loss=0.583]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.28it/s, loss=0.41] \n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.24it/s, loss=0.329]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.25] \n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.14it/s, loss=0.207]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.25it/s, loss=1.18]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.26it/s, loss=0.986]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.802]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.654]\n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.502]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.362]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:01<00:00, 16.91it/s, loss=0.284]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:01<00:00, 16.90it/s, loss=0.204]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.16it/s, loss=0.161]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=1.28]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.14it/s, loss=0.931]\n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.28it/s, loss=0.798]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.17it/s, loss=0.648]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.13it/s, loss=0.535]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.385]\n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.24it/s, loss=0.319]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.17it/s, loss=0.265]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.04it/s, loss=0.207]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.12it/s, loss=1.14]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.14it/s, loss=0.935]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.17it/s, loss=0.771]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.48it/s, loss=0.604]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:01<00:00, 16.28it/s, loss=0.429]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.39it/s, loss=0.326]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:01<00:00, 16.99it/s, loss=0.261]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.22it/s, loss=0.195]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.13it/s, loss=0.175]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.72it/s, loss=1.27]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.03it/s, loss=0.985]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.81it/s, loss=0.816]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.73it/s, loss=0.63] \n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.17it/s, loss=0.513]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.04it/s, loss=0.359]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:01<00:00, 16.92it/s, loss=0.265]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=0.205]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.16it/s, loss=0.194]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.91it/s, loss=1.28]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.988]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.852]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.29it/s, loss=0.701]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.04it/s, loss=0.499]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.99it/s, loss=0.39] \n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:01<00:00, 16.94it/s, loss=0.345]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.12it/s, loss=0.264]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.03it/s, loss=0.183]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.89it/s, loss=1.29]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.91it/s, loss=1.04] \n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.823]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.72it/s, loss=0.656]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:01<00:00, 16.88it/s, loss=0.509]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.414]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.07it/s, loss=0.307]\n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:01<00:00, 17.00it/s, loss=0.226]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.167]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.99it/s, loss=1.24]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.14it/s, loss=0.979]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.16it/s, loss=0.809]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.12it/s, loss=0.617]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.33it/s, loss=0.455]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.34it/s, loss=0.347]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.13it/s, loss=0.264]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.13it/s, loss=0.208]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.25it/s, loss=0.156]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.72it/s, loss=1.22]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.89it/s, loss=0.909]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.89it/s, loss=0.715]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.587]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.00it/s, loss=0.462]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.89it/s, loss=0.332]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=0.25] \n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.2]  \n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.06it/s, loss=0.16] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: milyiyo/distilbert-base-uncased-finetuned-amazon-review | EPOCHS=12, BATCH_SIZE=8, K-FOLD=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 1 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.74it/s, loss=1.23]\n",
      "Fold 1 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.95it/s, loss=0.966]\n",
      "Fold 1 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.14it/s, loss=0.822]\n",
      "Fold 1 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.637]\n",
      "Fold 1 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.02it/s, loss=0.481]\n",
      "Fold 1 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.36] \n",
      "Fold 1 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.15it/s, loss=0.291]\n",
      "Fold 1 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.211]\n",
      "Fold 1 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.01it/s, loss=0.188]\n",
      "Fold 1 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.03it/s, loss=0.134]\n",
      "Fold 1 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.18it/s, loss=0.115]\n",
      "Fold 1 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.0849]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 2 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.77it/s, loss=1.3] \n",
      "Fold 2 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.94it/s, loss=0.972]\n",
      "Fold 2 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.792]\n",
      "Fold 2 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.658]\n",
      "Fold 2 Epoch 5: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.486]\n",
      "Fold 2 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.94it/s, loss=0.36] \n",
      "Fold 2 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=0.267]\n",
      "Fold 2 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=0.203]\n",
      "Fold 2 Epoch 9: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.154]\n",
      "Fold 2 Epoch 10: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.121]\n",
      "Fold 2 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=0.117]\n",
      "Fold 2 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.06it/s, loss=0.0975]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 3 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.72it/s, loss=1.27]\n",
      "Fold 3 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.02it/s, loss=0.959]\n",
      "Fold 3 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.814]\n",
      "Fold 3 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.65] \n",
      "Fold 3 Epoch 5: 100%|██████████| 17/17 [00:01<00:00, 16.99it/s, loss=0.479]\n",
      "Fold 3 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 17.00it/s, loss=0.369]\n",
      "Fold 3 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.275]\n",
      "Fold 3 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.06it/s, loss=0.218]\n",
      "Fold 3 Epoch 9: 100%|██████████| 17/17 [00:01<00:00, 17.00it/s, loss=0.209]\n",
      "Fold 3 Epoch 10: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=0.185]\n",
      "Fold 3 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.13it/s, loss=0.138]\n",
      "Fold 3 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.04it/s, loss=0.12]  \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 4 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.83it/s, loss=1.29]\n",
      "Fold 4 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.94it/s, loss=1.01] \n",
      "Fold 4 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.814]\n",
      "Fold 4 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.02it/s, loss=0.598]\n",
      "Fold 4 Epoch 5: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.458]\n",
      "Fold 4 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.98it/s, loss=0.34] \n",
      "Fold 4 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.268]\n",
      "Fold 4 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.08it/s, loss=0.276]\n",
      "Fold 4 Epoch 9: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.2]  \n",
      "Fold 4 Epoch 10: 100%|██████████| 17/17 [00:01<00:00, 16.99it/s, loss=0.17] \n",
      "Fold 4 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.12it/s, loss=0.116]\n",
      "Fold 4 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.105]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 5 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.75it/s, loss=1.25]\n",
      "Fold 5 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.95it/s, loss=0.955]\n",
      "Fold 5 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.822]\n",
      "Fold 5 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.06it/s, loss=0.687]\n",
      "Fold 5 Epoch 5: 100%|██████████| 17/17 [00:01<00:00, 16.95it/s, loss=0.583]\n",
      "Fold 5 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.91it/s, loss=0.425]\n",
      "Fold 5 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.343]\n",
      "Fold 5 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.271]\n",
      "Fold 5 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.01it/s, loss=0.197]\n",
      "Fold 5 Epoch 10: 100%|██████████| 17/17 [00:01<00:00, 16.96it/s, loss=0.188]\n",
      "Fold 5 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.146]\n",
      "Fold 5 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.129]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 6 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.70it/s, loss=1.23]\n",
      "Fold 6 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=0.962]\n",
      "Fold 6 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.13it/s, loss=0.852]\n",
      "Fold 6 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.04it/s, loss=0.691]\n",
      "Fold 6 Epoch 5: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=0.574]\n",
      "Fold 6 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.99it/s, loss=0.453]\n",
      "Fold 6 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.13it/s, loss=0.371]\n",
      "Fold 6 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.04it/s, loss=0.312]\n",
      "Fold 6 Epoch 9: 100%|██████████| 17/17 [00:01<00:00, 16.92it/s, loss=0.225]\n",
      "Fold 6 Epoch 10: 100%|██████████| 17/17 [00:01<00:00, 16.98it/s, loss=0.195]\n",
      "Fold 6 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.14it/s, loss=0.153]\n",
      "Fold 6 Epoch 12: 100%|██████████| 17/17 [00:01<00:00, 16.67it/s, loss=0.133]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 7 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.71it/s, loss=1.23]\n",
      "Fold 7 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.81it/s, loss=0.985]\n",
      "Fold 7 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.74it/s, loss=0.831]\n",
      "Fold 7 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.89it/s, loss=0.667]\n",
      "Fold 7 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.14it/s, loss=0.535]\n",
      "Fold 7 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.435]\n",
      "Fold 7 Epoch 7: 100%|██████████| 17/17 [00:01<00:00, 16.89it/s, loss=0.341]\n",
      "Fold 7 Epoch 8: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.276]\n",
      "Fold 7 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.10it/s, loss=0.271]\n",
      "Fold 7 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.03it/s, loss=0.19] \n",
      "Fold 7 Epoch 11: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.152]\n",
      "Fold 7 Epoch 12: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.137] \n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 8 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.60it/s, loss=1.32]\n",
      "Fold 8 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.95it/s, loss=0.965]\n",
      "Fold 8 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.83it/s, loss=0.778]\n",
      "Fold 8 Epoch 4: 100%|██████████| 17/17 [00:01<00:00, 16.97it/s, loss=0.624]\n",
      "Fold 8 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.436]\n",
      "Fold 8 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.04it/s, loss=0.357]\n",
      "Fold 8 Epoch 7: 100%|██████████| 17/17 [00:01<00:00, 16.91it/s, loss=0.26] \n",
      "Fold 8 Epoch 8: 100%|██████████| 17/17 [00:01<00:00, 16.93it/s, loss=0.179]\n",
      "Fold 8 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.17it/s, loss=0.135]\n",
      "Fold 8 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.01it/s, loss=0.113] \n",
      "Fold 8 Epoch 11: 100%|██████████| 17/17 [00:01<00:00, 16.94it/s, loss=0.0852]\n",
      "Fold 8 Epoch 12: 100%|██████████| 17/17 [00:01<00:00, 16.91it/s, loss=0.0772]\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 9 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.94it/s, loss=1.15]\n",
      "Fold 9 Epoch 2: 100%|██████████| 17/17 [00:00<00:00, 17.19it/s, loss=0.941]\n",
      "Fold 9 Epoch 3: 100%|██████████| 17/17 [00:00<00:00, 17.09it/s, loss=0.778]\n",
      "Fold 9 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.03it/s, loss=0.665]\n",
      "Fold 9 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.26it/s, loss=0.473]\n",
      "Fold 9 Epoch 6: 100%|██████████| 17/17 [00:00<00:00, 17.22it/s, loss=0.377]\n",
      "Fold 9 Epoch 7: 100%|██████████| 17/17 [00:00<00:00, 17.11it/s, loss=0.311]\n",
      "Fold 9 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.17it/s, loss=0.235]\n",
      "Fold 9 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.31it/s, loss=0.189]\n",
      "Fold 9 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.23it/s, loss=0.165]\n",
      "Fold 9 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.15it/s, loss=0.124] \n",
      "Fold 9 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.13it/s, loss=0.104] \n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at milyiyo/distilbert-base-uncased-finetuned-amazon-review and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Fold 10 Epoch 1: 100%|██████████| 17/17 [00:01<00:00, 16.87it/s, loss=1.16]\n",
      "Fold 10 Epoch 2: 100%|██████████| 17/17 [00:01<00:00, 16.95it/s, loss=0.873]\n",
      "Fold 10 Epoch 3: 100%|██████████| 17/17 [00:01<00:00, 16.95it/s, loss=0.755]\n",
      "Fold 10 Epoch 4: 100%|██████████| 17/17 [00:00<00:00, 17.01it/s, loss=0.578]\n",
      "Fold 10 Epoch 5: 100%|██████████| 17/17 [00:00<00:00, 17.06it/s, loss=0.429]\n",
      "Fold 10 Epoch 6: 100%|██████████| 17/17 [00:01<00:00, 16.99it/s, loss=0.343]\n",
      "Fold 10 Epoch 7: 100%|██████████| 17/17 [00:01<00:00, 16.92it/s, loss=0.266]\n",
      "Fold 10 Epoch 8: 100%|██████████| 17/17 [00:00<00:00, 17.02it/s, loss=0.235]\n",
      "Fold 10 Epoch 9: 100%|██████████| 17/17 [00:00<00:00, 17.04it/s, loss=0.186]\n",
      "Fold 10 Epoch 10: 100%|██████████| 17/17 [00:00<00:00, 17.00it/s, loss=0.164]\n",
      "Fold 10 Epoch 11: 100%|██████████| 17/17 [00:00<00:00, 17.03it/s, loss=0.134]\n",
      "Fold 10 Epoch 12: 100%|██████████| 17/17 [00:00<00:00, 17.12it/s, loss=0.126] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best combination saved to milyiyo-distilbert-base-uncased-finetuned-amazon-review_label.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Constants and model list\n",
    "MODEL_NAMES = [\n",
    "    \"albert/albert-base-v2\",\n",
    "    \"albert/albert-large-v2\",\n",
    "    \"microsoft/deberta-v3-large\",\n",
    "    # \"microsoft/deberta-v2-xlarge\",\n",
    "    \"FacebookAI/roberta-large\",\n",
    "    \"google-bert/bert-base-uncased\",\n",
    "    \"ProsusAI/finbert\",\n",
    "    \"PHILIPPUNI/distilbert-amazon-software-reviews-finetuned\",\n",
    "    \"justinlamlamlam/softwareengineering\",\n",
    "    \"answerdotai/ModernBERT-large\",\n",
    "    \"milyiyo/distilbert-base-uncased-finetuned-amazon-review\"\n",
    "]\n",
    "LABEL_COLUMN = \"label\"\n",
    "\n",
    "# Hyperparameter grid\n",
    "EPOCHS_LIST = [1, 3, 4, 9, 12]\n",
    "BATCH_SIZES = [8]\n",
    "N_SPLITS_LIST = [5, 10]\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"type_val_single.csv\")\n",
    "label_encoder = LabelEncoder()\n",
    "data[LABEL_COLUMN] = label_encoder.fit_transform(data[LABEL_COLUMN])\n",
    "texts = data[\"sentence\"].tolist()\n",
    "labels = data[LABEL_COLUMN].tolist()\n",
    "\n",
    "# Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs, fold):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1}\")\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=total_loss / (progress_bar.n + 1))\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            preds = model(**inputs).logits.argmax(dim=-1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Generate folds once and reuse them\n",
    "def generate_kfold_splits(texts, labels, n_splits):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    return list(skf.split(texts, labels))\n",
    "\n",
    "# Save best result to file\n",
    "def save_best_result(log_path, header, result, best_combo_summary):\n",
    "    with open(log_path, \"w\") as f:\n",
    "        f.write(header + \"\\n\\n\")\n",
    "        f.write(result + \"\\n\")\n",
    "        f.write(\"\\n===== BEST COMBINATION =====\\n\")\n",
    "        f.write(best_combo_summary + \"\\n\")\n",
    "\n",
    "# Begin experiment\n",
    "for n_splits in N_SPLITS_LIST:\n",
    "    folds = generate_kfold_splits(texts, labels, n_splits)\n",
    "\n",
    "    for model_name in MODEL_NAMES:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        safe_model_name = model_name.replace('/', '-')\n",
    "        log_file = f\"{safe_model_name}_{LABEL_COLUMN}.txt\"\n",
    "\n",
    "        best_f1 = 0\n",
    "        best_result = \"\"\n",
    "        best_combo = \"\"\n",
    "\n",
    "        for epochs, batch_size in itertools.product(EPOCHS_LIST, BATCH_SIZES):\n",
    "            print(f\"\\nModel: {model_name} | EPOCHS={epochs}, BATCH_SIZE={batch_size}, K-FOLD={n_splits}\")\n",
    "            all_accuracies, all_precisions, all_recalls, all_f1s = [], [], [], []\n",
    "\n",
    "            for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "                train_texts = [texts[i] for i in train_idx]\n",
    "                val_texts = [texts[i] for i in val_idx]\n",
    "                train_labels = [labels[i] for i in train_idx]\n",
    "                val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "                train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "                val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                    model_name,\n",
    "                    num_labels=len(set(labels)),\n",
    "                    ignore_mismatched_sizes=True\n",
    "                ).to(device)\n",
    "\n",
    "                optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "                criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "                train_model(model, train_loader, optimizer, criterion, epochs, fold)\n",
    "                y_true, y_pred = evaluate_model(model, val_loader)\n",
    "\n",
    "                acc = accuracy_score(y_true, y_pred)\n",
    "                prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "\n",
    "                all_accuracies.append(acc)\n",
    "                all_precisions.append(prec)\n",
    "                all_recalls.append(rec)\n",
    "                all_f1s.append(f1)\n",
    "\n",
    "            avg_accuracy = np.mean(all_accuracies)\n",
    "            avg_precision = np.mean(all_precisions)\n",
    "            avg_recall = np.mean(all_recalls)\n",
    "            avg_f1 = np.mean(all_f1s)\n",
    "\n",
    "            if avg_f1 > best_f1:\n",
    "                best_f1 = avg_f1\n",
    "                best_combo = f\"Model: {model_name}\\nLabel Column: {LABEL_COLUMN}\\nEpochs: {epochs}, Batch Size: {batch_size}, K-Fold: {n_splits}\"\n",
    "                best_result = (\n",
    "                    f\"Accuracy: {avg_accuracy:.4f}\\n\"\n",
    "                    f\"Precision: {avg_precision:.4f}\\n\"\n",
    "                    f\"Recall: {avg_recall:.4f}\\n\"\n",
    "                    f\"F1-Score: {avg_f1:.4f}\"\n",
    "                )\n",
    "\n",
    "        # Save best result to file\n",
    "        header = f\"Best Hyperparameter Combination for {model_name} on {LABEL_COLUMN}\"\n",
    "        save_best_result(log_file, header, best_result, best_combo)\n",
    "        print(f\"\\nBest combination saved to {log_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db360b-1ec5-4c62-9046-2cde3f6da62c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Structure Focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2a7feb-75f8-427d-a779-46d2bc18f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Constants and model list\n",
    "MODEL_NAMES = [\n",
    "    # \"albert/albert-base-v2\",\n",
    "    # \"albert/albert-large-v2\",\n",
    "    # \"microsoft/deberta-v3-large\",\n",
    "    # \"microsoft/deberta-v2-xlarge\",\n",
    "    # \"FacebookAI/roberta-large\",\n",
    "    # \"google-bert/bert-base-uncased\",\n",
    "    # \"ProsusAI/finbert\",\n",
    "    # \"PHILIPPUNI/distilbert-amazon-software-reviews-finetuned\",\n",
    "    # \"justinlamlamlam/softwareengineering\",\n",
    "    # \"answerdotai/ModernBERT-large\",\n",
    "    \"milyiyo/distilbert-base-uncased-finetuned-amazon-review\"\n",
    "]\n",
    "LABEL_COLUMN = \"structure_focus\"\n",
    "\n",
    "# Hyperparameter grid\n",
    "EPOCHS_LIST = [1, 3, 4, 9, 12]\n",
    "BATCH_SIZES = [8]\n",
    "N_SPLITS_LIST = [5, 10]\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"type_classification-validation.csv\")\n",
    "label_encoder = LabelEncoder()\n",
    "data[LABEL_COLUMN] = label_encoder.fit_transform(data[LABEL_COLUMN])\n",
    "texts = data[\"sentence\"].tolist()\n",
    "labels = data[LABEL_COLUMN].tolist()\n",
    "\n",
    "# Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs, fold):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Fold {fold+1} Epoch {epoch+1}\")\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=total_loss / (progress_bar.n + 1))\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val.to(device) for key, val in batch.items() if key != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            preds = model(**inputs).logits.argmax(dim=-1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Generate folds once and reuse them\n",
    "def generate_kfold_splits(texts, labels, n_splits):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    return list(skf.split(texts, labels))\n",
    "\n",
    "# Save best result to file\n",
    "def save_best_result(log_path, header, result, best_combo_summary):\n",
    "    with open(log_path, \"w\") as f:\n",
    "        f.write(header + \"\\n\\n\")\n",
    "        f.write(result + \"\\n\")\n",
    "        f.write(\"\\n===== BEST COMBINATION =====\\n\")\n",
    "        f.write(best_combo_summary + \"\\n\")\n",
    "\n",
    "# Begin experiment\n",
    "for n_splits in N_SPLITS_LIST:\n",
    "    folds = generate_kfold_splits(texts, labels, n_splits)\n",
    "\n",
    "    for model_name in MODEL_NAMES:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        safe_model_name = model_name.replace('/', '-')\n",
    "        log_file = f\"{safe_model_name}_{LABEL_COLUMN}.txt\"\n",
    "\n",
    "        best_f1 = 0\n",
    "        best_result = \"\"\n",
    "        best_combo = \"\"\n",
    "\n",
    "        for epochs, batch_size in itertools.product(EPOCHS_LIST, BATCH_SIZES):\n",
    "            print(f\"\\nModel: {model_name} | EPOCHS={epochs}, BATCH_SIZE={batch_size}, K-FOLD={n_splits}\")\n",
    "            all_accuracies, all_precisions, all_recalls, all_f1s = [], [], [], []\n",
    "\n",
    "            for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "                train_texts = [texts[i] for i in train_idx]\n",
    "                val_texts = [texts[i] for i in val_idx]\n",
    "                train_labels = [labels[i] for i in train_idx]\n",
    "                val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "                train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "                val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                    model_name,\n",
    "                    num_labels=len(set(labels)),\n",
    "                    ignore_mismatched_sizes=True\n",
    "                ).to(device)\n",
    "\n",
    "                optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "                criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "                train_model(model, train_loader, optimizer, criterion, epochs, fold)\n",
    "                y_true, y_pred = evaluate_model(model, val_loader)\n",
    "\n",
    "                acc = accuracy_score(y_true, y_pred)\n",
    "                prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "\n",
    "                all_accuracies.append(acc)\n",
    "                all_precisions.append(prec)\n",
    "                all_recalls.append(rec)\n",
    "                all_f1s.append(f1)\n",
    "\n",
    "            avg_accuracy = np.mean(all_accuracies)\n",
    "            avg_precision = np.mean(all_precisions)\n",
    "            avg_recall = np.mean(all_recalls)\n",
    "            avg_f1 = np.mean(all_f1s)\n",
    "\n",
    "            if avg_f1 > best_f1:\n",
    "                best_f1 = avg_f1\n",
    "                best_combo = f\"Model: {model_name}\\nLabel Column: {LABEL_COLUMN}\\nEpochs: {epochs}, Batch Size: {batch_size}, K-Fold: {n_splits}\"\n",
    "                best_result = (\n",
    "                    f\"Accuracy: {avg_accuracy:.4f}\\n\"\n",
    "                    f\"Precision: {avg_precision:.4f}\\n\"\n",
    "                    f\"Recall: {avg_recall:.4f}\\n\"\n",
    "                    f\"F1-Score: {avg_f1:.4f}\"\n",
    "                )\n",
    "\n",
    "        # Save best result to file\n",
    "        header = f\"Best Hyperparameter Combination for {model_name} on {LABEL_COLUMN}\"\n",
    "        save_best_result(log_file, header, best_result, best_combo)\n",
    "        print(f\"\\nBest combination saved to {log_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf528d9-085a-4436-bd05-9e3b0709cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce3e03-6c0a-4012-90c4-575a13d2e73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
