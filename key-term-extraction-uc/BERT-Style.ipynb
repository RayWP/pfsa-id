{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:45:49.855955Z",
     "start_time": "2025-03-07T14:45:49.695025Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_dataset = pd.read_csv('../corpus-raymond/usecase-train-hf.csv')\n",
    "val_dataset = pd.read_csv('../corpus-raymond/usecase-val-hf.csv')\n",
    "test_dataset = pd.read_csv('../corpus-raymond/usecase-test-hf.csv')\n",
    "#take column 'tokens' as list\n",
    "train_dataset['tokens'] = train_dataset['tokens'].apply(eval)\n",
    "val_dataset['tokens'] = val_dataset['tokens'].apply(eval)\n",
    "test_dataset['tokens'] = test_dataset['tokens'].apply(eval)\n",
    "\n",
    "#take column 'IOB_tag' as list\n",
    "train_dataset['IOB_tag'] = train_dataset['IOB_tag'].apply(eval)\n",
    "val_dataset['IOB_tag'] = val_dataset['IOB_tag'].apply(eval)\n",
    "test_dataset['IOB_tag'] = test_dataset['IOB_tag'].apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f73d5f4016b9e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:45:49.896364Z",
     "start_time": "2025-03-07T14:45:49.867960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552deebe74c4634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:45:50.040212Z",
     "start_time": "2025-03-07T14:45:50.036210Z"
    }
   },
   "outputs": [],
   "source": [
    "# First define your standard IOB tags\n",
    "iob_mapping = {\n",
    "    \"O\": 0,\n",
    "    \"B-actor\": 1,\n",
    "    \"I-actor\": 2,\n",
    "    \"B-usecase\": 3,\n",
    "    \"I-usecase\": 4\n",
    "}\n",
    "\n",
    "# Create label names list including a special PAD token\n",
    "label_names = ['O', 'B-actor', 'I-actor', 'B-usecase', 'I-usecase', '[PAD]']\n",
    "\n",
    "# Define id2label and label2id including the PAD token\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# Define pad token label id as the last index (safer than -100 for CUDA)\n",
    "pad_token_label_id = label2id['[PAD]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d341879131b0e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:45:50.241226Z",
     "start_time": "2025-03-07T14:45:50.236225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'O', 1: 'B-class', 2: 'I-class', 3: 'B-attr', 4: 'I-attr', 5: '[PAD]'}\n",
      "{'O': 0, 'B-class': 1, 'I-class': 2, 'B-attr': 3, 'I-attr': 4, '[PAD]': 5}\n"
     ]
    }
   ],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(id2label)\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1809149bf9d95f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:45:50.456197Z",
     "start_time": "2025-03-07T14:45:50.450198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Customer', '.', 'HTTPS', 'with', 'browser', 'web', 'button', 'account', 'customer', 'new', 'sdram', 'MB', '128', ';', 'chip', 'ram', 'Flash', ';', 'GB', ':', 'requirement', 'hardware', 'follow', 'the', 'to', 'adhere', '4', 'Intel', 'XScale', 'PXA270', 'a']\n",
      "[1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "words = train_dataset.iloc[0][\"tokens\"]\n",
    "labels = train_dataset.iloc[0][\"IOB_tag\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(words)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0ad48192d4de0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:45:50.891213Z",
     "start_time": "2025-03-07T14:45:50.623559Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DebertaV2TokenizerFast\n",
    "import os\n",
    "from pathlib import Path\n",
    "tokenizer_checkpoint = \"microsoft/phi-4\"\n",
    "model_checkpoint = \"microsoft/phi-4\" \n",
    "folder_name = \"BERT-Style-result/microsoft/phi-4-4-epoch-8bs-new\"\n",
    "model_name_save = \"BERT-Style-model/microsoft/phi-4-4-epoch-8bs-new\"\n",
    "Path(folder_name).mkdir(parents=True, exist_ok=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint, add_prefix_space=True )\n",
    "\n",
    "max_length = 256\n",
    "epochs = 4\n",
    "bs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239159fe7bb3e643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:47:40.251290Z",
     "start_time": "2025-03-07T14:47:40.247348Z"
    }
   },
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            # Use pad_token_label_id for special tokens (None)\n",
    "            label = pad_token_label_id if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(pad_token_label_id)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd2a750b286ecd95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:47:41.349838Z",
     "start_time": "2025-03-07T14:47:41.344368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [13084, 13, 83454, 4291, 23279, 2984, 2208, 4711, 11296, 943, 13752, 2453, 8578, 4386, 26, 30762, 2453, 24818, 26, 5494, 25, 4408, 479, 69315, 19070, 1820, 998, 329, 6881, 19, 50199, 55, 7092, 47, 60550, 10914, 64], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(train_dataset.iloc[0][\"tokens\"],truncation=True, is_split_into_words=True, padding='do_not_pad', max_length=max_length)\n",
    "labels = train_dataset.iloc[0][\"IOB_tag\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(inputs)\n",
    "# print(labels)\n",
    "# print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5efd2fcfe3798a38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:51.421549Z",
     "start_time": "2025-03-07T14:29:51.417726Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(df):\n",
    "    # Convert Pandas DataFrame to dictionary format (column-based)\n",
    "    examples = df.to_dict(orient=\"list\")\n",
    "\n",
    "    # Tokenize the input tokens\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True, padding='max_length', max_length=max_length\n",
    "    )\n",
    "\n",
    "    all_labels = examples[\"IOB_tag\"]\n",
    "    rearranged_labels = []\n",
    "\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        rearranged_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = rearranged_labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e65afae5f293a13b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:51.915266Z",
     "start_time": "2025-03-07T14:29:51.761477Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_train = tokenize_and_align_labels(train_dataset)\n",
    "tokenized_val = tokenize_and_align_labels(val_dataset)\n",
    "tokenized_test = tokenize_and_align_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "849d07139f52d337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:52.481705Z",
     "start_time": "2025-03-07T14:29:52.126651Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "# convert tokenized train to arrow dataset class\n",
    "train_dataset = Dataset.from_dict(tokenized_train)\n",
    "val_dataset = Dataset.from_dict(tokenized_val)\n",
    "test_dataset = Dataset.from_dict(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161be3fb74d6927f",
   "metadata": {},
   "source": [
    "# Data Collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e60b4279359a555e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:52.683957Z",
     "start_time": "2025-03-07T14:29:52.678957Z"
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "# data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea37710ff2039e",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a14f04c19330eeac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:54.825368Z",
     "start_time": "2025-03-07T14:29:53.158363Z"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92b04db98538dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:55.027556Z",
     "start_time": "2025-03-07T14:29:55.021810Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove PAD tokens and convert to labels\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        seq_true_labels = []\n",
    "        seq_true_preds = []\n",
    "        \n",
    "        for j in range(len(labels[i])):\n",
    "            if labels[i][j] != pad_token_label_id:\n",
    "                # Only include non-PAD tokens\n",
    "                seq_true_labels.append(label_names[labels[i][j]])\n",
    "                seq_true_preds.append(label_names[predictions[i][j]])\n",
    "        \n",
    "        true_labels.append(seq_true_labels)\n",
    "        true_predictions.append(seq_true_preds)\n",
    "    \n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536937e8af00143",
   "metadata": {},
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e201335ef1af87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:55.671299Z",
     "start_time": "2025-03-07T14:29:55.436307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50692c66bd16497ebfaaf1a9af62725d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/802 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616b38e378f74919bd667667ef7971fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97f48bd5ecd42598422eafce6834efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0faf3babd8544140bd3041d51a5e842b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00006.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ba27240c604ec69c51784dc6df0847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00006.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0150e39772e14941a9ff3d733019eeb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00006.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bb849c61ed44e68ddf3cf7d4ccd9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00006.safetensors:   0%|          | 0.00/4.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b096aa6c7fdc4a89bdb57bd5236abcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00006.safetensors:   0%|          | 0.00/4.77G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c117ccb23ef2418486561bdd5febce5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00006.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import AutoModelForTokenClassification, AutoModelForSeq2SeqLM\n",
    "import torch.nn as nn\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, pad_token_id=5, smoothing=0.0):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.pad_token_id = pad_token_id  # Use the pad token ID you defined\n",
    "        self.smoothing = smoothing\n",
    "        self.confidence = 1.0 - smoothing\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # Create a mask for pad tokens\n",
    "        pad_mask = (target == self.pad_token_id)\n",
    "        \n",
    "        # Reshape logits for CrossEntropyLoss (batch_size * seq_len, num_classes)\n",
    "        logits_flat = logits.view(-1, logits.size(-1))\n",
    "        \n",
    "        # Reshape target for CrossEntropyLoss (batch_size * seq_len)\n",
    "        target_flat = target.view(-1)\n",
    "        \n",
    "        # Convert pad tokens to 0 temporarily for valid indexing, we'll ignore them with the mask\n",
    "        target_flat = torch.where(target_flat == self.pad_token_id, \n",
    "                                  torch.tensor(0, device=target.device), \n",
    "                                  target_flat)\n",
    "        \n",
    "        # Standard CrossEntropy calculation\n",
    "        loss = F.cross_entropy(logits_flat, target_flat, reduction='none')\n",
    "        \n",
    "        # Reshape pad_mask to match loss dimensions\n",
    "        pad_mask_flat = pad_mask.view(-1)\n",
    "        \n",
    "        # Zero out the loss for pad tokens (we don't want to train on those)\n",
    "        masked_loss = torch.where(pad_mask_flat, \n",
    "                                  torch.tensor(0.0, device=loss.device), \n",
    "                                  loss)\n",
    "        \n",
    "        # Calculate mean over non-pad tokens\n",
    "        non_pad_elements = (~pad_mask_flat).sum().float()\n",
    "        if non_pad_elements > 0:\n",
    "            return masked_loss.sum() / non_pad_elements\n",
    "        else:\n",
    "            return torch.tensor(0.0, device=masked_loss.device)\n",
    "\n",
    "class CustomTokenClassificationModel(nn.Module):\n",
    "    def __init__(self, base_model, num_labels, pad_token_label_id):\n",
    "        super(CustomTokenClassificationModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.pad_token_label_id = pad_token_label_id\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Use custom loss function to ignore pad tokens\n",
    "            loss_fct = LabelSmoothingCrossEntropy(pad_token_id=self.pad_token_label_id)\n",
    "            loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else logits\n",
    "\n",
    "# Load the base model for token classification\n",
    "base_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    num_labels=len(label_names),  # Include PAD in num_labels\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Wrap it in our custom model\n",
    "model = CustomTokenClassificationModel(base_model, len(label_names), pad_token_label_id)\n",
    "\n",
    "# weight_decay is a regularization procedure with regard to the weight matrices\n",
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.base_model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr=3e-5,\n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19216f4f9f0ef1c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:56.596964Z",
     "start_time": "2025-03-07T14:29:55.819246Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = \"cuda\"\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438f940b2194e8a",
   "metadata": {},
   "source": [
    "# Preparing Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f110bd1254115",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:57.596407Z",
     "start_time": "2025-03-07T14:29:56.798046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the dataset to torch tensors\n",
    "train_inputs = torch.tensor(train_dataset[\"input_ids\"])\n",
    "dev_inputs = torch.tensor(val_dataset[\"input_ids\"])\n",
    "test_inputs = torch.tensor(test_dataset[\"input_ids\"])\n",
    "train_tags = torch.tensor(train_dataset[\"labels\"])\n",
    "dev_tags = torch.tensor(val_dataset[\"labels\"])\n",
    "test_tags = torch.tensor(test_dataset[\"labels\"])\n",
    "train_masks = torch.tensor(train_dataset[\"attention_mask\"])\n",
    "dev_masks = torch.tensor(val_dataset[\"attention_mask\"])\n",
    "test_masks = torch.tensor(test_dataset[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e090fa3de219e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:57.824872Z",
     "start_time": "2025-03-07T14:29:57.820878Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader, SequentialSampler\n",
    "\n",
    "# We define the dataloaders. \n",
    "# Shuffle the data for training using RandomSampler\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "# Load dev and test data sequentially with SequentialSampler.\n",
    "dev_data = TensorDataset(dev_inputs, dev_masks, dev_tags)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=bs)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_tags)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef97bc0b87326df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:29:58.004324Z",
     "start_time": "2025-03-07T14:29:58.000310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import a scheduler to reduce the learning rate \n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs; the BERT paper uses 10\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68aa2ac29568db",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96e2008ecec57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:30:09.818329800Z",
     "start_time": "2025-03-07T14:30:03.696195Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tqdm import trange\n",
    "\n",
    "# To measure execution time of this cell\n",
    "\n",
    "# Train the model for; the BERT paper uses 4\n",
    "## Store the average loss after each epoch; these values are used to plot the loss.\n",
    "loss_values, development_loss_values = [], []\n",
    "\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    #\n",
    "    # Training\n",
    "    #\n",
    "    # Set the model into training mode\n",
    "    model.train()\n",
    "    # Reset the total loss for each epoch\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Transfer batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Remove previous gradients before each backward pass\n",
    "        model.zero_grad()\n",
    "        # forward pass\n",
    "        # This returns the loss (not the model output) since we have input the labels.\n",
    "        outputs = model(input_ids=b_input_ids,\n",
    "                        attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Get the loss\n",
    "        loss = outputs[0]\n",
    "        # Backward pass to compute the gradients\n",
    "        loss.backward()\n",
    "        # Train loss\n",
    "        total_loss += loss.item()\n",
    "        # Clip the norm of the gradient\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "    \n",
    "\n",
    "    # Store each loss value for plotting the learning curve afterwards\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    # After each training epoch, measure performance on development set\n",
    "\n",
    "    # Set the model into evaluation mode\n",
    "    model.eval()\n",
    "    # Reset the development loss for this epoch\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions, true_labels = [], []\n",
    "    for batch in dev_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # The model must not compute or save gradients, in order to save memory and speed up this step\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, compute predictions\n",
    "            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Transfer logits and labels to CPU\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Compute the accuracy for this batch of development sentences\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.extend(label_ids)\n",
    "    \n",
    "    eval_loss = eval_loss / len(dev_dataloader)\n",
    "    development_loss_values.append(eval_loss)\n",
    "    print(\"Development loss: {}\".format(eval_loss))\n",
    "    \n",
    "    # Filter out pad tokens when computing metrics\n",
    "    pred_tags = []\n",
    "    dev_tags = []\n",
    "    \n",
    "    for p, l in zip(predictions, true_labels):\n",
    "        for p_i, l_i in zip(p, l):\n",
    "            if l_i != pad_token_label_id:  # Only include non-pad tokens\n",
    "                pred_tags.append(label_names[p_i])\n",
    "                dev_tags.append(label_names[l_i])\n",
    "    \n",
    "    f1 = f1_score(dev_tags, pred_tags, average='micro')\n",
    "\n",
    "    # Format output with 4 decimal places\n",
    "    output_text = \"train-val F1 score: {:.4f}\\n\".format(f1)\n",
    "\n",
    "    # Print to console\n",
    "    print(output_text)\n",
    "\n",
    "    # Save to a text file\n",
    "    with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
    "        file.write(output_text)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f51cd3e2dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(pred_tags, dev_tags)),\n",
    "               columns =['Pred', 'True'])\n",
    "df.to_csv(folder_name + '/train-val-result-bert.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba5b5bf726c34c1",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa54a7b1f8075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
    "plt.plot(development_loss_values, 'r-o', label=\"validation loss\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Learning curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95241329f809f83f",
   "metadata": {},
   "source": [
    "# Testing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a911e1ce59aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the model to the test set with PAD token prediction prevention\n",
    "# Set again the model into evaluation mode\n",
    "model.eval()\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "input_ids_list = []\n",
    "eval_loss = 0\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # The model must not compute or store gradients\n",
    "    with torch.no_grad():\n",
    "        # Get loss\n",
    "        outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        \n",
    "        # Use the predict_without_pad function to get predictions (avoiding PAD predictions)\n",
    "        batch_preds = predict_without_pad(model, b_input_ids, b_input_mask, pad_token_label_id)\n",
    "        batch_preds = batch_preds.detach().cpu().numpy()\n",
    "    \n",
    "    # Transfer labels to CPU\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    input_ids_list.extend(b_input_ids)\n",
    "    \n",
    "    predictions.extend([list(p) for p in batch_preds])\n",
    "    true_labels.extend(label_ids)\n",
    "\n",
    "# Filter out pad tokens when computing metrics\n",
    "pred_tags = []\n",
    "test_tags = []\n",
    "\n",
    "for p, l in zip(predictions, true_labels):\n",
    "    for p_i, l_i in zip(p, l):\n",
    "        if l_i != pad_token_label_id:  # Only include non-pad tokens\n",
    "            # No need to check if p_i == pad_token_label_id because our prediction function prevents this\n",
    "            pred_tags.append(label_names[p_i])\n",
    "            test_tags.append(label_names[l_i])\n",
    "\n",
    "f1 = f1_score(test_tags, pred_tags, average='micro')\n",
    "\n",
    "# Format output with 4 decimal places\n",
    "output_text = \"Test F1 score (with PAD prevention): {:.4f}\\n\".format(f1)\n",
    "\n",
    "# Print to console\n",
    "print(output_text)\n",
    "\n",
    "# Save to a text file\n",
    "with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
    "    file.write(output_text)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42cd76-91e2-4530-a62c-c3e32a937a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(pred_tags, test_tags)),\n",
    "               columns =['Pred', 'True'])\n",
    "df.to_csv(folder_name + '/test-result-bert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc31b3-c79a-4066-bf98-bc1d9bc4186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(folder_name+\"/test-result-bert.csv\")\n",
    "\n",
    "# Extract true and predicted labels\n",
    "y_true = df[\"True\"]\n",
    "y_pred = df[\"Pred\"]\n",
    "\n",
    "# Define the target classes\n",
    "target_classes = [\"B-class\", \"I-class\", \"B-attr\", \"I-attr\", \"O\"]\n",
    "\n",
    "# Compute precision, recall, and F1-score for the specified classes\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=target_classes, zero_division=0)\n",
    "\n",
    "# Compute overall accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Create a results dictionary\n",
    "metrics = pd.DataFrame({\n",
    "    \"Class\": target_classes,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1-Score\": f1\n",
    "})\n",
    "\n",
    "# Add overall accuracy\n",
    "metrics.loc[len(metrics)] = [\"Overall Accuracy\", accuracy, accuracy, accuracy]\n",
    "\n",
    "# Save metrics to a text file\n",
    "with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
    "    file.write(metrics.to_string(index=False) + \"\\n\")\n",
    "\n",
    "# Display results\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c94be0102f039b7",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce2b962f166c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241bd72f66c1bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(model_name_save)\n",
    "tokenizer.save_pretrained(model_name_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6ce5ff-5ff5-42b5-ac6c-95ca0b6220c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report, f1_score\n",
    "from seqeval.scheme import IOB2  # or another scheme depending on your dataset\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "input_ids_list = []\n",
    "eval_loss = 0  # Make sure this is initialized\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get loss\n",
    "        outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        \n",
    "        # Get predictions using PAD prevention\n",
    "        batch_preds = predict_without_pad(model, b_input_ids, b_input_mask, pad_token_label_id)\n",
    "        batch_preds = batch_preds.detach().cpu().numpy()\n",
    "\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    input_ids_list.extend(b_input_ids)\n",
    "\n",
    "    # Convert predictions and labels to label strings\n",
    "    for pred_seq, label_seq in zip(batch_preds, label_ids):\n",
    "        pred_tags_seq = []\n",
    "        true_tags_seq = []\n",
    "        for p_i, l_i in zip(pred_seq, label_seq):\n",
    "            if l_i != pad_token_label_id:  # Only include non-pad tokens\n",
    "                pred_tags_seq.append(label_names[p_i])\n",
    "                true_tags_seq.append(label_names[l_i])\n",
    "        if pred_tags_seq:  # Only add non-empty sequences\n",
    "            predictions.append(pred_tags_seq)\n",
    "            true_labels.append(true_tags_seq)\n",
    "\n",
    "# Compute F1 score using seqeval\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "output_text = \"Test F1 score (seqeval with PAD prevention): {:.4f}\\n\".format(f1)\n",
    "\n",
    "print(output_text)\n",
    "\n",
    "# Save to a text file\n",
    "with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
    "    file.write(output_text)\n",
    "\n",
    "# Print full classification report\n",
    "print(\"Seqeval classification report:\")\n",
    "print(classification_report(true_labels, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb46c42-716e-4291-8000-228aa1e1cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(predictions, true_labels)),\n",
    "               columns =['Pred', 'True'])\n",
    "df.to_csv(folder_name + '/test-result-bert-seqeval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d16f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a custom data collator to handle padding properly\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "class CustomDataCollatorForTokenClassification(DataCollatorForTokenClassification):\n",
    "    def __call__(self, features):\n",
    "        batch = super().__call__(features)\n",
    "        \n",
    "        # Ensure labels are properly masked with pad_token_label_id\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        # Where attention mask is 0, set the label to pad_token_label_id\n",
    "        labels[attention_mask == 0] = pad_token_label_id\n",
    "        batch['labels'] = labels\n",
    "        \n",
    "        return batch\n",
    "\n",
    "# Create the data collator\n",
    "data_collator = CustomDataCollatorForTokenClassification(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    "    max_length=max_length,\n",
    "    pad_to_multiple_of=8\n",
    ")\n",
    "\n",
    "# You can use this data collator with a PyTorch DataLoader or HuggingFace Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to improve model prediction by preventing pad token predictions\n",
    "def prevent_pad_token_prediction(model, batch_inputs, batch_attention_mask):\n",
    "    \"\"\"\n",
    "    Runs model prediction but ensures pad tokens are never predicted\n",
    "    by setting their logit values very low before argmax.\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    \n",
    "    # Get model outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=batch_inputs, attention_mask=batch_attention_mask)\n",
    "    \n",
    "    # Get logits\n",
    "    if isinstance(outputs, tuple):\n",
    "        logits = outputs[1]  # For our custom model which returns (loss, logits)\n",
    "    else:\n",
    "        logits = outputs  # Direct logits\n",
    "    \n",
    "    # Set logits for the PAD class to a very low value for all positions\n",
    "    # This ensures PAD will never be predicted\n",
    "    min_value = torch.finfo(logits.dtype).min\n",
    "    \n",
    "    # Create a mask for the PAD label\n",
    "    pad_label_mask = torch.ones_like(logits)\n",
    "    pad_label_mask[:, :, pad_token_label_id] = 0\n",
    "    \n",
    "    # Set PAD label's logits to min_value\n",
    "    masked_logits = logits.clone()\n",
    "    masked_logits[:, :, pad_token_label_id] = min_value\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = torch.argmax(masked_logits, dim=-1)\n",
    "    \n",
    "    return predictions, logits\n",
    "\n",
    "# Example usage in evaluation:\n",
    "# predictions, _ = prevent_pad_token_prediction(model, b_input_ids, b_input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe20062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to use the prevent_pad_token_prediction function during evaluation\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # Use the function to prevent PAD predictions\n",
    "    with torch.no_grad():\n",
    "        predictions, _ = prevent_pad_token_prediction(model, b_input_ids, b_input_mask)\n",
    "    \n",
    "    # Convert to CPU and numpy\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    labels = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    all_predictions.extend([list(p) for p in predictions])\n",
    "    all_labels.extend(labels)\n",
    "\n",
    "# Process for metrics\n",
    "pred_tags = []\n",
    "true_tags = []\n",
    "\n",
    "for p, l in zip(all_predictions, all_labels):\n",
    "    for p_i, l_i in zip(p, l):\n",
    "        if l_i != pad_token_label_id:  # Only include non-pad tokens\n",
    "            pred_tags.append(label_names[p_i])\n",
    "            true_tags.append(label_names[l_i])\n",
    "\n",
    "# Calculate F1 score\n",
    "test_f1 = f1_score(true_tags, pred_tags, average='micro')\n",
    "print(f\"Test F1 score with PAD prevention: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34245b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify saving function to handle our custom model\n",
    "def save_model(model, save_path):\n",
    "    # If using custom model, save the base model\n",
    "    if hasattr(model, 'base_model'):\n",
    "        model.base_model.save_pretrained(save_path)\n",
    "    else:\n",
    "        model.save_pretrained(save_path)\n",
    "    tokenizer.save_pretrained(save_path)\n",
    "\n",
    "# Save the model\n",
    "save_model(model, model_name_save)\n",
    "print(f\"Model saved to {model_name_save}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56abb4f",
   "metadata": {},
   "source": [
    "# Preventing PAD Token Prediction During Inference\n",
    "\n",
    "This section introduces functions to ensure that the model never predicts PAD tokens during inference by masking the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b97e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def mask_pad_predictions(logits, pad_token_id=5):\n",
    "    \"\"\"\n",
    "    Modifies logits to prevent PAD token predictions by setting its logits to negative infinity.\n",
    "    \n",
    "    Args:\n",
    "        logits: Model logits of shape [batch_size, seq_length, num_classes]\n",
    "        pad_token_id: ID of the PAD token to mask\n",
    "        \n",
    "    Returns:\n",
    "        Modified logits with PAD token logits set to -infinity\n",
    "    \"\"\"\n",
    "    # Make a copy of the logits to avoid modifying the original\n",
    "    modified_logits = logits.clone()\n",
    "    \n",
    "    # Set pad token logits to a very negative number (effectively -infinity)\n",
    "    modified_logits[:, :, pad_token_id] = -1e10\n",
    "    \n",
    "    return modified_logits\n",
    "\n",
    "def predict_without_pad(model, input_ids, attention_mask, pad_token_label_id):\n",
    "    \"\"\"\n",
    "    Run model prediction ensuring PAD tokens are never predicted.\n",
    "    \n",
    "    Args:\n",
    "        model: The token classification model\n",
    "        input_ids: Input token IDs\n",
    "        attention_mask: Attention mask\n",
    "        pad_token_label_id: ID of the PAD token label\n",
    "        \n",
    "    Returns:\n",
    "        Predictions with PAD tokens removed\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Get logits (handle both tuples and direct outputs)\n",
    "        if isinstance(outputs, tuple):\n",
    "            logits = outputs[1]\n",
    "        else:\n",
    "            logits = outputs\n",
    "        \n",
    "        # Mask PAD token predictions \n",
    "        masked_logits = mask_pad_predictions(logits, pad_token_label_id)\n",
    "        \n",
    "        # Get predictions from masked logits\n",
    "        predictions = torch.argmax(masked_logits, dim=-1)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70653b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to modify a pre-trained model to prevent PAD token prediction during inference\n",
    "def add_pad_prevention_to_model(model_path):\n",
    "    \"\"\"\n",
    "    Loads a model and adds a custom forward method to prevent PAD token prediction.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model\n",
    "    \n",
    "    Returns:\n",
    "        Modified model that will never predict PAD tokens\n",
    "    \"\"\"\n",
    "    from transformers import AutoModelForTokenClassification\n",
    "    import types\n",
    "    \n",
    "    # Load the model\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "    \n",
    "    # Original forward method\n",
    "    original_forward = model.forward\n",
    "    \n",
    "    # Define new forward method that prevents PAD predictions\n",
    "    def forward_with_pad_prevention(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = original_forward(input_ids=input_ids, attention_mask=attention_mask, labels=labels, **kwargs)\n",
    "        \n",
    "        if labels is None:  # Only modify logits during inference, not training\n",
    "            # Get logits\n",
    "            if hasattr(outputs, \"logits\"):\n",
    "                logits = outputs.logits\n",
    "            else:\n",
    "                # If outputs is a tuple, assume the second element is logits (typical for HF models)\n",
    "                logits = outputs[1] if isinstance(outputs, tuple) else outputs\n",
    "            \n",
    "            # Identify the PAD token ID\n",
    "            if hasattr(self.config, \"pad_token_id\"):\n",
    "                pad_token_id = self.config.pad_token_id\n",
    "            else:\n",
    "                # If not specified, use the last class index\n",
    "                pad_token_id = self.config.num_labels - 1\n",
    "            \n",
    "            # Mask PAD token logits\n",
    "            masked_logits = mask_pad_predictions(logits, pad_token_id)\n",
    "            \n",
    "            # Replace the original logits with the masked ones\n",
    "            if hasattr(outputs, \"logits\"):\n",
    "                outputs.logits = masked_logits\n",
    "            else:\n",
    "                # If outputs is a tuple, update the logits part\n",
    "                if isinstance(outputs, tuple):\n",
    "                    outputs_list = list(outputs)\n",
    "                    outputs_list[1] = masked_logits\n",
    "                    outputs = tuple(outputs_list)\n",
    "                else:\n",
    "                    outputs = masked_logits\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    # Replace the forward method\n",
    "    model.forward = types.MethodType(forward_with_pad_prevention, model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage to load a model with PAD prevention:\n",
    "# model = add_pad_prevention_to_model(model_name_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab51789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Predicting on a single example with PAD prevention\n",
    "def predict_single_example_with_pad_prevention(model, tokenizer, tokens, label_names, pad_token_label_id):\n",
    "    \"\"\"\n",
    "    Run prediction on a single example with PAD prevention\n",
    "    \n",
    "    Args:\n",
    "        model: Token classification model\n",
    "        tokenizer: Tokenizer\n",
    "        tokens: List of tokens to classify\n",
    "        label_names: List of label names\n",
    "        pad_token_label_id: ID of the PAD token label\n",
    "    \n",
    "    Returns:\n",
    "        Predicted labels for the tokens\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(tokens, \n",
    "                      truncation=True, \n",
    "                      is_split_into_words=True, \n",
    "                      padding='max_length', \n",
    "                      max_length=max_length, \n",
    "                      return_tensors=\"pt\")\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    \n",
    "    # Get predictions with PAD prevention\n",
    "    predictions = predict_without_pad(model, input_ids, attention_mask, pad_token_label_id)\n",
    "    predictions = predictions.detach().cpu().numpy()[0]\n",
    "    \n",
    "    # Convert word pieces back to original tokens and assign labels\n",
    "    word_ids = inputs.word_ids(0)\n",
    "    previous_word_idx = None\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx is None or word_idx == previous_word_idx:\n",
    "            # Skip special tokens and continuation of words\n",
    "            continue\n",
    "        \n",
    "        # Get predicted label for this token\n",
    "        predicted_labels.append(label_names[predictions[idx]])\n",
    "        previous_word_idx = word_idx\n",
    "    \n",
    "    # Match predictions with original tokens\n",
    "    result = list(zip(tokens[:len(predicted_labels)], predicted_labels))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# sample_tokens = [\"User\", \"logs\", \"in\", \"to\", \"the\", \"system\"]\n",
    "# predictions = predict_single_example_with_pad_prevention(model, tokenizer, sample_tokens, label_names, pad_token_label_id)\n",
    "# print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
