{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Already done\n",
        "# pip install transformers==2.9\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1740908084155
        }
      },
      "id": "125562b3-559c-46d6-a17e-fd827757b1aa"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "folder_name = \"result-bert-large\"\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1740908085971
        }
      },
      "id": "6de8e206-d2fa-4cfa-9596-414c48965711"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_train = []\n",
        "labels_train = []\n",
        "\n",
        "tokens = []\n",
        "token_labels = []\n",
        "unique_labels_train = set()\n",
        "\n",
        "with open(\"corpus-raymond/train-full.txt\", newline = '') as lines:                                                                                          \n",
        "  \n",
        "    line_reader = csv.reader(lines, delimiter='\\t')\n",
        "\n",
        "    for line in line_reader:\n",
        "        \n",
        "        if line == []:\n",
        "\n",
        "            sentences_train.append(tokens)\n",
        "            labels_train.append(token_labels)           \n",
        "    \n",
        "            tokens = []\n",
        "            token_labels = []        \n",
        "\n",
        "        else: \n",
        "            #print(str(line[0]))\n",
        "            tokens.append(line[0])\n",
        "            token_labels.append(line[1])\n",
        "\n",
        "            unique_labels_train.add(line[1])"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1740908086220
        }
      },
      "id": "d56252cd-d718-4c80-8ccc-bc8ba88bc41a"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "sentences_dev = []\n",
        "labels_dev = []\n",
        "unique_labels_dev = set()\n",
        "\n",
        "tokens = []\n",
        "token_labels = []\n",
        "\n",
        "with open(\"corpus-raymond/validation-full.txt\", newline='', encoding='utf-8') as file:\n",
        "    line_reader = csv.reader(file, delimiter='\\t')\n",
        "\n",
        "    for line in line_reader:\n",
        "        # Remove empty spaces and ensure valid parsing\n",
        "        line = [x.strip() for x in line if x.strip()]  # Strip whitespace & ignore empty columns\n",
        "        \n",
        "        if not line:  # If it's an empty line, treat it as a sentence separator\n",
        "            if tokens:  # Avoid adding empty lists\n",
        "                sentences_dev.append(tokens)\n",
        "                labels_dev.append(token_labels)\n",
        "                tokens, token_labels = [], []  # Reset for next sentence\n",
        "        else:\n",
        "            if len(line) == 1 and line[0] == '\\\"':  # Handle single double-quote case\n",
        "                tokens.append('\\\"')\n",
        "                token_labels.append('O')  # Assuming label should be 'O' if unknown\n",
        "            elif len(line) >= 2:  # Normal case (word, label)\n",
        "                tokens.append(line[0])\n",
        "                token_labels.append(line[1])\n",
        "                unique_labels_dev.add(line[1])\n",
        "\n",
        "# Ensure last collected sentence is added\n",
        "if tokens:\n",
        "    sentences_dev.append(tokens)\n",
        "    labels_dev.append(token_labels)\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1740908086394
        }
      },
      "id": "570990f1-c1d2-4db0-bfd4-de6c18e39c75"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_test = []\n",
        "labels_test = []\n",
        "\n",
        "tokens = []\n",
        "token_labels = []\n",
        "unique_labels_test = set()\n",
        "\n",
        "with open(\"corpus-raymond/validation-full.txt\", newline='', encoding='utf-8') as file:\n",
        "    line_reader = csv.reader(file, delimiter='\\t')\n",
        "\n",
        "    for line in line_reader:\n",
        "        # Remove empty spaces and ensure valid parsing\n",
        "        line = [x.strip() for x in line if x.strip()]  # Strip whitespace & ignore empty columns\n",
        "        \n",
        "        if not line:  # If it's an empty line, treat it as a sentence separator\n",
        "            if tokens:  # Avoid adding empty lists\n",
        "                sentences_test.append(tokens)\n",
        "                labels_test.append(token_labels)\n",
        "                tokens, token_labels = [], []  # Reset for next sentence\n",
        "        else:\n",
        "            if len(line) == 1 and line[0] == '\\\"':  # Handle single double-quote case\n",
        "                tokens.append('\\\"')\n",
        "                token_labels.append('O')  # Assuming label should be 'O' if unknown\n",
        "            elif len(line) >= 2:  # Normal case (word, label)\n",
        "                tokens.append(line[0])\n",
        "                token_labels.append(line[1])\n",
        "                unique_labels_test.add(line[1])\n",
        "\n",
        "# Ensure last collected sentence is added\n",
        "if tokens:\n",
        "    sentences_test.append(tokens)\n",
        "    labels_test.append(token_labels)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1740908086561
        }
      },
      "id": "af4f8038-a683-4249-bda7-4ef05387acba"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_test[0][:10] # First 10 elements of sentence 1"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "['the',\n 'clinic',\n 'basically',\n 'schedule',\n 'patient',\n ',',\n 'provide',\n 'service',\n 'for',\n 'they']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1740908086805
        }
      },
      "id": "059392ef-d305-4d6c-9aec-9172d08d38b1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels_test[0][:10]) # First 10 labels of sentence 1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['O', 'O', 'O', 'O', 'B-class', 'O', 'O', 'B-class', 'O', 'O']\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1740908086967
        }
      },
      "id": "819f9bc0-2329-47c6-b5e0-925c1d2089f0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Label values\n",
        "tag_values = list(unique_labels_train)\n",
        "tag_values.append(\"PAD\")\n",
        "tag2idx = {t: i for i, t in enumerate(tag_values)}"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1740908087192
        }
      },
      "id": "69da810f-3060-4e7d-bf63-f780fb4e3e8d"
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare data for BERT\n",
        "# Import pytorch and transformers library\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "\n",
        "from tensorflow import keras \n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "torch.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "'1.12.1'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1740908091703
        }
      },
      "id": "730e0067-57e8-43b2-a585-95a2e10cddd5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define BERT parameters\n",
        "# Sentence length\n",
        "MAX_LEN = 175\n",
        "# Batch size\n",
        "bs = 32 "
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1740908091904
        }
      },
      "id": "d691ae5e-60ad-4639-a3c7-31a923461d8e"
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA device (GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "# torch.cuda.get_device_name(0)\n",
        "# Print state of GPU\n",
        "!nvidia-smi"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\r\n\r\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1740908092071
        }
      },
      "id": "ba9e890b-5ba4-44a7-b580-480ec4481420"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import BERT tokenizer\n",
        "# Use the BETO model (BERT for Spanish), available in the Transformers library  \n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased',use_fast=False)\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1740908092619
        }
      },
      "id": "c7f3b613-0e01-4c10-8861-45f4b1815be0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to tokenize and preserve labels\n",
        "def tokenize_and_keep_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize each word and count number of its subwords\n",
        "        # We force conversion to string to avoid errors with float elements\n",
        "        tokenized_word = tokenizer.tokenize(str(word))\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # The tokenized word is added to the resulting tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # The same label is added to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1740908092767
        }
      },
      "id": "2580c6f5-06b8-4b79-b453-5f90599f9b6f"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_and_labels_train = [\n",
        "    tokenize_and_keep_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences_train, labels_train)\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1740908095906
        }
      },
      "id": "2ea005fd-0f8e-4661-ab2e-444d33a3fe95"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_and_labels_dev = [\n",
        "    tokenize_and_keep_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences_dev, labels_dev)\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1740908096531
        }
      },
      "id": "98153f0b-0980-46cf-bd8e-707fff75f16e"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_and_labels_test = [\n",
        "    tokenize_and_keep_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences_test, labels_test)\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1740908097112
        }
      },
      "id": "d670d60e-805a-4369-ba34-21888f059303"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_train = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_train]\n",
        "labels_train = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels_train]\n",
        "\n",
        "tokenized_texts_dev = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_dev]\n",
        "labels_dev = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels_dev]\n",
        "\n",
        "tokenized_texts_test = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_test]\n",
        "labels_test = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels_test]"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1740908097744
        }
      },
      "id": "a4c5cbc6-c1f0-4a4e-9c20-1a7c0c7510b7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding of sentences according to desired input length\n",
        "input_ids_train = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_train],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids_dev = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_dev],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids_test = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_test],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1740908098508
        }
      },
      "id": "9e31ec4b-d77a-441d-8782-5a5cc2c18f67"
    },
    {
      "cell_type": "code",
      "source": [
        "# Paddding of labels with regard to input length\n",
        "tags_train = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_train],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "tags_dev = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_dev],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "tags_test = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_test],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1740908099226
        }
      },
      "id": "6b24cdb0-e082-436c-aa3d-96bd71e46c59"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the attention mask to ignore the padded elements in the sequences during training, development and testing\n",
        "attention_masks_train = [[float(i != 0.0) for i in ii] for ii in input_ids_train]\n",
        "attention_masks_dev = [[float(i != 0.0) for i in ii] for ii in input_ids_dev]\n",
        "attention_masks_test = [[float(i != 0.0) for i in ii] for ii in input_ids_test]"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1740908099989
        }
      },
      "id": "6e8eb718-1a6a-424d-9f2b-6722a0ff4346"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to torch tensors\n",
        "train_inputs = torch.tensor(input_ids_train)\n",
        "dev_inputs = torch.tensor(input_ids_dev)\n",
        "test_inputs = torch.tensor(input_ids_test)\n",
        "train_tags = torch.tensor(tags_train)\n",
        "dev_tags = torch.tensor(tags_dev)\n",
        "test_tags = torch.tensor(tags_test)\n",
        "train_masks = torch.tensor(attention_masks_train)\n",
        "dev_masks = torch.tensor(attention_masks_dev)\n",
        "test_masks = torch.tensor(attention_masks_test)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1740908100512
        }
      },
      "id": "43649f73-0361-4c00-a7cb-8c02d851ce65"
    },
    {
      "cell_type": "code",
      "source": [
        "# We define the dataloaders. \n",
        "# Shuffle the data for training using RandomSampler\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "# Load dev and test data sequentially with SequentialSampler.\n",
        "dev_data = TensorDataset(dev_inputs, dev_masks, dev_tags)\n",
        "dev_sampler = SequentialSampler(dev_data)\n",
        "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=bs)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_tags)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1740908100911
        }
      },
      "id": "f511d5b9-d6fd-4080-8d4f-058aa2cffc92"
    },
    {
      "cell_type": "code",
      "source": [
        "# The BertForTokenClassification class is used for token-level predictions. \n",
        "# It includes the BERT model and carries out token-level classification in the last layer\n",
        "# We use the Adam optimizer\n",
        "from transformers import BertForTokenClassification, AdamW "
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1740908101434
        }
      },
      "id": "cd412309-b4e5-4971-9e29-61d9689ec8b7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model and use the pretrained BETO model (BERT for Spanish)\n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-large-uncased\",\n",
        "    num_labels=len(tag2idx),\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1740908108354
        }
      },
      "id": "798b6d06-e01a-4b1d-8e35-278226257211"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model to the GPU\n",
        "#model.cuda();"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1740908109292
        }
      },
      "id": "651511cc-46d3-4fb4-835e-c9a0e446932c"
    },
    {
      "cell_type": "code",
      "source": [
        "# weight_decay is a regularization procedure with regard to the weight matrices\n",
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "# Adam optimizer\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/custom_37/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1740908109908
        }
      },
      "id": "b2e87b61-e29d-4868-9765-a4af1c354dd9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import a scheduler to reduce the learning rate \n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs; the BERT paper uses 4\n",
        "epochs = 4\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1740908110526
        }
      },
      "id": "8399d3b9-12d3-4ae1-8a9d-90ab004a11d1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modules to measure the progression of training\n",
        "# Done\n",
        "# !pip install seqeval"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1740908110747
        }
      },
      "id": "7fa09649-860e-4e9c-877c-cf9e6a355879"
    },
    {
      "cell_type": "code",
      "source": [
        "import seqeval\n",
        "#from seqeval.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
        "from sklearn.metrics import f1_score, classification_report, precision_recall_fscore_support\n",
        "from tqdm import tqdm, trange"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1740908110991
        }
      },
      "id": "8d8e3d8f-3ddd-464f-acff-eb8b05289712"
    },
    {
      "cell_type": "code",
      "source": [
        "#import wandb\n",
        "#wandb.login()"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1740908111501
        }
      },
      "id": "87c9efc8-7864-444e-9943-5942be8ba67e"
    },
    {
      "cell_type": "code",
      "source": [
        "#wandb.init(project=\"pfsa-id-gtx1080ti-bert-v1\",entity=\"sigitpurnomo\")"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1740908112125
        }
      },
      "id": "7705caa1-a74a-4e02-a648-b5e3f5c21e4c"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "# To measure execution time of this cell\n",
        "\n",
        "# Train the model for; the BERT paper uses 4\n",
        "## Store the average loss after each epoch; these values are used to plot the loss.\n",
        "loss_values, development_loss_values = [], []\n",
        "\n",
        "#data_seqeval = {\n",
        "#    \"predicted_tags\": [],\n",
        "#    \"true_tags\": [],\n",
        "#}\n",
        "#df_seqeval = None\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    #\n",
        "    # Training\n",
        "    #\n",
        "    # Set the model into training mode\n",
        "    model.train()\n",
        "    # Reset the total loss for each epoch\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Transfer batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Remove previous gradients before each backward pass\n",
        "        model.zero_grad()\n",
        "        # forward pass\n",
        "        # This returns the loss (not the model output) since we have input the labels.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "        # Get the loss\n",
        "        loss = outputs[0]\n",
        "        # Backward pass to compute the gradients\n",
        "        loss.backward()\n",
        "        # Train loss\n",
        "        total_loss += loss.item()\n",
        "        # Clip the norm of the gradient\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "    \n",
        "\n",
        "    # Store each loss value for plotting the learning curve afterwards\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    # After each training epoch, measure performance on development set\n",
        "\n",
        "    # Set the model into evaluation mode\n",
        "    model.eval()\n",
        "    # Reset the development loss for this epoch\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in dev_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # The model must not compute or save gradients, in order to save memory and speed up this step\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, compute predictions\n",
        "            # This will return the logits (logarithm of the odds), not the loss (we do not provide labels)\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "        # Transfer logits and labels to CPU\n",
        "        logits = outputs[1].detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Compute the accuracy for this batch of development sentences\n",
        "        eval_loss += outputs[0].mean().item()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.extend(label_ids)\n",
        "        \n",
        "        #data_seqeval[\"batch\"].append(str(batch))\n",
        "        #data_seqeval[\"true_tags\"].append(str(label_ids))\n",
        "        #data_seqeval[\"predicted_tags\"].append(str([list(p) for p in np.argmax(logits, axis=2)]))\n",
        "\n",
        "    #df_seqeval = pd.DataFrame(data_seqeval)\n",
        "    #wandb.log({f\"dataframe_seqeval\": wandb.Table(dataframe=df_seqeval)})\n",
        "    \n",
        "    eval_loss = eval_loss / len(dev_dataloader)\n",
        "    development_loss_values.append(eval_loss)\n",
        "    print(\"Development loss: {}\".format(eval_loss))\n",
        "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "    dev_tags = [tag_values[l_i] for l in true_labels\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "    f1 = f1_score(pred_tags, dev_tags, average='micro')\n",
        "\n",
        "    # Format output with 4 decimal places\n",
        "    output_text = \"Test F1 score: {:.4f}\".format(f1)\n",
        "\n",
        "    # Print to console\n",
        "    print(output_text)\n",
        "\n",
        "    # Save to a text file\n",
        "    with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
        "        file.write(output_text)\n",
        "    #print(\"Development classification report:\\n{}\".format(classification_report(pred_tags, dev_tags,digits=4)))\n",
        "    print()\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\rEpoch:   0%|          | 0/4 [00:00<?, ?it/s]"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Average train loss: 0.8116358305726733\n\nAverage train loss: 0.24886962558541978\nDevelopment loss: 0.17209635227918624\nTest F1 score: 0.7158\n\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "id": "fb45a631-fd1a-464e-8796-46280326bff9"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(pred_tags, dev_tags)),\n",
        "               columns =['Pred', 'True'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1740907261933
        }
      },
      "id": "310dcdc4-f5e5-4d52-b817-1ddf90188e2f"
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(folder_name+'/train-val-result-bert.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1740907261949
        }
      },
      "id": "bd1f278d-2ddc-4e4f-9c6d-52e435941af8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training loss\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
        "plt.plot(development_loss_values, 'r-o', label=\"validation loss\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Learning curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1740907261961
        }
      },
      "id": "8e860ba8-a0da-4cc5-912d-59d24da75563"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the model to the test set\n",
        "# Set again the model into evaluation mode\n",
        "model.eval()\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "input_ids_list = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # The model must not compute or store gradients\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate predictions.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "    # Transfer logits and labels to CPU\n",
        "    logits = outputs[1].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    input_ids_list.extend(b_input_ids)\n",
        "    \n",
        "    # Calculate the accuracy for this batch of test sentences\n",
        "    eval_loss += outputs[0].mean().item()\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    true_labels.extend(label_ids)\n",
        "\n",
        "pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "test_tags = [tag_values[l_i] for l in true_labels\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "#print(str(pred_tags))\n",
        "#print(str(test_tags))\n",
        "# Compute F1 score\n",
        "f1 = f1_score(pred_tags, test_tags, average='micro')\n",
        "\n",
        "# Format output with 4 decimal places\n",
        "output_text = \"Test F1 score: {:.4f}\".format(f1)\n",
        "\n",
        "# Print to console\n",
        "print(output_text)\n",
        "\n",
        "# Save to a text file\n",
        "with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
        "    file.write(output_text)\n",
        "#print(\"Test classification report: {}\".format(classification_report(pred_tags, test_tags,digits=4)))\n",
        "\n",
        "\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1740907261978
        }
      },
      "id": "0d64d31a-e5b6-40ae-bbfb-0bf300a7ffc5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# Print optimizer's state_dict\n",
        "#print(\"Optimizer's state_dict:\")\n",
        "#for var_name in optimizer.state_dict():\n",
        "#    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1740907261994
        }
      },
      "id": "6cdb58de-aa8e-4bca-b481-c8708e43a28c"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(pred_tags, test_tags)),\n",
        "               columns =['Pred', 'True'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1740907262008
        }
      },
      "id": "fb3fd637-aa6a-4435-9030-20f6060e1629"
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(folder_name+'/test-result-bert.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1740907262022
        }
      },
      "id": "3df4c9a0-dfbe-46d7-805d-82d7a465e2d7"
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"bert-large-local\")\n",
        "tokenizer.save_pretrained(\"bert-large-local\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "10aa1d62-6169-430a-9d43-c38b970dec49"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the model to the test with only structure_focus set\n",
        "# Set again the model into evaluation mode\n",
        "\n",
        "tokenized_texts_and_labels_test = [\n",
        "    tokenize_and_keep_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences_test_class, labels_test_class)\n",
        "]\n",
        "\n",
        "tags_test_class = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_test],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "test_class_inputs = torch.tensor(input_ids_test_class)\n",
        "test_class_tags = torch.tensor(tags_class_test)\n",
        "\n",
        "attention_masks_test_class = [[float(i != 0.0) for i in ii] for ii in input_ids_test_class]\n",
        "test_class_masks = torch.tensor(attention_masks_test_class)\n",
        "\n",
        "test_class_data = TensorDataset(test_inputs, test_masks, test_tags)\n",
        "test_class_sampler = SequentialSampler(test_data)\n",
        "test_class_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)\n",
        "\n",
        "model.eval()\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "input_ids_list = []\n",
        "\n",
        "for batch in test_class_dataloader:\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # The model must not compute or store gradients\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate predictions.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "    # Transfer logits and labels to CPU\n",
        "    logits = outputs[1].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    input_ids_list.extend(b_input_ids)\n",
        "    \n",
        "    # Calculate the accuracy for this batch of test sentences\n",
        "    eval_loss += outputs[0].mean().item()\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    true_labels.extend(label_ids)\n",
        "\n",
        "pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "test_tags = [tag_values[l_i] for l in true_labels\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "#print(str(pred_tags))\n",
        "#print(str(test_tags))\n",
        "# Compute F1 score\n",
        "f1 = f1_score(pred_tags, test_tags, average='micro')\n",
        "\n",
        "# Format output with 4 decimal places\n",
        "output_text = \"Test with structure only F1 score: {:.4f}\".format(f1)\n",
        "\n",
        "# Print to console\n",
        "print(output_text)\n",
        "\n",
        "# Save to a text file\n",
        "with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
        "    file.write(output_text)\n",
        "#print(\"Test classification report: {}\".format(classification_report(pred_tags, test_tags,digits=4)))\n",
        "\n",
        "\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "31d32fb0-2784-4257-a0ee-4c773f8e2830"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "custom_37",
      "language": "python",
      "display_name": "Python_37"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "custom_37"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}