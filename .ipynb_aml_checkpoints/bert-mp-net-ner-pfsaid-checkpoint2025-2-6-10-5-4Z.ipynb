{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Already done\n",
        "# pip install transformers==2.9\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1741255364472
        }
      },
      "id": "125562b3-559c-46d6-a17e-fd827757b1aa"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "folder_name = \"result-bert-mpnettokenizer\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1741255366191
        }
      },
      "id": "6de8e206-d2fa-4cfa-9596-414c48965711"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_train = []\n",
        "labels_train = []\n",
        "\n",
        "tokens = []\n",
        "token_labels = []\n",
        "unique_labels_train = set()\n",
        "\n",
        "with open(\"corpus-raymond/train-full.txt\", newline = '') as lines:                                                                                          \n",
        "  \n",
        "    line_reader = csv.reader(lines, delimiter='\\t')\n",
        "\n",
        "    for line in line_reader:\n",
        "        \n",
        "        if line == []:\n",
        "\n",
        "            sentences_train.append(tokens)\n",
        "            labels_train.append(token_labels)           \n",
        "    \n",
        "            tokens = []\n",
        "            token_labels = []        \n",
        "\n",
        "        else: \n",
        "            #print(str(line[0]))\n",
        "            tokens.append(line[0])\n",
        "            token_labels.append(line[1])\n",
        "\n",
        "            unique_labels_train.add(line[1])"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1741255366421
        }
      },
      "id": "d56252cd-d718-4c80-8ccc-bc8ba88bc41a"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "sentences_dev = []\n",
        "labels_dev = []\n",
        "unique_labels_dev = set()\n",
        "\n",
        "tokens = []\n",
        "token_labels = []\n",
        "\n",
        "with open(\"corpus-raymond/validation-full.txt\", newline='', encoding='utf-8') as file:\n",
        "    line_reader = csv.reader(file, delimiter='\\t')\n",
        "\n",
        "    for line in line_reader:\n",
        "        # Remove empty spaces and ensure valid parsing\n",
        "        line = [x.strip() for x in line if x.strip()]  # Strip whitespace & ignore empty columns\n",
        "        \n",
        "        if not line:  # If it's an empty line, treat it as a sentence separator\n",
        "            if tokens:  # Avoid adding empty lists\n",
        "                sentences_dev.append(tokens)\n",
        "                labels_dev.append(token_labels)\n",
        "                tokens, token_labels = [], []  # Reset for next sentence\n",
        "        else:\n",
        "            if len(line) == 1 and line[0] == '\\\"':  # Handle single double-quote case\n",
        "                tokens.append('\\\"')\n",
        "                token_labels.append('O')  # Assuming label should be 'O' if unknown\n",
        "            elif len(line) >= 2:  # Normal case (word, label)\n",
        "                tokens.append(line[0])\n",
        "                token_labels.append(line[1])\n",
        "                unique_labels_dev.add(line[1])\n",
        "\n",
        "# Ensure last collected sentence is added\n",
        "if tokens:\n",
        "    sentences_dev.append(tokens)\n",
        "    labels_dev.append(token_labels)\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1741255368099
        }
      },
      "id": "570990f1-c1d2-4db0-bfd4-de6c18e39c75"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_test = []\n",
        "labels_test = []\n",
        "\n",
        "tokens = []\n",
        "token_labels = []\n",
        "unique_labels_test = set()\n",
        "\n",
        "with open(\"corpus-raymond/validation-full.txt\", newline='', encoding='utf-8') as file:\n",
        "    line_reader = csv.reader(file, delimiter='\\t')\n",
        "\n",
        "    for line in line_reader:\n",
        "        # Remove empty spaces and ensure valid parsing\n",
        "        line = [x.strip() for x in line if x.strip()]  # Strip whitespace & ignore empty columns\n",
        "        \n",
        "        if not line:  # If it's an empty line, treat it as a sentence separator\n",
        "            if tokens:  # Avoid adding empty lists\n",
        "                sentences_test.append(tokens)\n",
        "                labels_test.append(token_labels)\n",
        "                tokens, token_labels = [], []  # Reset for next sentence\n",
        "        else:\n",
        "            if len(line) == 1 and line[0] == '\\\"':  # Handle single double-quote case\n",
        "                tokens.append('\\\"')\n",
        "                token_labels.append('O')  # Assuming label should be 'O' if unknown\n",
        "            elif len(line) >= 2:  # Normal case (word, label)\n",
        "                tokens.append(line[0])\n",
        "                token_labels.append(line[1])\n",
        "                unique_labels_test.add(line[1])\n",
        "\n",
        "# Ensure last collected sentence is added\n",
        "if tokens:\n",
        "    sentences_test.append(tokens)\n",
        "    labels_test.append(token_labels)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1741255370120
        }
      },
      "id": "af4f8038-a683-4249-bda7-4ef05387acba"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_test[0][:10] # First 10 elements of sentence 1"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "['the',\n 'clinic',\n 'basically',\n 'schedule',\n 'patient',\n ',',\n 'provide',\n 'service',\n 'for',\n 'they']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1741255373118
        }
      },
      "id": "059392ef-d305-4d6c-9aec-9172d08d38b1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels_test[0][:10]) # First 10 labels of sentence 1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['O', 'O', 'O', 'O', 'B-class', 'O', 'O', 'B-class', 'O', 'O']\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1741255374264
        }
      },
      "id": "819f9bc0-2329-47c6-b5e0-925c1d2089f0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Label values\n",
        "tag_values = list(unique_labels_train)\n",
        "tag_values.append(\"PAD\")\n",
        "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
        "tag2idx"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "{'I-class': 0, 'B-class': 1, 'I-attr': 2, 'O': 3, 'B-attr': 4, 'PAD': 5}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1741255382129
        }
      },
      "id": "69da810f-3060-4e7d-bf63-f780fb4e3e8d"
    },
    {
      "cell_type": "code",
      "source": [
        "## Prepare data for BERT\n",
        "# Import pytorch and transformers library\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "\n",
        "from tensorflow import keras \n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "torch.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'1.12.1'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1741255406142
        }
      },
      "id": "730e0067-57e8-43b2-a585-95a2e10cddd5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define BERT parameters\n",
        "# Sentence length\n",
        "MAX_LEN = 175\n",
        "# Batch size\n",
        "bs = 32 "
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1741255407100
        }
      },
      "id": "d691ae5e-60ad-4639-a3c7-31a923461d8e"
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA device (GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "# torch.cuda.get_device_name(0)\n",
        "# Print state of GPU\n",
        "!nvidia-smi"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\r\n\r\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1741255408446
        }
      },
      "id": "ba9e890b-5ba4-44a7-b580-480ec4481420"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import BERT tokenizer\n",
        "# Use the BETO model (BERT for Spanish), available in the Transformers library  \n",
        "from transformers import MPNetTokenizer\n",
        "tokenizer = MPNetTokenizer.from_pretrained('microsoft/mpnet-base',use_fast=False)\n"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1741255410991
        }
      },
      "id": "c7f3b613-0e01-4c10-8861-45f4b1815be0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to tokenize and preserve labels\n",
        "def tokenize_and_keep_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize each word and count number of its subwords\n",
        "        # We force conversion to string to avoid errors with float elements\n",
        "        tokenized_word = tokenizer.tokenize(str(word))\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # The tokenized word is added to the resulting tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # The same label is added to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "    print(\"sentence: \" + sentence)\n",
        "    print(\"text_labels: \" + text_labels)\n",
        "    print(\"tokenized sentence: \", end='')\n",
        "    print(tokenized_sentence)\n",
        "    print(\"tokenized sentence: \", end='')\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1740934397401
        }
      },
      "id": "2580c6f5-06b8-4b79-b453-5f90599f9b6f"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_and_labels_train = [\n",
        "    tokenize_and_keep_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences_train, labels_train)\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1740934400721
        }
      },
      "id": "2ea005fd-0f8e-4661-ab2e-444d33a3fe95"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_and_labels_dev = [\n",
        "    tokenize_and_keep_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences_dev, labels_dev)\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1740934400994
        }
      },
      "id": "98153f0b-0980-46cf-bd8e-707fff75f16e"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_and_labels_test = [\n",
        "    tokenize_and_keep_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences_test, labels_test)\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1740934401263
        }
      },
      "id": "d670d60e-805a-4369-ba34-21888f059303"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_train = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_train]\n",
        "labels_train = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels_train]\n",
        "\n",
        "tokenized_texts_dev = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_dev]\n",
        "labels_dev = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels_dev]\n",
        "\n",
        "tokenized_texts_test = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_test]\n",
        "labels_test = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels_test]"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1740934401412
        }
      },
      "id": "a4c5cbc6-c1f0-4a4e-9c20-1a7c0c7510b7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding of sentences according to desired input length\n",
        "input_ids_train = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_train],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids_dev = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_dev],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids_test = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_test],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1740934401712
        }
      },
      "id": "9e31ec4b-d77a-441d-8782-5a5cc2c18f67"
    },
    {
      "cell_type": "code",
      "source": [
        "# Paddding of labels with regard to input length\n",
        "tags_train = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_train],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "tags_dev = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_dev],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "tags_test = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_test],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1740934401845
        }
      },
      "id": "6b24cdb0-e082-436c-aa3d-96bd71e46c59"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the attention mask to ignore the padded elements in the sequences during training, development and testing\n",
        "attention_masks_train = [[float(i != 0.0) for i in ii] for ii in input_ids_train]\n",
        "attention_masks_dev = [[float(i != 0.0) for i in ii] for ii in input_ids_dev]\n",
        "attention_masks_test = [[float(i != 0.0) for i in ii] for ii in input_ids_test]"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1740934401987
        }
      },
      "id": "6e8eb718-1a6a-424d-9f2b-6722a0ff4346"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to torch tensors\n",
        "train_inputs = torch.tensor(input_ids_train)\n",
        "dev_inputs = torch.tensor(input_ids_dev)\n",
        "test_inputs = torch.tensor(input_ids_test)\n",
        "train_tags = torch.tensor(tags_train)\n",
        "dev_tags = torch.tensor(tags_dev)\n",
        "test_tags = torch.tensor(tags_test)\n",
        "train_masks = torch.tensor(attention_masks_train)\n",
        "dev_masks = torch.tensor(attention_masks_dev)\n",
        "test_masks = torch.tensor(attention_masks_test)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1740934402123
        }
      },
      "id": "43649f73-0361-4c00-a7cb-8c02d851ce65"
    },
    {
      "cell_type": "code",
      "source": [
        "# We define the dataloaders. \n",
        "# Shuffle the data for training using RandomSampler\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "# Load dev and test data sequentially with SequentialSampler.\n",
        "dev_data = TensorDataset(dev_inputs, dev_masks, dev_tags)\n",
        "dev_sampler = SequentialSampler(dev_data)\n",
        "dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=bs)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_tags)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1740934402252
        }
      },
      "id": "f511d5b9-d6fd-4080-8d4f-058aa2cffc92"
    },
    {
      "cell_type": "code",
      "source": [
        "# The BertForTokenClassification class is used for token-level predictions. \n",
        "# It includes the BERT model and carries out token-level classification in the last layer\n",
        "# We use the Adam optimizer\n",
        "from transformers import BertForTokenClassification, AdamW "
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1740934402380
        }
      },
      "id": "cd412309-b4e5-4971-9e29-61d9689ec8b7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model and use the pretrained BETO model (BERT for Spanish)\n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    \"bert-large-uncased\",\n",
        "    num_labels=len(tag2idx),\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1740934412394
        }
      },
      "id": "798b6d06-e01a-4b1d-8e35-278226257211"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model to the GPU\n",
        "#model.cuda();"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1740934412712
        }
      },
      "id": "651511cc-46d3-4fb4-835e-c9a0e446932c"
    },
    {
      "cell_type": "code",
      "source": [
        "# weight_decay is a regularization procedure with regard to the weight matrices\n",
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "# Adam optimizer\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/custom_37/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1740934412885
        }
      },
      "id": "b2e87b61-e29d-4868-9765-a4af1c354dd9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import a scheduler to reduce the learning rate \n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs; the BERT paper uses 4\n",
        "epochs = 4\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1740934413012
        }
      },
      "id": "8399d3b9-12d3-4ae1-8a9d-90ab004a11d1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modules to measure the progression of training\n",
        "# Done\n",
        "# !pip install seqeval"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1740934413148
        }
      },
      "id": "7fa09649-860e-4e9c-877c-cf9e6a355879"
    },
    {
      "cell_type": "code",
      "source": [
        "import seqeval\n",
        "#from seqeval.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
        "from sklearn.metrics import f1_score, classification_report, precision_recall_fscore_support\n",
        "from tqdm import tqdm, trange"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1740934413307
        }
      },
      "id": "8d8e3d8f-3ddd-464f-acff-eb8b05289712"
    },
    {
      "cell_type": "code",
      "source": [
        "#import wandb\n",
        "#wandb.login()"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1740934413440
        }
      },
      "id": "87c9efc8-7864-444e-9943-5942be8ba67e"
    },
    {
      "cell_type": "code",
      "source": [
        "#wandb.init(project=\"pfsa-id-gtx1080ti-bert-v1\",entity=\"sigitpurnomo\")"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1740934413570
        }
      },
      "id": "7705caa1-a74a-4e02-a648-b5e3f5c21e4c"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "# To measure execution time of this cell\n",
        "\n",
        "# Train the model for; the BERT paper uses 4\n",
        "## Store the average loss after each epoch; these values are used to plot the loss.\n",
        "loss_values, development_loss_values = [], []\n",
        "\n",
        "#data_seqeval = {\n",
        "#    \"predicted_tags\": [],\n",
        "#    \"true_tags\": [],\n",
        "#}\n",
        "#df_seqeval = None\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    #\n",
        "    # Training\n",
        "    #\n",
        "    # Set the model into training mode\n",
        "    model.train()\n",
        "    # Reset the total loss for each epoch\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Transfer batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Remove previous gradients before each backward pass\n",
        "        model.zero_grad()\n",
        "        # forward pass\n",
        "        # This returns the loss (not the model output) since we have input the labels.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "        # Get the loss\n",
        "        loss = outputs[0]\n",
        "        # Backward pass to compute the gradients\n",
        "        loss.backward()\n",
        "        # Train loss\n",
        "        total_loss += loss.item()\n",
        "        # Clip the norm of the gradient\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(\"Average train loss: {}\".format(avg_train_loss))\n",
        "    \n",
        "\n",
        "    # Store each loss value for plotting the learning curve afterwards\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    # After each training epoch, measure performance on development set\n",
        "\n",
        "    # Set the model into evaluation mode\n",
        "    model.eval()\n",
        "    # Reset the development loss for this epoch\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in dev_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # The model must not compute or save gradients, in order to save memory and speed up this step\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, compute predictions\n",
        "            # This will return the logits (logarithm of the odds), not the loss (we do not provide labels)\n",
        "            outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "        # Transfer logits and labels to CPU\n",
        "        logits = outputs[1].detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Compute the accuracy for this batch of development sentences\n",
        "        eval_loss += outputs[0].mean().item()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.extend(label_ids)\n",
        "        \n",
        "        #data_seqeval[\"batch\"].append(str(batch))\n",
        "        #data_seqeval[\"true_tags\"].append(str(label_ids))\n",
        "        #data_seqeval[\"predicted_tags\"].append(str([list(p) for p in np.argmax(logits, axis=2)]))\n",
        "\n",
        "    #df_seqeval = pd.DataFrame(data_seqeval)\n",
        "    #wandb.log({f\"dataframe_seqeval\": wandb.Table(dataframe=df_seqeval)})\n",
        "    \n",
        "    eval_loss = eval_loss / len(dev_dataloader)\n",
        "    development_loss_values.append(eval_loss)\n",
        "    print(\"Development loss: {}\".format(eval_loss))\n",
        "    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "    dev_tags = [tag_values[l_i] for l in true_labels\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "    f1 = f1_score(pred_tags, dev_tags, average='micro')\n",
        "\n",
        "    # Format output with 4 decimal places\n",
        "    output_text = \"train-val F1 score: {:.4f}\\n\".format(f1)\n",
        "\n",
        "    # Print to console\n",
        "    print(output_text)\n",
        "\n",
        "    # Save to a text file\n",
        "    with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
        "        file.write(output_text)\n",
        "    #print(\"Development classification report:\\n{}\".format(classification_report(pred_tags, dev_tags,digits=4)))\n",
        "    print()\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Epoch:  25%|██▌       | 1/4 [24:29<1:13:27, 1469.23s/it]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Average train loss: 0.6366148282374654\nAverage train loss: 0.21576899183647974\nDevelopment loss: 0.16514649391174316\ntrain-val F1 score: 0.7484\n\n\nAverage train loss: 0.1287839865045888\nDevelopment loss: 0.15562740564346314\ntrain-val F1 score: 0.7547\n\n\nAverage train loss: 0.1185712782399995\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "id": "fb45a631-fd1a-464e-8796-46280326bff9"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(pred_tags, dev_tags)),\n",
        "               columns =['Pred', 'True'])"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1740940247926
        }
      },
      "id": "310dcdc4-f5e5-4d52-b817-1ddf90188e2f"
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(folder_name + '/train-val-result-bert.csv')"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1740940248109
        }
      },
      "id": "bd1f278d-2ddc-4e4f-9c6d-52e435941af8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training loss\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o', label=\"training loss\")\n",
        "plt.plot(development_loss_values, 'r-o', label=\"validation loss\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Learning curve\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 864x432 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1740940251463
        }
      },
      "id": "8e860ba8-a0da-4cc5-912d-59d24da75563"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the model to the test set\n",
        "# Set again the model into evaluation mode\n",
        "model.eval()\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "input_ids_list = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # The model must not compute or store gradients\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate predictions.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "    # Transfer logits and labels to CPU\n",
        "    logits = outputs[1].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    input_ids_list.extend(b_input_ids)\n",
        "    \n",
        "    # Calculate the accuracy for this batch of test sentences\n",
        "    eval_loss += outputs[0].mean().item()\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    true_labels.extend(label_ids)\n",
        "\n",
        "pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "test_tags = [tag_values[l_i] for l in true_labels\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "#print(str(pred_tags))\n",
        "#print(str(test_tags))\n",
        "f1 = f1_score(pred_tags, test_tags, average='micro')\n",
        "\n",
        "# Format output with 4 decimal places\n",
        "output_text = \"Test F1 score: {:.4f}\\n\".format(f1)\n",
        "\n",
        "# Print to console\n",
        "print(output_text)\n",
        "\n",
        "# Save to a text file\n",
        "with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
        "    file.write(output_text)\n",
        "#print(\"Test classification report: {}\".format(classification_report(pred_tags, test_tags,digits=4)))\n",
        "print()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Test F1 score: 0.7554\n\n\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1740940384396
        }
      },
      "id": "0d64d31a-e5b6-40ae-bbfb-0bf300a7ffc5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "\n",
        "# Print optimizer's state_dict\n",
        "#print(\"Optimizer's state_dict:\")\n",
        "#for var_name in optimizer.state_dict():\n",
        "#    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model's state_dict:\nbert.embeddings.position_ids \t torch.Size([1, 512])\nbert.embeddings.word_embeddings.weight \t torch.Size([30522, 1024])\nbert.embeddings.position_embeddings.weight \t torch.Size([512, 1024])\nbert.embeddings.token_type_embeddings.weight \t torch.Size([2, 1024])\nbert.embeddings.LayerNorm.weight \t torch.Size([1024])\nbert.embeddings.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.0.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.0.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.0.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.0.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.0.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.0.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.0.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.0.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.0.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.0.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.0.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.0.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.0.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.0.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.0.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.0.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.1.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.1.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.1.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.1.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.1.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.1.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.1.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.1.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.1.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.1.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.1.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.1.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.1.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.1.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.1.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.1.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.2.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.2.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.2.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.2.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.2.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.2.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.2.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.2.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.2.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.2.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.2.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.2.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.2.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.2.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.2.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.2.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.3.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.3.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.3.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.3.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.3.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.3.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.3.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.3.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.3.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.3.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.3.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.3.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.3.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.3.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.3.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.3.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.4.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.4.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.4.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.4.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.4.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.4.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.4.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.4.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.4.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.4.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.4.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.4.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.4.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.4.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.4.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.4.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.5.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.5.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.5.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.5.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.5.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.5.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.5.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.5.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.5.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.5.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.5.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.5.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.5.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.5.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.5.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.5.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.6.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.6.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.6.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.6.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.6.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.6.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.6.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.6.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.6.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.6.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.6.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.6.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.6.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.6.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.6.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.6.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.7.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.7.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.7.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.7.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.7.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.7.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.7.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.7.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.7.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.7.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.7.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.7.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.7.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.7.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.7.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.7.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.8.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.8.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.8.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.8.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.8.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.8.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.8.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.8.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.8.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.8.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.8.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.8.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.8.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.8.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.8.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.8.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.9.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.9.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.9.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.9.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.9.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.9.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.9.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.9.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.9.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.9.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.9.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.9.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.9.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.9.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.9.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.9.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.10.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.10.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.10.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.10.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.10.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.10.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.10.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.10.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.10.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.10.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.10.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.10.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.10.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.10.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.10.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.10.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.11.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.11.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.11.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.11.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.11.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.11.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.11.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.11.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.11.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.11.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.11.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.11.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.11.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.11.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.11.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.11.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.12.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.12.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.12.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.12.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.12.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.12.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.12.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.12.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.12.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.12.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.12.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.12.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.12.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.12.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.12.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.12.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.13.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.13.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.13.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.13.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.13.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.13.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.13.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.13.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.13.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.13.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.13.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.13.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.13.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.13.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.13.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.13.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.14.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.14.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.14.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.14.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.14.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.14.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.14.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.14.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.14.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.14.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.14.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.14.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.14.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.14.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.14.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.14.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.15.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.15.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.15.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.15.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.15.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.15.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.15.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.15.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.15.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.15.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.15.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.15.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.15.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.15.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.15.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.15.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.16.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.16.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.16.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.16.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.16.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.16.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.16.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.16.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.16.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.16.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.16.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.16.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.16.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.16.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.16.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.16.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.17.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.17.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.17.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.17.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.17.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.17.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.17.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.17.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.17.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.17.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.17.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.17.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.17.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.17.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.17.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.17.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.18.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.18.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.18.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.18.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.18.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.18.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.18.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.18.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.18.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.18.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.18.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.18.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.18.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.18.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.18.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.18.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.19.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.19.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.19.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.19.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.19.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.19.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.19.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.19.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.19.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.19.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.19.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.19.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.19.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.19.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.19.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.19.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.20.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.20.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.20.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.20.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.20.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.20.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.20.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.20.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.20.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.20.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.20.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.20.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.20.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.20.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.20.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.20.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.21.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.21.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.21.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.21.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.21.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.21.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.21.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.21.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.21.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.21.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.21.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.21.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.21.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.21.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.21.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.21.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.22.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.22.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.22.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.22.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.22.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.22.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.22.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.22.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.22.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.22.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.22.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.22.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.22.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.22.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.22.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.22.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.23.attention.self.query.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.23.attention.self.query.bias \t torch.Size([1024])\nbert.encoder.layer.23.attention.self.key.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.23.attention.self.key.bias \t torch.Size([1024])\nbert.encoder.layer.23.attention.self.value.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.23.attention.self.value.bias \t torch.Size([1024])\nbert.encoder.layer.23.attention.output.dense.weight \t torch.Size([1024, 1024])\nbert.encoder.layer.23.attention.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.23.attention.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.23.attention.output.LayerNorm.bias \t torch.Size([1024])\nbert.encoder.layer.23.intermediate.dense.weight \t torch.Size([4096, 1024])\nbert.encoder.layer.23.intermediate.dense.bias \t torch.Size([4096])\nbert.encoder.layer.23.output.dense.weight \t torch.Size([1024, 4096])\nbert.encoder.layer.23.output.dense.bias \t torch.Size([1024])\nbert.encoder.layer.23.output.LayerNorm.weight \t torch.Size([1024])\nbert.encoder.layer.23.output.LayerNorm.bias \t torch.Size([1024])\nclassifier.weight \t torch.Size([6, 1024])\nclassifier.bias \t torch.Size([6])\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1740940385875
        }
      },
      "id": "6cdb58de-aa8e-4bca-b481-c8708e43a28c"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(list(zip(pred_tags, test_tags)),\n",
        "               columns =['Pred', 'True'])"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1740940385995
        }
      },
      "id": "fb3fd637-aa6a-4435-9030-20f6060e1629"
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(folder_name + '/test-result-bert.csv')"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1740940386119
        }
      },
      "id": "3df4c9a0-dfbe-46d7-805d-82d7a465e2d7"
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"bert-large-mp-local\")\n",
        "tokenizer.save_pretrained(\"bert-large-mp-local\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "('bert-large-mp-local/tokenizer_config.json',\n 'bert-large-mp-local/special_tokens_map.json',\n 'bert-large-mp-local/vocab.txt',\n 'bert-large-mp-local/added_tokens.json')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1740940395911
        }
      },
      "id": "10aa1d62-6169-430a-9d43-c38b970dec49"
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_test_class = []\n",
        "labels_test_class = []\n",
        "\n",
        "tokens = []\n",
        "token_labels = []\n",
        "unique_labels_test_class = set()\n",
        "\n",
        "with open(\"corpus-raymond/validation-full-class-only.txt\", newline='', encoding='utf-8') as file:\n",
        "    line_reader = csv.reader(file, delimiter='\\t')\n",
        "\n",
        "    for line in line_reader:\n",
        "        # Remove empty spaces and ensure valid parsing\n",
        "        line = [x.strip() for x in line if x.strip()]  # Strip whitespace & ignore empty columns\n",
        "        \n",
        "        if not line:  # If it's an empty line, treat it as a sentence separator\n",
        "            if tokens:  # Avoid adding empty lists\n",
        "                sentences_test_class.append(tokens)\n",
        "                labels_test_class.append(token_labels)\n",
        "                tokens, token_labels = [], []  # Reset for next sentence\n",
        "        else:\n",
        "            if len(line) == 1 and line[0] == '\\\"':  # Handle single double-quote case\n",
        "                tokens.append('\\\"')\n",
        "                token_labels.append('O')  # Assuming label should be 'O' if unknown\n",
        "            elif len(line) >= 2:  # Normal case (word, label)\n",
        "                tokens.append(line[0])\n",
        "                token_labels.append(line[1])\n",
        "                unique_labels_test_class.add(line[1])\n",
        "\n",
        "# Ensure last collected sentence is added\n",
        "if tokens:\n",
        "    sentences_test_class.append(tokens)\n",
        "    labels_test_class.append(token_labels)"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1740940396051
        }
      },
      "id": "ff3200ac-d6a8-4456-9774-c3a5492faa27"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the model to the test with only structure_focus set\n",
        "# Set again the model into evaluation mode\n",
        "\n",
        "tokenized_texts_and_labels_test_class = [\n",
        "    tokenize_and_keep_labels(sent, labs)\n",
        "    for sent, labs in zip(sentences_test_class, labels_test_class)\n",
        "]\n",
        "\n",
        "tokenized_texts_test = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels_test_class]\n",
        "labels_test = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels_test_class]\n",
        "\n",
        "input_ids_test_class = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts_test],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "tags_test_class = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels_test],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "test_class_inputs = torch.tensor(input_ids_test_class)\n",
        "test_class_tags = torch.tensor(tags_test_class)\n",
        "\n",
        "attention_masks_test_class = [[float(i != 0.0) for i in ii] for ii in input_ids_test_class]\n",
        "test_class_masks = torch.tensor(attention_masks_test_class)\n",
        "\n",
        "test_class_data = TensorDataset(test_class_inputs, test_class_masks, test_class_tags)\n",
        "test_class_sampler = SequentialSampler(test_class_data)\n",
        "test_class_dataloader = DataLoader(test_class_data, sampler=test_class_sampler, batch_size=bs)\n",
        "\n",
        "model.eval()\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "input_ids_list = []\n",
        "\n",
        "for batch in test_class_dataloader:\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # The model must not compute or store gradients\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate predictions.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                            attention_mask=b_input_mask, labels=b_labels)\n",
        "    # Transfer logits and labels to CPU\n",
        "    logits = outputs[1].detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    input_ids_list.extend(b_input_ids)\n",
        "    \n",
        "    # Calculate the accuracy for this batch of test sentences\n",
        "    eval_loss += outputs[0].mean().item()\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    true_labels.extend(label_ids)\n",
        "\n",
        "pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
        "test_tags = [tag_values[l_i] for l in true_labels\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n",
        "#print(str(pred_tags))\n",
        "#print(str(test_tags))\n",
        "# Compute F1 score\n",
        "f1 = f1_score(pred_tags, test_tags, average='micro')\n",
        "\n",
        "# Format output with 4 decimal places\n",
        "output_text = \"Test with structure only F1 score: {:.4f}\\n\".format(f1)\n",
        "\n",
        "# Print to console\n",
        "print(output_text)\n",
        "\n",
        "# Save to a text file\n",
        "with open(folder_name + \"/f1_score.txt\", \"a\") as file:\n",
        "    file.write(output_text)\n",
        "#print(\"Test classification report: {}\".format(classification_report(pred_tags, test_tags,digits=4)))\n",
        "\n",
        "\n",
        "print()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Test with structure only F1 score: 0.7780\n\n\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1740940442313
        }
      },
      "id": "3c761a5f-25b9-4890-bbdb-143a2f63f4fc"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "custom_37",
      "language": "python",
      "display_name": "Python_37"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "custom_37"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}