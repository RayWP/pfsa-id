{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e528e393",
   "metadata": {},
   "source": [
    "# Use Case Diagram Extraction Pipeline\n",
    "\n",
    "This notebook reads text documents from the target_text directory and processes them to extract class diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a65797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from collections import defaultdict\n",
    "from spacy import displacy\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee013dbe",
   "metadata": {},
   "source": [
    "# Reading Files from target_text Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eeea468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory already exists: /work/pfsa-id/survey-ud/usecase_diagrams_output\n",
      "Reading files from: /work/pfsa-id/survey-ud/target_text\n",
      "Found 10 text file(s): ['R13_municipal-library.txt', 'R26_BlockCard.txt', 'R28_AnimalClinic.txt', 'R36_Video Rental.txt', 'R39_Insurance.txt', 'R7_SuperMarket.txt', 'R81_VideoSearch.txt', 'dental-clinic.txt', 'geological-samples-observation.txt', 'rental-truck-company.txt']\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for PlantUML files\n",
    "output_dir = os.path.join(os.path.dirname(os.getcwd()), \"survey-ud/usecase_diagrams_output\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created output directory: {output_dir}\")\n",
    "else:\n",
    "    print(f\"Output directory already exists: {output_dir}\")\n",
    "\n",
    "# Define target directory path\n",
    "target_dir = os.path.join(os.path.dirname(os.getcwd()), \"survey-ud/target_text\")\n",
    "print(f\"Reading files from: {target_dir}\")\n",
    "\n",
    "# Check if directory exists\n",
    "if not os.path.exists(target_dir):\n",
    "    print(f\"Error: Directory '{target_dir}' does not exist.\")\n",
    "    raise FileNotFoundError(f\"Directory '{target_dir}' does not exist.\")\n",
    "\n",
    "# Get list of text files from the directory\n",
    "text_files = [f for f in os.listdir(target_dir) if f.endswith('.txt')]\n",
    "\n",
    "if not text_files:\n",
    "    print(\"No text files found in the directory.\")\n",
    "else:\n",
    "    print(f\"Found {len(text_files)} text file(s): {text_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6066cf",
   "metadata": {},
   "source": [
    "# Process Each Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcdcdf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_document(document_text, filename):\n",
    "    \"\"\"Preprocess the document text and split it into sentences\"\"\"\n",
    "    print(f\"Processing document: {filename}\")\n",
    "    \n",
    "    # Data preprocessing\n",
    "    print(\"Step 1: Preprocessing\")\n",
    "    # Remove newlines and extra spaces\n",
    "    document = re.sub(r'\\n', ' ', document_text)\n",
    "    document = re.sub(r'\\s+', ' ', document)\n",
    "    \n",
    "    # Separate document by sentences into a dataframe\n",
    "    document_sentence = pd.DataFrame(document.split('.'), columns=['sentence'])\n",
    "    document_sentence = document_sentence[document_sentence['sentence'].str.strip().str.len() > 0].reset_index(drop=True)\n",
    "    \n",
    "    return document_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd00cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained BERT model for sentence classification\n",
    "def load_sentence_classifier_model():\n",
    "    \"\"\"Load the pre-trained BERT model for sentence classification\"\"\"\n",
    "    model_dir = os.path.join(os.path.dirname(os.getcwd()), \"requirement_classification\", \"all_model\")\n",
    "    \n",
    "    # If multiple models exist, use the most recently created one\n",
    "    model_file = \"microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\"\n",
    "    model_path = os.path.join(model_dir, model_file)\n",
    "    print(f\"Loading sentence classifier model from: {model_path}\")\n",
    "    \n",
    "    # Define model name based on file name pattern\n",
    "    model_name = \"microsoft/deberta-v3-large\"  # Default model base\n",
    "    \n",
    "    # Load the tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    model.to(device)\n",
    "    \n",
    "    return model, tokenizer, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8ada9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextDataset class for sentence classification\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=512):\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f814552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentences(document_sentence, filename, output_dir):\n",
    "    \"\"\"Classify sentences to identify those useful for class diagram extraction using BERT model\"\"\"\n",
    "    print(\"Step 2: Categorizing sentences using pre-trained model\")\n",
    "    document_sentence['useful'] = 0\n",
    "    \n",
    "    # Load the pre-trained model\n",
    "    try:\n",
    "        model, tokenizer, device = load_sentence_classifier_model()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading sentence classifier model: {e}\")\n",
    "        print(\"Falling back to default classification method\")\n",
    "        # You could implement a fallback method here\n",
    "        return document_sentence\n",
    "    \n",
    "    # Create dataset from sentences\n",
    "    sentences = document_sentence['sentence'].tolist()\n",
    "    dataset = TextDataset(sentences, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # Process batches and get predictions\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Classifying sentences\"):\n",
    "            # Move inputs to device\n",
    "            inputs = {key: val.to(device) for key, val in batch.items()}\n",
    "            \n",
    "            # Get model outputs\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Get predicted class (0 = not useful, 1 = useful)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "    \n",
    "    # Update dataframe with predictions\n",
    "    # document_sentence['useful'] = predictions\n",
    "    document_sentence['useful'] = 1 #override\n",
    "    # Log results\n",
    "    useful_count = sum(predictions)\n",
    "    print(f\"Found {useful_count} useful sentences out of {len(sentences)} total sentences\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    checkpoint_file = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_checkpoint.csv\")\n",
    "    document_sentence.to_csv(checkpoint_file)\n",
    "    print(f\"Saved checkpoint to {checkpoint_file}\")\n",
    "    \n",
    "    return document_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7356a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(document_sentence, filename, output_dir):\n",
    "    \"\"\"Extract entities from useful sentences\"\"\"\n",
    "    # Extract sentences marked as useful for class diagram extraction\n",
    "    print(\"Step 3: Extracting class diagram entities\")\n",
    "    sentence_class_diagram_only = document_sentence[document_sentence['useful'] == 1]\n",
    "    document_class = ' '.join(sentence_class_diagram_only['sentence'].tolist())\n",
    "    \n",
    "    # Entity extraction using the model\n",
    "    model_path = os.path.join(os.path.dirname(os.getcwd()), \"key-term-extraction-uc\", \"BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\")\n",
    "    print(f\"Using NER model from: {model_path}\")\n",
    "    \n",
    "    try:\n",
    "        ner_pipeline = pipeline(\"ner\", model=model_path, aggregation_strategy=\"simple\")\n",
    "        entities = ner_pipeline(document_class)\n",
    "        \n",
    "        # Process entities\n",
    "        summary = {\n",
    "            \"actor\": defaultdict(int),\n",
    "            \"usecase\": defaultdict(int)\n",
    "        }\n",
    "        \n",
    "        for ent in entities:\n",
    "            entity_type = ent[\"entity_group\"].lower()\n",
    "            word = ent[\"word\"]\n",
    "            \n",
    "            if entity_type in summary:\n",
    "                summary[entity_type][word] += 1\n",
    "        \n",
    "        # Convert defaultdict to normal dict\n",
    "        summary = {key: list(value.keys()) for key, value in summary.items()}\n",
    "        \n",
    "        # Save entity data as CSV\n",
    "        entity_csv_file = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_entities.csv\")\n",
    "        pd.DataFrame(entities).to_csv(entity_csv_file)\n",
    "        print(f\"Entities saved to CSV: {entity_csv_file}\")\n",
    "        \n",
    "        # Convert entities to JSON serializable format\n",
    "        serializable_entities = []\n",
    "        for ent in entities:\n",
    "            # Extract only serializable properties and convert non-serializable types\n",
    "            serializable_ent = {\n",
    "                \"entity_group\": ent[\"entity_group\"],\n",
    "                \"word\": ent[\"word\"],\n",
    "                \"score\": float(ent[\"score\"]),  # Convert tensor to float if needed\n",
    "                \"start\": ent[\"start\"],\n",
    "                \"end\": ent[\"end\"]\n",
    "            }\n",
    "            serializable_entities.append(serializable_ent)\n",
    "        \n",
    "        # Save entity data as JSON\n",
    "        import json\n",
    "        entity_json_file = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_entities.json\")\n",
    "        with open(entity_json_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                \"entities\": serializable_entities,  # Use serializable entities\n",
    "                \"summary\": summary,\n",
    "                \"document_class\": document_class\n",
    "            }, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"Entities saved to JSON: {entity_json_file}\")\n",
    "        \n",
    "        # Save entity data as plain text\n",
    "        entity_txt_file = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_entities.txt\")\n",
    "        with open(entity_txt_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Document: {filename}\\n\\n\")\n",
    "            f.write(f\"actor identified:\\n{'-'*20}\\n\")\n",
    "            for cls in summary['actor']:\n",
    "                f.write(f\"- {cls}\\n\")\n",
    "            f.write(f\"\\n usecase identified:\\n{'-'*20}\\n\")\n",
    "            for attr in summary['usecase']:\n",
    "                f.write(f\"- {attr}\\n\")\n",
    "            f.write(f\"\\nDetailed Entities:\\n{'-'*20}\\n\")\n",
    "            for ent in serializable_entities:  # Use serializable entities\n",
    "                f.write(f\"Type: {ent['entity_group']}, Word: {ent['word']}, Score: {ent['score']:.4f}\\n\")\n",
    "        print(f\"Entities saved to TXT: {entity_txt_file}\")\n",
    "        \n",
    "        # Return serializable entities for further processing\n",
    "        return {\n",
    "            \"entities\": serializable_entities,  # Use serializable entities\n",
    "            \"summary\": summary,\n",
    "            \"document_class\": document_class\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting entities: {e}\")\n",
    "        return {\n",
    "            \"error\": str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f803e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(document_text, filename):\n",
    "    \"\"\"Process a document through the entire pipeline\"\"\"\n",
    "    # Step 1: Preprocess document\n",
    "    document_sentence = preprocess_document(document_text, filename)\n",
    "    \n",
    "    # Step 2: Classify sentences\n",
    "    document_sentence = classify_sentences(document_sentence, filename, output_dir)\n",
    "    \n",
    "    # Step 3: Extract entities\n",
    "    extraction_result = extract_entities(document_sentence, filename, output_dir)\n",
    "\n",
    "    return \"true \" + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ecd44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing file: R13_municipal-library.txt\n",
      "==================================================\n",
      "Processing document: R13_municipal-library.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 3/3 [00:00<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 useful sentences out of 17 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/R13_municipal-library_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/R13_municipal-library_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/R13_municipal-library_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/R13_municipal-library_entities.txt\n",
      "\n",
      "==================================================\n",
      "Processing file: R26_BlockCard.txt\n",
      "==================================================\n",
      "Processing document: R26_BlockCard.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 3/3 [00:00<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 useful sentences out of 19 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/R26_BlockCard_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/R26_BlockCard_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/R26_BlockCard_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/R26_BlockCard_entities.txt\n",
      "\n",
      "==================================================\n",
      "Processing file: R28_AnimalClinic.txt\n",
      "==================================================\n",
      "Processing document: R28_AnimalClinic.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 2/2 [00:00<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 useful sentences out of 15 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/R28_AnimalClinic_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/R28_AnimalClinic_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/R28_AnimalClinic_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/R28_AnimalClinic_entities.txt\n",
      "\n",
      "==================================================\n",
      "Processing file: R36_Video Rental.txt\n",
      "==================================================\n",
      "Processing document: R36_Video Rental.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 6/6 [00:00<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 useful sentences out of 48 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/R36_Video Rental_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/R36_Video Rental_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/R36_Video Rental_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/R36_Video Rental_entities.txt\n",
      "\n",
      "==================================================\n",
      "Processing file: R39_Insurance.txt\n",
      "==================================================\n",
      "Processing document: R39_Insurance.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 7/7 [00:00<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 useful sentences out of 49 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/R39_Insurance_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/R39_Insurance_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/R39_Insurance_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/R39_Insurance_entities.txt\n",
      "\n",
      "==================================================\n",
      "Processing file: R7_SuperMarket.txt\n",
      "==================================================\n",
      "Processing document: R7_SuperMarket.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 3/3 [00:00<00:00, 16.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 useful sentences out of 22 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/R7_SuperMarket_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/R7_SuperMarket_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/R7_SuperMarket_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/R7_SuperMarket_entities.txt\n",
      "\n",
      "==================================================\n",
      "Processing file: R81_VideoSearch.txt\n",
      "==================================================\n",
      "Processing document: R81_VideoSearch.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 2/2 [00:00<00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 useful sentences out of 16 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/R81_VideoSearch_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/R81_VideoSearch_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/R81_VideoSearch_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/R81_VideoSearch_entities.txt\n",
      "\n",
      "==================================================\n",
      "Processing file: dental-clinic.txt\n",
      "==================================================\n",
      "Processing document: dental-clinic.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 3/3 [00:00<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 useful sentences out of 20 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/dental-clinic_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/dental-clinic_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/dental-clinic_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/dental-clinic_entities.txt\n",
      "\n",
      "==================================================\n",
      "Processing file: geological-samples-observation.txt\n",
      "==================================================\n",
      "Processing document: geological-samples-observation.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 3/3 [00:00<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 useful sentences out of 17 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/geological-samples-observation_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/geological-samples-observation_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/geological-samples-observation_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/geological-samples-observation_entities.txt\n",
      "\n",
      "==================================================\n",
      "Processing file: rental-truck-company.txt\n",
      "==================================================\n",
      "Processing document: rental-truck-company.txt\n",
      "Step 1: Preprocessing\n",
      "Step 2: Categorizing sentences using pre-trained model\n",
      "Loading sentence classifier model from: /work/pfsa-id/requirement_classification/all_model/microsoft-deberta-v3-large_usecase_focus_epochs12_kfold10_batch8.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Classifying sentences: 100%|██████████| 4/4 [00:00<00:00, 12.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 useful sentences out of 32 total sentences\n",
      "Saved checkpoint to /work/pfsa-id/survey-ud/usecase_diagrams_output/rental-truck-company_checkpoint.csv\n",
      "Step 3: Extracting class diagram entities\n",
      "Using NER model from: /work/pfsa-id/key-term-extraction-uc/BERT-Style-model/microsoft/deberta-v3-large-12-epoch-4bs-1028-mt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities saved to CSV: /work/pfsa-id/survey-ud/usecase_diagrams_output/rental-truck-company_entities.csv\n",
      "Entities saved to JSON: /work/pfsa-id/survey-ud/usecase_diagrams_output/rental-truck-company_entities.json\n",
      "Entities saved to TXT: /work/pfsa-id/survey-ud/usecase_diagrams_output/rental-truck-company_entities.txt\n",
      "\n",
      "Processing complete!\n",
      "Processed 10 files.\n",
      "Output saved to: /work/pfsa-id/survey-ud/usecase_diagrams_output\n"
     ]
    }
   ],
   "source": [
    "# Process all files in the target directory\n",
    "results = []\n",
    "\n",
    "for filename in text_files:\n",
    "    file_path = os.path.join(target_dir, filename)\n",
    "    print(f\"\\n{'='*50}\\nProcessing file: {filename}\\n{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            document_text = file.read()\n",
    "            \n",
    "            result = process_document(document_text, filename)\n",
    "            results.append(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filename}: {e}\")\n",
    "        results.append({\n",
    "            \"filename\": filename,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        \n",
    "print(\"\\nProcessing complete!\")\n",
    "print(f\"Processed {len(results)} files.\")\n",
    "print(f\"Output saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a491cb9a",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f90122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a591d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI endpoint: https://dewi.openai.azure.com/\n",
      "Azure OpenAI deployment: o3-mini\n"
     ]
    }
   ],
   "source": [
    "# Initialize Azure OpenAI client\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT_URL_1\", \"\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME_1\", \"\")\n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY_1\", \"\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION_1\")\n",
    "\n",
    "print(f\"Azure OpenAI endpoint: {endpoint}\")\n",
    "print(f\"Azure OpenAI deployment: {deployment}\")\n",
    "\n",
    "# Initialize Azure OpenAI Service client with key-based authentication\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=subscription_key,\n",
    "    api_version=api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "138d4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_diagram_with_azure(actor, usecase, document_text, filename):\n",
    "    \"\"\"\n",
    "    Generate a class diagram using Azure OpenAI by sending a request with the extracted classes, attributes,\n",
    "    and document text.\n",
    "    \n",
    "    Args:\n",
    "        classes (list): List of extracted class names\n",
    "        attributes (list): List of extracted attributes\n",
    "        document_text (str): The full document text used for context\n",
    "        filename (str): The name of the file being processed (without extension)\n",
    "    \n",
    "    Returns:\n",
    "        str: PlantUML code for the class diagram\n",
    "    \"\"\"\n",
    "    # Prepare summary for diagram generation\n",
    "    summary_string = f\"actor: {actor}, usecase: {usecase}, description: {document_text}\"\n",
    "    \n",
    "    mode = \"gen-r-ent\"\n",
    "    # Create plantuml_result folder if it doesn't exist\n",
    "    plantuml_result_dir = \"./\"+ mode + \"-\" + deployment\n",
    "\n",
    "    if mode == \"gen-r-ent\": #with restrictions and entities\n",
    "        prompt = '''Given a description of software requirement: {document_text}\n",
    "                There are list of entities\n",
    "                List of actor:  {actor}\n",
    "                List of usecase: {usecase}\n",
    "\n",
    "                Generate a Use Case Diagram according to the above description and these factors:\n",
    "                - preferably use the actor and usecase provided, but you can also add new ones if needed\n",
    "                - similar actor or usecase could be merged as one\n",
    "                - discover the relationships between actor and usecase as many as possible correctly\n",
    "                - only discover usecase related within the software\n",
    "                Set the output strictly to only PlantUML of the result diagram \n",
    "                '''.format(document_text=document_text, actor=actor, usecase=usecase)\n",
    "        \n",
    "    elif mode == \"gen-nr-nent\": #no resctrictions and no entities\n",
    "        prompt = '''Given a description of software requirement: {document_text}\n",
    "\n",
    "                Generate a Use Case Diagram according to the above description and these factors:\n",
    "                - only discover actor and usecase related within the software\n",
    "                Set the output strictly to only PlantUML of the result diagram \n",
    "                '''.format(document_text=document_text)\n",
    "    \n",
    "    elif mode == \"gen-nr-ent\": #no restrictions and entities\n",
    "        prompt = '''Given a description of software requirement: {document_text}\n",
    "                There are list of entities\n",
    "                List of actor:  {actor}\n",
    "                List of usecase: {usecase}\n",
    "\n",
    "                Generate a Use Case Diagram according to the above description\n",
    "                Set the output strictly to only PlantUML of the result diagram \n",
    "                '''.format(document_text=document_text, actor=actor, usecase=usecase)\n",
    "\n",
    "    \n",
    "    chat_prompt = [\n",
    "            {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt\n",
    "                }]\n",
    "            },\n",
    "        ]\n",
    "\n",
    "    print(chat_prompt)\n",
    "    # Use the existing client from previous cells\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=chat_prompt,\n",
    "        # max_tokens=1000,\n",
    "        # temperature=0,\n",
    "        # top_p=0.95,\n",
    "        # frequency_penalty=0,\n",
    "        # presence_penalty=0,\n",
    "        # stop=None,\n",
    "        # stream=False\n",
    "        max_completion_tokens=100000\n",
    "    )\n",
    "    \n",
    "    # Extract and clean up the result\n",
    "    plantuml_result = completion.choices[0].message.content\n",
    "    \n",
    "    # Clean up any markdown code block markers\n",
    "    plantuml_result = plantuml_result.strip()\n",
    "    plantuml_result = plantuml_result.replace(\"```plantuml\", \"\").replace(\"```\", \"\").strip()\n",
    "    \n",
    "\n",
    "    if not os.path.exists(plantuml_result_dir):\n",
    "        os.makedirs(plantuml_result_dir)\n",
    "        print(f\"Created directory: {plantuml_result_dir}\")\n",
    "    \n",
    "    # Save PlantUML code to file\n",
    "    output_file = os.path.join(plantuml_result_dir, f\"{filename}_class_diagram.puml\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(plantuml_result)\n",
    "    print(f\"PlantUML diagram saved to {output_file}\")\n",
    "    \n",
    "    return plantuml_result, output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6e9fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 JSON files\n",
      "[{'role': 'user', 'content': [{'type': 'text', 'text': \"Given a description of software requirement: The clinic basically schedules patients, provides services for them, and bills them for those services  New patients fill out a form listing their name, address, telephone numbers, allergies, and state of mind prior to scheduling their first appointment  Existing patients are normally scheduled for their next appointment as they depart from their current appointment  When the office staff forget to do this, a desk worker has to call the patient to set up a date  Schedules are entered into a central appointment book; patient records (including contact information) are kept in paper files  Appointments are for one of three procedures: dental hygiene, cavities and fillings, and oral surgery (including root canals and tooth extractions)  For each procedure the patient needs to be prepared and supplies need to be collected (e g , probes, drill bits, cements, resins, etc )  For a hygienist's appointment, preparation could be as simple as seating the patient in dental chair and putting a bib around his or her neck  For oral surgery, anesthesia of various strengths are normally administered prior to operation  Only for oral surgery procedures is it necessary to ask the patient to wait for up to twenty minutes before performing a post-operative check  Billing is always done by the month, and bills are always sent by mail to patients' contact addresses  Checks are received by mail  HMO-funded patients are asked to make a copayment at the time that they leave the office  Each patient also generates a reimbursement request to an insurance company  Insurance companies and HMOs send their checks by mail three months after receiving a reimbursement request  The clinic maintains a supplies inventory file that a worker fills out once a week by physically inspecting each of the three procedures rooms  Supplies and tools are stored in a standard layout in each room\\n                There are list of entities\\n                List of actor:  ['New patients', 'desk', 'patient', 'worker']\\n                List of usecase: ['fill out a form listing', 'generates a reimbursement request']\\n\\n                Generate a Use Case Diagram according to the above description and these factors:\\n                - preferably use the actor and usecase provided, but you can also add new ones if needed\\n                - similar actor or usecase could be merged as one\\n                - discover the relationships between actor and usecase as many as possible correctly\\n                - only discover usecase related within the software\\n                Set the output strictly to only PlantUML of the result diagram \\n                \"}]}]\n",
      "PlantUML diagram saved to ./gen-r-ent-o3-mini\\dental-clinic_class_diagram.puml\n",
      "[{'role': 'user', 'content': [{'type': 'text', 'text': \"Given a description of software requirement: We want to automate the management of a small municipal library  For this, we analyzed its operation to obtain the following list of rules and statements: Members have a first name (character string) and a surname (character string)  The library consists of a set of documents and a set of patrons  Members are subscribed or unsubscribed on a simple request  New documents are added to the library regularly  These documents are either journals or volumes  Volumes are either dictionaries, books or comics  The documents are characterized by a title (character string)  Volumes also have an author (character string)  Bds also have a recipient name (character string)  The newspapers have, in addition to the characteristics of the documents, a date of publication (a date)  Only books can be borrowed  A member can borrow or return a book  Members can borrow books (and only books) and it must be possible to know at any time which books a member has borrowed  A member can borrow a maximum of 3 books  The return date for a borrowed book is fixed at the time of the loan  This date can be extended upon request\\n                There are list of entities\\n                List of actor:  ['member']\\n                List of usecase: ['borrow or return a book', 'borrow books']\\n\\n                Generate a Use Case Diagram according to the above description and these factors:\\n                - preferably use the actor and usecase provided, but you can also add new ones if needed\\n                - similar actor or usecase could be merged as one\\n                - discover the relationships between actor and usecase as many as possible correctly\\n                - only discover usecase related within the software\\n                Set the output strictly to only PlantUML of the result diagram \\n                \"}]}]\n",
      "PlantUML diagram saved to ./gen-r-ent-o3-mini\\R13_municipal-library_class_diagram.puml\n",
      "[{'role': 'user', 'content': [{'type': 'text', 'text': 'Given a description of software requirement: BLOCK CARD Purpose This study aims to design new software that allows bank customers to block their desired card or cards  By finishing this project, customers can block any card via online banking systems  Scope The study will include the \"Block\" process on both web and mobile systems  There will be two separate applications for the mobile platforms, which are Android and iOS  They should have the same function and features for the account creation process  The project will also contain the back-end communication system for the kiosk and branches  Requirements Menu Placement The \"Block Card\" process should be under the \"Cards\" menu  It should be added after the \"My Cards\" page  Customer Users can have four types of cards: debit, credit, virtual and supplementary  Users should be able to block any card using online banking systems  Software System The system should check the card status when the user blocks the desired card  The user can initiate the card-blocking process if the card status is available  During the card-blocking process, the system should ask for the reason for the blocking  The system should display three different kinds of blocking reasons for the user  The blocking reasons can be stolen, missing, and others  If the user selects \"other\" as the reason, the system should ask for further explanation in a free-text area  If the user does not enter this area field as input, the system should not let the user block their card  After the user completes the card-blocking process, the system should immediately block the related card, and no one should be able to use that card in ATMs, shopping, online shopping, etc  If a blocked card is used for anything, the system should inform the banking staff and cardholder\\n                There are list of entities\\n                List of actor:  [\\'user\\']\\n                List of usecase: [\\'block\\', \\'block any card\\', \\'initiate the card-blocking\\']\\n\\n                Generate a Use Case Diagram according to the above description and these factors:\\n                - preferably use the actor and usecase provided, but you can also add new ones if needed\\n                - similar actor or usecase could be merged as one\\n                - discover the relationships between actor and usecase as many as possible correctly\\n                - only discover usecase related within the software\\n                Set the output strictly to only PlantUML of the result diagram \\n                '}]}]\n",
      "PlantUML diagram saved to ./gen-r-ent-o3-mini\\R26_BlockCard_class_diagram.puml\n",
      "[{'role': 'user', 'content': [{'type': 'text', 'text': \"Given a description of software requirement: For each admitted animal, its name, breed (if any) and owner must be stored  Each animal should be given an unique numeric identifier  For each owner, its name, address and phone number should be stored  An unique numeric identifier should also be generated for each one of them  An animal might be owner-less  This happens frequently as the clinic often rescues abandoned dogs from the streets in order to treat them and get them new owners  It should be possible to store information about a specific breed even if no animals of that breed have been treated at the clinic  Each appointement always has a responsible physician  All appointements start at a certain date and time; and are attended by an animal (and of course its owner)  For each physician, his name, address and phone number should be stored  An unique numeric identifier should also be generated for each one of them  In an appointement, several medical conditions might be detected  Each condition has a common name and a scientific name  No two conditions have the same scientific name  It should be possible to store information about the most common conditions for each different breed in the database\\n                There are list of entities\\n                List of actor:  []\\n                List of usecase: ['store information', 'store']\\n\\n                Generate a Use Case Diagram according to the above description and these factors:\\n                - preferably use the actor and usecase provided, but you can also add new ones if needed\\n                - similar actor or usecase could be merged as one\\n                - discover the relationships between actor and usecase as many as possible correctly\\n                - only discover usecase related within the software\\n                Set the output strictly to only PlantUML of the result diagram \\n                \"}]}]\n",
      "PlantUML diagram saved to ./gen-r-ent-o3-mini\\R28_AnimalClinic_class_diagram.puml\n",
      "[{'role': 'user', 'content': [{'type': 'text', 'text': 'Given a description of software requirement: SchlockBuster video is a chain of video rental stores  A unique storeID identifies each store  Additional information about each store is the store address and phone number  SchlockBuster has many employees  An employee ID identifies each employee  Additional information about an employee is the employee\\'s name, address, and phone number  Each employee has at least one and could have many phone numbers  Each employee\\'s phone number is classified by a phone number type, such as an office phone number, home phone number, beeper number, etc  An employee can have many phone numbers but only one per phone number type  Each employee is classified as one type of employee: \"manager,\" \"cashier,\" or \"stocker  An employee type such as \"manager,\" \"cashier,\" or \"stocker\" can classify many employees  A store can employ many employees  An employee must be employed by one and only one store  There are numerous video titles (Braveheart, Lion King, Waterworld, etc ) available to SchlockBuster from many video distributors  SchlockBuster maintains a listing of titles by a title ID  Additional information for each title includes the title\\'s name, run time(such as 120 minutes), and rating (G, PG, R)  SchlockBuster maintains a listing of distributors by distributor ID  Additional information about a distributor includes the distributor\\'s name and phone number  A video title is available from one and only one distributor  A distributor can provide many video titles  Each SchlockBuster store can carry many titles  Many stores can carry a title  All stores carry not all titles  In other words, stores can carry many of the same titles, and some can carry titles that other stores do not  SchlockBuster also maintains, by store, the amount (rental rate) that the store charges to customers to rent the title  This implies that each store can set its rental price for each title  A store can stock multiple copies (the physical cassette cartridge) of the same title  In other words, store 101 can maintain five physical cartridges of \"Mission Impossible \" A cartridge ID number identifies each cartridge  A cartridge utilization count is also maintained for each cartridge  The utilization count represents the number of times a cartridge has been rented  A cartridge status classifies each cartridge  The domain of cartridge status is Available\", \"Rented,\" and \"Broken \" A status type can apply to many cartridges  SchlockBuster maintains a record of each of its customers  A unique customer ID identifies each customer  Additional information maintained about each customer is the customer\\'s name and the customer\\'s phone number  Each customer is associated with the store where they enrolled as members to receive their SchlockBuster Video card  A customer can rent a video from any store  This relationship allows Schlockbuster to credit a portion of each rental amount to the home store of the member, regardless of where the video is rented  SchlockBuster maintains a record of each rental transaction  A rental ID number identifies each rental transaction  Each rental transaction is associated with one and only one customer  Each rental transaction is associated with (rented from) one and only one store  Each rental transaction also captures the rental date and total rental amount  Each rental transaction is associated with one or more rental transaction detail lines  Each rental transaction detail line captures the id of the cartridge being rented, the due date of the cartridge being rented, and the actual return date\\n                There are list of entities\\n                List of actor:  []\\n                List of usecase: [\\'rent a video\\']\\n\\n                Generate a Use Case Diagram according to the above description and these factors:\\n                - preferably use the actor and usecase provided, but you can also add new ones if needed\\n                - similar actor or usecase could be merged as one\\n                - discover the relationships between actor and usecase as many as possible correctly\\n                - only discover usecase related within the software\\n                Set the output strictly to only PlantUML of the result diagram \\n                '}]}]\n",
      "PlantUML diagram saved to ./gen-r-ent-o3-mini\\R36_Video Rental_class_diagram.puml\n",
      "[{'role': 'user', 'content': [{'type': 'text', 'text': \"Given a description of software requirement: Java Programming Workshop Your job is to begin creating classes to support storing, retrieving, and tracking insurance information for Fireman’s Fund customers  You will start by tracking persons, then add policies, then contact info and vehicles and eventually be able to generalize the model and increase its flexibility  We want to get to a point where you can retrieve a person, their policies, vehicles, dwellings, addresses, and contact info  Person and Policy Start by creating a Person class and attributes and getters and setters, as shown below  Assume a Person can be created with all this information at creation time  In a Tester class, create a main()  In the main(), create three-person objects with differing information  Print out the persons’ information using the getXXX() methods  Create a Policy class and test that you can get and set its attributes correctly by creating a policy object  If you have time: See if you can calculate the age for the age() method using the birth date  Collections of Policies There is a link between Persons and Policies  A Person object can hold a collection of multiple policy objects  Add a java util List to your Person class to hold instances of Policy objects  Use an ArrayList object to implement the List interface  Add an addPolicy(Policy) method to the Person class that will accept a policy object and stores it in the list  Add a method: getPolicies() that returns a List of the Policy objects for that Person  Test this works in the main(): Create two policy objects for each Person Add a policy object to the Person by calling addPolicy() Retrieve the policy object and print its details for each customer Policy Details Policies have additional information the company wishes to keep  Policies have the contact information: Phone Numbers, Addresses, and Emails  Policies can cover things like Vehicles  Create classes, attributes, getters, and setters for these new things  Note that the contact classes have a method: contactPointAsString(), which returns a string representation of the contact information  Verify you can create objects of these types in your main()  Since the policy keeps track of these things, create separate list objects in the Policy class to track these items  Like the Person, you should create addEmail(), addPhone(), addAddress(), addVehicle() methods and getVehicles(), getPhones()… methods to store the objects in the policy and retrieve all objects of that type from the policy  Test that this works by adding some of the things you created to the policy and then printing: The Person info For Each policy, its info and a list of its contacts and vehicles  For simplicity, you can code a simple toString() method for Vehicles to print the vehicle  Generalize the Model You do business with companies and persons, so add a class to track Company information  Create a common superclass called a party representing those (persons or companies) with policies  Move the collection of policies up to the Party superclass, along with the addPolicy() and getPolicies() methods  Note that the party has a name() method that returns a String representation of the name  You will need to override this in the Person class and return a concatenation of Last, First name  To test this, create an Array of Party (size 3) in your main()  Create a new company, two polices and some contact info, and two vehicles for each policy  Add these to the Company object Do the same with a Person  Now, add the Person and company objects to the Party Array  You should now be able to loop through the party array and print the party, its name, its policies, and its details (try reusing some of the code you wrote earlier)  Emails, Phones, and Addresses can be considered types of ContactPoints  Create a superclass to hold the common method contactPointAsString()  Vehicles are just one type of thing that can be listed on a policy  Dwellings are another type of thing  Create a superclass PhysicalObject for these two classes, and factor out the common methods and attributes: Redesign your Policy class to hold a list of ContactPoints and a List of Dwellings  You will need to create these physical things in the main() and call a new addPhysicalObject() method to add the things to the list in the policy object  You will need to change the methods to add and retrieve contacts to addContactPoint() and getContactPoints()  You should now be able to print out the policy, its contact points, and its physical things  When you print the physical things, print the description and names, which are the attributes common to the physical object class  Your main() should not have to change much to accommodate these changes  You have now implemented this non-trivial model\\n                There are list of entities\\n                List of actor:  []\\n                List of usecase: ['retrieve a person', 'Policy', 'print', 'print out the policy']\\n\\n                Generate a Use Case Diagram according to the above description and these factors:\\n                - preferably use the actor and usecase provided, but you can also add new ones if needed\\n                - similar actor or usecase could be merged as one\\n                - discover the relationships between actor and usecase as many as possible correctly\\n                - only discover usecase related within the software\\n                Set the output strictly to only PlantUML of the result diagram \\n                \"}]}]\n",
      "PlantUML diagram saved to ./gen-r-ent-o3-mini\\R39_Insurance_class_diagram.puml\n",
      "[{'role': 'user', 'content': [{'type': 'text', 'text': \"Given a description of software requirement: The processes we want to describe are recording the product on the shelf, the customer collecting product, and payment after choosing items; in this part, we have two types of customers: Normal and Extra-customer  Before purchasing products from different continents, the supermarket puts on store according to or following on type of each product  They use physical inventory where every product purchased is recorded by using the form of stock  When the chief of the store wants to check the number on the store, they take all forms for each product and then count products to verify if the number written on the form matches the number of products stored  After purchasing a new product or getting the outcome from a supplier, those products are recorded in stock  For selling, Products are recorded on the shelf of supermarkets  Others to the cold chamber (cheese, meat) or in the fridge and freezer sometimes come from the cold chamber toward the freezer before being recorded to the shelf, checking the product's expiration date  All products are recorded according to the group of each product, the group of alimentation products, the group of pastry/bakery, and butcher products  After recording all products on stock and shelf, it is necessary to record on the cashier's machine where recordable depending on the group  There is a person loaded that action in the supermarket who controller when the shelf is taken care of or occupied of products  When clients or customers enter the supermarket, saw the product wanted in a different group of products, and some employees can help us or orient clients/customers by showing where products are placed  After choosing and selecting products, one can take a basket for storing goods; before going, check the price, expiration date, and ingredients, then go to the cashier  Arriving there, they deposit around him; the cashier takes one by one entering on machine according also on a group of the product when finished, gives us to the controller to make the product on free packing  When the cashier finishes those transactions, they calculate and show the client/customer on-screen of the machine and tell the customer total of money they can pay, and give us an invoice when the customer or client needed  The delivery process begins when the customer first interacts with the service organization and ends when the delivery of the desired service is completed and the customer exits the process  At the supermarket, after getting the order from the chief of order, the bakery and pastry agent prepare the goods and quantities of the order  When finished, they package according to each category of product  Then the chief of order checks and counts if there is no mistake; when the number of orders written to the proforma invoice is well prepared, they give the order for put out before arriving to the customer  Some controllers check again to see if there is some product stolen  After those actions, customers get their order of items ordered; after delivery of that product, the stump and original of the proforma invoice are transferred to the office of the general director  After selecting the product and calculating the total money, the payment to the customer is made in the following ways: Cash: where the customer presents cash to the cashier or where the cashier receives money, and the customer gets an invoice  Cheques: where customers present checks to the cashier for extra-person, not every customer, for example, MINISANTE, CNLS, Rwanda Revenue Authority, and Top Tower Hotel \\n                There are list of entities\\n                List of actor:  ['chief', 'controllers', 'customers']\\n                List of usecase: []\\n\\n                Generate a Use Case Diagram according to the above description and these factors:\\n                - preferably use the actor and usecase provided, but you can also add new ones if needed\\n                - similar actor or usecase could be merged as one\\n                - discover the relationships between actor and usecase as many as possible correctly\\n                - only discover usecase related within the software\\n                Set the output strictly to only PlantUML of the result diagram \\n                \"}]}]\n",
      "PlantUML diagram saved to ./gen-r-ent-o3-mini\\R7_SuperMarket_class_diagram.puml\n",
      "Successfully extracted data from 0 files\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import glob\n",
    "import os \n",
    "\n",
    "output_dir = \"./usecase_diagrams_output\"\n",
    "# Get all JSON files from the output directory\n",
    "json_files = glob.glob(os.path.join(output_dir, \"*_entities.json\"))\n",
    "print(f\"Found {len(json_files)} JSON files\")\n",
    "\n",
    "# Parse each JSON file and extract the required information\n",
    "extracted_data = []\n",
    "\n",
    "for json_file in json_files:\n",
    "    try:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        filename = os.path.basename(json_file).replace('_entities.json', '')\n",
    "        \n",
    "        # Extract document text, classes, and attributes\n",
    "        document = data.get('document_class', '')\n",
    "        actor = data.get('summary', {}).get('actor', [])\n",
    "        usecase = data.get('summary', {}).get('usecase', [])\n",
    "        \n",
    "        generate_class_diagram_with_azure(actor, usecase, document, filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file}: {e}\")\n",
    "\n",
    "print(f\"Successfully extracted data from {len(extracted_data)} files\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
