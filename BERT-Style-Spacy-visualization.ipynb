{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from spacy.tokens import Span\n",
    "import spacy\n",
    "# Load Hugging Face pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=\"BERT-Style-model/microsoft/deberta-v3-large-4-epoch-8-bs\" ,aggregation_strategy = \"simple\")\n",
    "\n",
    "text = \"user will have username and password\"\n",
    "entities = ner_pipeline(text)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3002399-fce7-4d77-a264-c75ee77dc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Hugging Face output to spaCy format\n",
    "from spacy import displacy\n",
    "spacy_ents = {\n",
    "    \"text\": text,\n",
    "    \"ents\": [\n",
    "        {\"start\": ent[\"start\"], \"end\": ent[\"end\"], \"label\": ent[\"entity_group\"]}\n",
    "        for ent in entities\n",
    "    ],\n",
    "    \"title\": \"Named Entity Recognition\",\n",
    "}\n",
    "\n",
    "# Render the visualization\n",
    "displacy.render(spacy_ents, style=\"ent\", manual=True, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db989ed-dccd-4742-9c73-52309ad5bed7",
   "metadata": {},
   "source": [
    "## Seqeval trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4bc373f3-de26-493d-9413-f82e5c8b4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "# === 1. Load test data ===\n",
    "df = pd.read_csv(\"corpus-raymond/test-full-hf-style.csv\")  # replace with your path\n",
    "df[\"IOB_tag\"] = df[\"IOB_tag\"].apply(ast.literal_eval)\n",
    "\n",
    "# === 2. Load model and tokenizer ===\n",
    "model_name = \"BERT-Style-model/microsoft/deberta-v3-large-4-epoch-8-bs\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# === 3. Define label map ===\n",
    "# You must match this to your model's label config\n",
    "id2label = model.config.id2label  # {0: 'O', 1: 'B-ENTITY', ...}\n",
    "label_map = {v: k for k, v in id2label.items()}  # reverse for later if needed\n",
    "df[\"IOB_tag_str\"] = df[\"IOB_tag\"].apply(lambda tags: [id2label[tag] for tag in tags])\n",
    "\n",
    "# === 4. Evaluation ===\n",
    "y_true = df[\"IOB_tag_str\"]\n",
    "y_pred = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4328149e-0c4c-4ccb-861b-82d5a0cee653",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in df[\"tokens\"]:\n",
    "    encoding = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**encoding).logits\n",
    "\n",
    "    predictions = torch.argmax(logits, dim=2)  # shape: [seq_len]\n",
    "    predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]\n",
    "    predicted_token_class = predicted_token_class[1:-1] # remove [pad token]\n",
    "    y_pred.append(predicted_token_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2bc9fcf7-5c75-4355-80e0-ff9a2c2d8a4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples:\n[18, 28, 17, 23, 22, 27, 31, 28, 15, 27, 21, 6, 19, 12, 17]\n[18, 28, 17, 23, 22, 27, 34, 29, 15, 27, 21, 6, 20, 12, 18]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseqeval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseqeval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[0;32m----> 4\u001b[0m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:359\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, average, suffix, mode, sample_weight, zero_division, scheme)\u001b[0m\n\u001b[1;32m    350\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support_v1(y_true, y_pred,\n\u001b[1;32m    351\u001b[0m                                                     average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[1;32m    352\u001b[0m                                                     warn_for\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf-score\u001b[39m\u001b[38;5;124m'\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    356\u001b[0m                                                     scheme\u001b[38;5;241m=\u001b[39mscheme,\n\u001b[1;32m    357\u001b[0m                                                     suffix\u001b[38;5;241m=\u001b[39msuffix)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/seqeval/metrics/sequence_labeling.py:130\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, suffix)\u001b[0m\n\u001b[1;32m    126\u001b[0m         true_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(true_sum, \u001b[38;5;28mlen\u001b[39m(entities_true_type))\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred_sum, tp_sum, true_sum\n\u001b[0;32m--> 130\u001b[0m precision, recall, f_score, true_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_precision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheme\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_tp_actual_correct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_tp_actual_correct\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m precision, recall, f_score, true_sum\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/seqeval/metrics/v1.py:122\u001b[0m, in \u001b[0;36m_precision_recall_fscore_support\u001b[0;34m(y_true, y_pred, average, warn_for, beta, sample_weight, zero_division, scheme, suffix, extract_tp_actual_correct)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(average_options))\n\u001b[0;32m--> 122\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m pred_sum, tp_sum, true_sum \u001b[38;5;241m=\u001b[39m extract_tp_actual_correct(y_true, y_pred, suffix, scheme)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/seqeval/metrics/v1.py:101\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_true) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_pred) \u001b[38;5;129;01mor\u001b[39;00m len_true \u001b[38;5;241m!=\u001b[39m len_pred:\n\u001b[1;32m    100\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(len_true, len_pred)\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples:\n[18, 28, 17, 23, 22, 27, 31, 28, 15, 27, 21, 6, 19, 12, 17]\n[18, 28, 17, 23, 22, 27, 34, 29, 15, 27, 21, 6, 20, 12, 18]"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "f1_score(y_true[0:15], y_pred[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e89d3e5f-9745-46d0-ade1-f8167ad3e861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for each procedure the patient need to be prepare and supply need to be collect ( e.g. , probe , drill bit , cement , resin , etc . ) .'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tokens\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76591043-e323-4b76-95c0-63525cc30512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "59f442d3-b340-4080-ab10-75f3eecc92cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a706c-ecda-4eb7-be35-2ae9cfb345cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
